<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Niels Berglund</title>
  <link href="http://nielsberglund.com/atom.xml" rel="self"/>
  <link href="http://nielsberglund.com"/>
  <updated>2019-06-03T18:29:57+02:00</updated>
  <id>http://nielsberglund.com/</id>
  <generator uri="http://gohugo.io/">Hugo</generator>

  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 22, 2019]]></title>
    <link href="http://nielsberglund.com/2019/06/03/interesting-stuff---week-22-2019/" rel="alternate" type="text/html"/>
    <updated>2019-06-03T18:29:57+02:00</updated>
    <id>http://nielsberglund.com/2019/06/03/interesting-stuff---week-22-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/porting-desktop-apps-to-net-core/">Porting desktop apps to .NET Core</a>. This is a very informative post discussing porting of .NET Framework applications to .NET Core. Seeing that the apps to port can be of different grades of complexity, this first post covers simple use cases, and a follow-up post covers the more complex scenarios.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/apache-spark-mllib-tutorial-ec6f1cb336a9">Apache Spark MLlib Tutorial: Linear Regression</a>. This post is the first part of a tutorial on how to work with MLLib in Apache Spark. For me, this is interesting as I can see us at <a href="/derivco">Derivco</a> start to use Spark.</li>
</ul>

<h2 id="vs-code">VS Code</h2>

<ul>
<li><a href="https://blog.usejournal.com/visual-studio-code-for-java-the-ultimate-guide-2019-8de7d2b59902">Visual Studio Code for Java: The Ultimate Guide 2019</a>. I have written a couple of posts where I have used <em>VS Code</em> and Java. However, since I am a .NET guy &ldquo;at heart&rdquo;, the Java ecosystem is a mystery to me, and I have &ldquo;fumbled&rdquo; my way through. I wish I had come across the post I link to here, as it gives you awesome information about how to work with <em>VS Code</em> and Java.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/visual-data-ops-for-apache-kafka-on-azure-hdinsight-powered-by-lenses/">Visual data ops for Apache Kafka on Azure HDInsight, powered by Lenses</a>. This post looks at how you can manage your streaming data operations, from visibility to monitoring, by the use of <a href="https://lenses.io/">Lenses</a>. The post looks at how to do it in Azure, but it is as applicable on-prem as well. Once again, this is interesting to me as, at <a href="/derivco">Derivco</a>, we are great fans of Kafka.</li>
<li><a href="https://www.confluent.io/blog/deploying-kafka-streams-and-ksql-with-gradle-part-2-managing-ksql-implementations">Deploying Kafka Streams and KSQL with Gradle â€“ Part 2: Managing KSQL Implementations</a>. The second part in a series about how to develop, and deploy Kafka Streams and KSQL parts of streaming applications using <a href="https://gradle.org/">Gradle</a>.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 21, 2019]]></title>
    <link href="http://nielsberglund.com/2019/05/26/interesting-stuff---week-21-2019/" rel="alternate" type="text/html"/>
    <updated>2019-05-26T10:02:45+02:00</updated>
    <id>http://nielsberglund.com/2019/05/26/interesting-stuff---week-21-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/schemas-contracts-compatibility">Schemas, Contracts, and Compatibility</a>. This blog post looks at how Kafka together with its schema registry can be used in a microservices environment, potentially as a replacement for REST. Very interesting!</li>
<li><a href="https://www.confluent.io/blog/kafka-summit-london-2019-session-videos">Kafka Summit London 2019 Session Videos</a>. In last weeks <a href="/2019/05/19/interesting-stuff---week-20-2019/">roundup</a> I mentioned that I had attended the Kafka Summit in London. The organizers have now made all session videos and slides available. So go to the post I link to and look at the sessions that interest you!</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="/2019/05/26/java--sql-server-2019-extensibility-framework-the-sequel/">Java &amp; SQL Server 2019 Extensibility Framework: The Sequel</a>. In SQL Server 2019 CTP 2.5, Microsoft made some changes to requirements for writing Java code to be used by SQL Server. In this post, I look at what those changes are, and what our Java code should look like going forward.</li>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/05/22/sql-server-2019-community-technology-preview-3-0-is-now-available/">SQL Server 2019 community technology preview 3.0 is now available</a>. The title says it all. Microsoft just released SQL Server 2019 CTP 3.0. Go and get it while it is hot! Oh, above I mentioned about changes in CTP 2.5 impacting how we write Java code for SQL Server. The 3.0 release has some additional changes, so expect a follow-up blog post about that.</li>
</ul>

<h2 id="next-weeks-roundup">Next Weeks Roundup</h2>

<p>I am away the whole of next week, and not back until Tuesday, June 4. Due to this, the roundup for next week may be delayed for a couple of days.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Java &amp; SQL Server 2019 Extensibility Framework: The Sequel]]></title>
    <link href="http://nielsberglund.com/2019/05/26/java--sql-server-2019-extensibility-framework-the-sequel/" rel="alternate" type="text/html"/>
    <updated>2019-05-26T07:20:09+02:00</updated>
    <id>http://nielsberglund.com/2019/05/26/java--sql-server-2019-extensibility-framework-the-sequel/</id>
    <content type="html"><![CDATA[<p>As you may know, a while back I wrote some posts about the support for Java in SQL Server 2019: <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a>. The posts covered in some detail how Java in SQL Server worked, and how to write Java code for use in SQL Server. However, a week or two ago &ldquo;the sky came tumbling down&rdquo; when Microsoft released SQL Server 2019 CTP 2.5.</p>

<blockquote>
<p><strong>NOTE:</strong> CTP stands for Community Technology Preview and is like a beta release.</p>
</blockquote>

<p>What Microsoft did in CTP 2.5 was to introduce Java Language Extension SDK, and your Java code now needs to inherit an abstract base class from the SDK. This requirement makes a large part of my previous posts &ldquo;null and void&rdquo;, so in this post, we look at what to do going forward.</p>

<p></p>

<p>What happened here, (functionality introduced that negates previous functionality), is the danger when writing about beta releases. I should know, as it has happened before. Back in 2003 some colleagues and I wrote a book about the upcoming SQL Server 2005 release: <a href="https://www.amazon.com/First-Look-Server-2005-Developers/dp/0321180593/ref=sr_1_fkmrnull_1">A First Look at SQL Server 2005 for Developers</a>, and we wrote the book based on beta releases. When Microsoft eventually released SQL Server 2005, at least a couple of chapters in the book covered functionality that no longer existed. Well, what can you do?</p>

<p>Anyway, let us go back to SQL Server 2019 and Java.</p>

<h2 id="recap-pre-ctp-2-5">Recap (pre CTP 2.5)</h2>

<p>When I started this post, my idea was to do a brief recap of what the Java implementation looked like in the previous CTP&rsquo;s, to show what it used to be, and refer to that in this post. After I had written 90% of the <em>Recap</em> I realized it had become way too long, so I decided to skip it.</p>

<p>If you are interested in what it used to be, you can go back and read the posts in the <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a> series. The most relevant posts are:</p>

<ul>
<li><a href="/2018/12/02/sql-server-2019-extensibility-framework--java---hello-world/">SQL Server 2019 Extensibility Framework &amp; Java - Hello World</a>: We looked at installing and enabling the Java extension, as well as some very basic Java code.</li>
<li><a href="/2018/12/08/sql-server-2019-extensibility-framework--java---passing-data/">SQL Server 2019 Extensibility Framework &amp; Java - Passing Data</a>: In this post, we discussed what is required to pass data back and forth between SQL Server and Java.</li>
<li><a href="/2018/12/19/sql-server-2019-extensibility-framework--java---null-values/">SQL Server 2019 Extensibility Framework &amp; Java - Null Values</a>: This, the <a href="/2018/12/19/sql-server-2019-extensibility-framework--java---null-values/">Null Values</a>, post is a follow up to the <a href="/2018/12/08/sql-server-2019-extensibility-framework--java---passing-data/">Passing Data</a> post, and we look at how to handle <code>null</code> values in data passed to Java.</li>
</ul>

<h2 id="demo-data">Demo Data</h2>

<p>In this post, we use some data from the database, so let us set up the necessary database, tables, and load data into the tables:</p>

<pre><code class="language-sql">USE master;
GO
SET NOCOUNT ON;
GO
DROP DATABASE IF EXISTS JavaTestDB;
GO
CREATE DATABASE JavaTestDB;
GO
USE JavaTestDB;
GO

DROP TABLE IF EXISTS dbo.tb_Rand10
CREATE TABLE dbo.tb_Rand10(RowID int identity primary key, x int, 
                          y int;

INSERT INTO dbo.tb_Rand10(x, y)
SELECT TOP(10) CAST(ABS(CHECKSUM(NEWID())) % 14 AS int) 
  , CAST(ABS(CHECKSUM(NEWID())) % 20 AS int)
FROM sys.objects o1
CROSS JOIN sys.objects o2
GO
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Create Database Objects</em></p>

<p>We see from <em>Code Snippet 1</em> how we:</p>

<ul>
<li>Create a database: <code>JavaTestDB</code>.</li>
<li>Create a table: <code>dbo.tb_Rand10</code>.</li>
<li>Insert some data into the table.</li>
</ul>

<p>The data we insert is entirely random, but it gives us something to &ldquo;play around&rdquo; with. Now, when we have a database and some data let us get started.</p>

<h2 id="microsoft-extensibility-sdk-for-java">Microsoft Extensibility SDK for Java</h2>

<p>As mentioned above, in CTP 2.5, Microsoft changes the way we implement Java code in SQL Server, and they do it to create a better developer experience when writing Java code for SQL Server.</p>

<blockquote>
<p><strong>NOTE:</strong> I am not totally sure this change gives us a better developer experience, I guess time will tell.</p>
</blockquote>

<p>In CTP 2.5 and onwards when you write Java code for SQL Server you implement your code using the <strong>Microsoft Extensibility SDK for Java</strong>, (SDK). The SDK acts sort of like an interface as it exposes abstract classes that your code need to extend/target, (more about that later).</p>

<p>The SDK comes in the form of a <code>.jar</code> file, and you download the SDK from <a href="http://aka.ms/mssql-java-lang-extension">here</a>. Since a <code>.jar</code> file is essentially an archive file you can open the SDK <code>.jar</code> with your favorite file archiver utility and when you do, you see:</p>

<p><img src="/images/posts/sql_2k19_java_sdk_jar1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>SDK Jar - I</em></p>

<p>We see in <em>Figure 1</em> how I have extracted the SDK <code>.jar</code> to a folder, and how the <code>.jar</code> file contains at the top level two folders: <code>com</code> and <code>META-INF</code>. The <code>com</code> folder is the top level folder for the Java SDK package, and below we look a bit more into it. The <code>META-INF</code> folder contains metadata information about the <code>.jar</code> package, and in this post we do not care about it.</p>

<p>Coming back to the <code>com</code> folder I mentioned it was the top level folder for the package, and if we drill down into it, it looks something like so:</p>

<p><img src="/images/posts/sql_2k19_java_sdk_jar2.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>SDK Jar - II</em></p>

<p>In <em>Figure 2</em>, outlined in blue, we see how the package name follows the standard of a hierarchical naming pattern: <code>com.microsoft.sqlserver.javalengextension</code>. Below <code>javalangextension</code> we have three classes outlined in red - these are the classes mentioned above:</p>

<ul>
<li><strong><code>AbstractSqlServerExtensionExecutor</code></strong></li>
<li><strong><code>AbstractSqlServerExtensionDataset</code></strong></li>
<li><strong><code>PrimitiveDataset</code></strong></li>
</ul>

<p>Let us look at what these classes do.</p>

<h2 id="abstractsqlserverextensionexecutor">AbstractSqlServerExtensionExecutor</h2>

<p>The <code>AbstractSqlServerExtensionExecutor</code> abstract class is the class you need to inherit from/extend in the classes that SQL Server calls. The source code looks like so (I have copied the code from <a href="https://docs.microsoft.com/en-us/sql/advanced-analytics/java/java-sdk?view=sqlallproducts-allversions#abstractsqlserverextensionexecutor-source-code">here</a>):</p>

<pre><code class="language-java"> package com.microsoft.sqlserver.javalangextension;

import com.microsoft.sqlserver.javalangextension.AbstractSqlServerExtensionDataset;
import java.lang.UnsupportedOperationException;
import java.util.LinkedHashMap;

/**
 * Abstract class containing interface used by the Java extension
 */
public abstract class AbstractSqlServerExtensionExecutor {
  /* Supported versions of the Java extension */
  public final int SQLSERVER_JAVA_LANG_EXTENSION_V1 = 1;

  /* Members used by the extension to determine application specifics */
  protected int executorExtensionVersion;
  protected String executorInputDatasetClassName;
  protected String executorOutputDatasetClassName;

  public AbstractSqlServerExtensionExecutor() { }

  public void init(String sessionId, int taskId, int numTasks) {
    /* Default implementation of init() is no-op */
  }

  public AbstractSqlServerExtensionDataset execute(
               AbstractSqlServerExtensionDataset input, 
               LinkedHashMap&lt;String, Object&gt; params) {
    throw new UnsupportedOperationException(
       &quot;AbstractSqlServerExtensionExecutor execute() is not implemented&quot;);
  }

  public void cleanup() {
    /* Default implementation of cleanup() is no-op */
  }
}
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>AbstractSqlServerExtensionExecutor</em></p>

<p>When looking at the code in <em>Code Snippet 2</em> we see how the class:</p>

<ul>
<li>Has three class members that according to the comments have something to do with application specifics.</li>
<li>Has three methods: <code>init</code>, <code>execute</code>, and <code>cleanup</code>.</li>
</ul>

<p>Later in the post, I come back to the class members, but now I want to look at the three methods. More specifically, I want to look at the <code>execute</code> method since <code>init</code>, and <code>cleanup</code> are fairly self-explanatory: <code>init</code> if any initialization needs to be done, and <code>cleanup</code> for any, well, clean up after usage.</p>

<h4 id="execute">execute</h4>

<p>That leaves us <code>execute</code>. Notice in <em>Code Snippet 2</em> how both <code>init</code> and <code>cleanup</code> are no-ops, whereas <code>execute</code> is not. Furthermore, if someone calls <code>execute</code> in a class which extends <code>AbstractSqlServerExtensionExecutor</code>, and there is no implementation of <code>execute</code> the method throws an <code>UnsupportedOperationException</code> error. So who would call <code>execute</code>?</p>

<p>To answer the question about who is calling <code>execute</code>, let us remind ourselves what happens when we call <code>sp_execute_external_script</code>. We do that by looking at what happens when we execute R/Python code. In my <a href="/sql_server_2k16_r_services">SQL Server R Services</a> series we  talked about the components which make up <strong>SQL Server Machine Learning Services</strong>, and we saw how the flow when we execute an external script, looks something like so:</p>

<p><img src="/images/posts/sql_2k19_java_intro_flow1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Components &amp; Flow</em></p>

<p>The flow is similar when we execute Java code; e.g. when we execute <code>sp_execute_external_script</code> SQL Server calls into the <em>Launchpad</em> service which then &ldquo;spins&rdquo; up the external engine and your code runs. In this case the call goes into the Java extension library (a <code>.dll</code>), and the extension library calls into the JVM. So it is the extension library that calls the <code>execute</code> method. This is different to pre CTP 2.5 where the extension called a method specified in the <code>@script</code> parameter: <code>@script = N'packagename.classname.method'</code>, and now it is: <code>@script = N'packagename.classname'</code>.</p>

<p>The implication of this is that in pre CTP 2.5 you could have multiple &ldquo;entry&rdquo; points, (methods), to call into, whereas now the entry point is the <code>execute</code> method.</p>

<p>Above I mentioned that one of the reasons for introducing the SDK was to create a better developer experience, and the signature of <code>execute</code> gives some hints about this:</p>

<pre><code class="language-java">public AbstractSqlServerExtensionDataset execute(
               AbstractSqlServerExtensionDataset input, 
               LinkedHashMap&lt;String, Object&gt; params) {...}
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Execute Method</em></p>

<p>From the signature in <em>Code Snippet 3</em> we see how the <code>execute</code> method takes two parameters and has a return type. This in itself is interesting as pre CTP 2.5 the methods you called into did not allow parameters, and had to be <code>void</code>.</p>

<p>When we look at the parameters, the <code>execute</code> method expects we see they are:</p>

<ul>
<li><code>AbstractSqlServerExtensionDataset input</code></li>
<li><code>LinkedHashMap&lt;String, Object&gt; params</code></li>
</ul>

<p>The <code>input</code> parameter references any dataset you pass in the class, (from the <code>@input_data_1</code> parameter in <code>sp_execute_external_script</code>). We talk more about <code>AbstractSqlServerExtensionDataset</code> below.</p>

<p>What about the <code>params</code> parameter? As the name implies, it has to do with passing in parameters to the <code>execute</code> method. Remember that in pre CTP 2.5 a method could not have parameters and if you wanted to send in parameters you first defined them in the <code>@params</code> parameter in <code>sp_execute_external_script</code> and declared them like so:</p>

<pre><code class="language-sql">DECLARE @p1 int = 21;
DECLARE @p2 int = 21;
EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'JavaTest1.adder'
, @params = N'@x int, @y int'
, @x = @p1
, @y = @p2   
GO
</code></pre>

<p><strong>Code Snippet 4</strong> <em>Call from T-SQL to Java with Parameters</em></p>

<p>What we see in <em>Code Snippet 4</em> how we add two parameter definitions, (<code>@x</code> and <code>@y</code>), to the <code>@params</code> parameter, and how we then declare and assign values to them: <code>@x = @p1</code>, and <code>@y = @p2</code>. In the Java code, as the methods had to be parameterless, we added the parameters as class members and named them the same as in the SQL code, but without the <code>@</code> sign. In the methods, we then used those class members.</p>

<p>In CTP 2.5 and onwards, we still declare the parameters as before in <code>sp_execute_external_script</code>, but we no longer need to define the parameters as class members in the Java code. The Java extension dll takes the parameters and populates the <code>LinkedHasMap</code>, with the parameters defined in <code>sp_execute_external_script</code>. The extension adds them as key-value pairs, with the key being the parameter name, (without the <code>@</code>), and the value is the value of the parameter. In the <code>execute</code> method, you retrieve them from the <code>params</code> parameter and use them.</p>

<p>So far I have not mentioned anything about the return type of the <code>execute</code> method, other than it being an <code>AbstractSqlServerExtensionDataset</code>, (as is the first input parameter in <code>execute</code>). So, let us discuss <code>AbstractSqlServerExtensionDataset</code>.</p>

<h2 id="abstractsqlserverextensiondataset">AbstractSqlServerExtensionDataset</h2>

<p>As the name implies, the <code>AbstractSqlServerExtensionDataset</code> &ldquo;deals&rdquo; with datasets. In pre CTP 2.5 if you wanted to send in a dataset like: <code>SELECT col1, col2 FROM someTable</code>, you had to - in your class - define arrays as class members representing the columns in the dataset. For return datasets, you had to do the same. Both for input datasets as well as return datasets the class members had to have well-known names: <code>inputDataCol*N*</code>, and <code>outputDataCol*N*</code>, where <em>N</em> is the column number (1 based). For input datasets, the Java extension populated the <code>inputDataCol</code> class members, and in your code, you looped through them. When returning a dataset from your code, you populated the <code>outputDataCol</code> class members, and the Java extension converted it to a result set when returning.</p>

<p>Many developers found the above complex and convoluted, so the Java SDK introduces the <code>AbstractSqlServerExtensionDataset</code>. The class contains methods for handling input and output data, and you see the source code for it <a href="https://docs.microsoft.com/en-us/sql/advanced-analytics/java/java-sdk?view=sqlallproducts-allversions#abstractsqlserverextensiondataset">here</a>. As a developer, you - instead of defining all the various input and output column arrays - create an implementation of the <code>AbstractSqlServerExtensionDataset</code> and uses that in the code. Unless you have specific requirements, you do not even have to create the implementation of <code>AbstractSqlServerExtensionDataset</code>; an implementation already exists in the SDK, the <code>PrimitiveDataset</code>.</p>

<h2 id="primitivedataset">PrimitiveDataSet</h2>

<p>The <code>PrimitiveDataset</code> is a concrete implementation of the <code>AbstractSqlServerExtensionDataset</code>, and it is similar to how we handled datasets pre CTP 2.5 in that it stores simple types as primitives arrays. You find the source of the class <a href="https://docs.microsoft.com/en-us/sql/advanced-analytics/java/java-sdk?view=sqlallproducts-allversions#primitivedataset">here</a>, and below, we see how we use it.</p>

<h2 id="java-code">Java Code</h2>

<p>It is time for some code, but before we do that, ensure you have downloaded the SDK from <a href="http://aka.ms/mssql-java-lang-extension">here</a>. For the code I write here I use <em>VS Code</em> together with the <em>Maven</em> extension. I wrote a blog post about <em>VS Code</em>, Java and <em>Maven</em> <a href="/2019/01/17/sql-server-2019--java-with-visual-studio-code/">here</a> if you want to refresh your memory.</p>

<p>I start with creating a <em>Maven</em> project based on the <em>Maven</em> archetype <code>maven-archetype-quickstart</code>. This gives me a &ldquo;starter&rdquo; class <code>App</code> containing a <code>public static void main()</code> entry point. I add to the project a class <code>JavatTest1</code> in the source file <code>JavaTest1.java</code>, and this is the class that I want to inherit from <code>AbstractSqlServerExtensionExecutor</code>. So I write some code like so:</p>

<pre><code class="language-java">public class JavaTest1 extends AbstractSqlServerExtensionExecutor {

}
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Extending AbstractSqlServerExtensionExecutor</em></p>

<p>As we see in <em>Code Snippet 5</em> I extend the <code>AbstractSqlServerExtensionExecutor</code> class, but when I do it I immediately see red &ldquo;squiggles&rdquo; under <code>AbstractSqlServerExtensionExecutor</code>, and when I mouse over I get a dialog like so:</p>

<p><img src="/images/posts/sql_2k19_java_sdk_dep1.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Inheritance Error</em></p>

<h4 id="maven-dependencies">Maven Dependencies</h4>

<p>As we see in <em>Figure 2</em>, it looks like <em>Maven</em>/<em>VS Code</em> cannot resolve the name <code>AbstractSqlServerExtensionExecutor</code>. That is not that strange as we do not have any dependency on the <code>.jar</code> file. So how do we set a dependency on the downloaded SDK? Well, we add a dependency in the <code>pom.xml</code> file, and, (for <em>Maven</em>), it needs to be in the form of:</p>

<pre><code class="language-xml">&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;some_groupId&lt;/groupId&gt;
    &lt;artifactId&gt;the_artifactId&lt;/artifactId&gt;
    &lt;version&gt;some_version&lt;/version&gt;
  &lt;/dependency&gt;
  ...
&lt;/dependencies&gt;
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Dependency</em></p>

<p>We see in <em>Code Snippet 6</em> how a dependency consists of a <code>groupId</code>, <code>artifactId</code>, and <code>version</code>. Usually, you follow the <em>Maven</em> <a href="https://maven.apache.org/guides/mini/guide-naming-conventions.html">naming standards</a>, but in our case, where we have downloaded the SDK <code>jar</code> directly, we do not have to do that. Regardless of that, the <code>artifactId</code> needs to match the filename, sans extension, and a version number is required.</p>

<p>The dependency points out where to find the dependent file in the local <em>Maven</em> repository, or to be downloaded to from a remote repository. On Windows, we find the local <em>Maven</em> repository at <code>%USERPROFILE%\.m2\repository</code>. Coming back to <em>Code Snippet 6</em>, the <code>groupId</code>\<code>artifactId</code>\<code>version</code> defines the folder hierarchy in the local <em>Maven</em> repository:</p>

<pre><code class="language-xml">&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;nielsb&lt;/groupId&gt;
    &lt;artifactId&gt;mssql-java-lang-extension&lt;/artifactId&gt;
    &lt;version&gt;1.0&lt;/version&gt;
  &lt;/dependency&gt;
  ...
&lt;/dependencies&gt;
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Java SDK Dependency</em></p>

<p>The <code>dependency</code> in <em>Code Snippet 7</em> sets the expectation that the <code>.jar</code> file is located at: <code>%USERPROFILE%\.m2\repository\nielsb\mssql-java-lang-extension\1.0</code>. The <code>nielsb</code> directory is just a random directory, and it could be anything. The one thing to think about is that when you copy the actual file to the directory, the file-name needs to include the version. So as per <em>Code Snippet 7</em>, the file name is: <code>mssql-java-lang-extension-1.0.jar</code>:</p>

<p><img src="/images/posts/sql_2k19_java_sdk_dep_hierarch.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Folder Hierarchy Dependency</em></p>

<p>In <em>Figure 3</em> we see the &ldquo;layout&rdquo; of the local <em>Maven</em> repository after I have set it up for the SDK dependency. Outlined in blue we see the different folders below<code>..\m2\repository</code>, and the outline in red shows the renamed SDK file. Having done this <em>VS Code</em> now &ldquo;picks up&rdquo; the dependency and we can start using it in our code.</p>

<h4 id="use-the-sdk">Use the SDK</h4>

<p>Our project should now compile OK, so let us add some logic to the <code>JavaTest1</code> class. We start with writing similar code to what we saw in the [<strong>SQL Server 2019 Extensibility Framework &amp; Java - Hello World</strong>] post; the <code>adder</code> method where we took two variables and added them together.</p>

<p>However, now when we use the SDK, we do not have to declare the variables as global class members, they are instead  part of the <code>params</code> parameter in the <code>execute</code> method:</p>

<pre><code class="language-java">package sql;

import com.microsoft.sqlserver.javalangextension.PrimitiveDataset;
import java.util.LinkedHashMap;
import com.microsoft.sqlserver.javalangextension.\
            AbstractSqlServerExtensionExecutor;
public class JavaTest1 extends AbstractSqlServerExtensionExecutor {

  public PrimitiveDataset execute(PrimitiveDataset input, 
                                  LinkedHashMap&lt;String, 
                                  Object&gt; params) {

      int x = (int)params.get(&quot;x&quot;);
      int y = (int)params.get(&quot;y&quot;);

      System.out.printf(&quot;The result of adding %d and %d = %d&quot;, 
                         x, y, x + y);  
      return null;

  }
}
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>JavaTest1 Class and Execute Method</em></p>

<p>In <em>Code Snippet 8</em> we see the complete <code>JavaTest1</code> source code. We see how we do some <code>import</code> of classes we use, and in the <code>execute</code> method, we <code>get</code> the two parameters we want from the <code>params</code> parameter. We return <code>null</code> since we do not have any resultset to pass back. Oh, the Java language extension does, still, not support output parameters.</p>

<p>In the <em>VS Code</em> project we have an <code>App.java</code> source file with a <code>main</code> method, by which we can test that our code works:</p>

<pre><code class="language-java">public static void main( String[] args )
{
    JavaTest1 j1 = new JavaTest1();
    LinkedHashMap&lt;String, Object&gt; lh = 
            new LinkedHashMap&lt;String, Object&gt;();
    lh.put(&quot;x&quot;, 21);
    lh.put(&quot;y&quot;, 21);

    j1.execute(null, lh);

}
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Main Method</em></p>

<p>In <em>Code Snippet 9</em> we see a big difference between pre CTP 2.5 and now, in that now the method (<code>execute</code>) is not required to be <code>static</code> any more. The Java language extension now &ldquo;news up&rdquo; an instance of the class that we call into.</p>

<p>Let us create a <code>.jar</code> file out of our project so we can deploy to SQL Server. Since I am using <em>Maven</em>, in the <em>VS Code</em>&rsquo;s&rsquo; <em>Maven</em> extension I click on <code>package</code>, (read more about it in the <a href="/2019/01/17/sql-server-2019--java-with-visual-studio-code/">Java with Visual Studio Code</a> post). What happens is that <em>Maven</em> recompiles, (if any changes have taken place), and then builds the <code>.jar</code> file, and places it in the <code>..\target</code> directory.</p>

<p>Theoretically when we have the <code>.jar</code> file we can deploy it to the database where we want to execute the code from, by using the <code>CREATE EXTERNAL LIBRARY</code> statement we discussed in the <strong>SQL Server 2019, Java &amp; External Libraries</strong> - <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">I</a>, and <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">II</a> posts. The issue with that is if we try to do that in a database where we have not deployed any Java code to, exceptions happen when we execute against the code, as the SDK is not present in the database (the <code>.jar</code> does not contain the SDK). So we first need to deploy the SDK, and as we do it on the local machine, we can deploy it based on file location:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY javaSDK 
FROM (CONTENT = 'W:\mssql-java-lang-extension.jar')
WITH (LANGUAGE = 'Java');
GO 
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Create SDK External Library</em></p>

<p>When you have run the code in <em>Code Snippet 10</em> you can check that everything worked by executing: <code>SELECT * FROM sys.external_libraries</code>, and you see an entry named <code>javaSDK</code>. Oh, the name we give the library is of no importance. Having done this, we deploy our <code>.jar</code> to the database, also using <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY mySqlJar 
FROM (CONTENT = 'W:\sql-1.0.jar')
WITH (LANGUAGE = 'Java');
GO 
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Create External Library from Java Project</em></p>

<p>After executing the code in <em>Code Snippet 11</em> we try and execute the Java code:</p>

<pre><code class="language-sql">DECLARE @p1 int = 21;
DECLARE @p2 int = 21;
EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'sql.JavaTest1'
, @params = N'@x int, @y int'
, @x = @p1
, @y = @p2   
GO
</code></pre>

<p><strong>Code Snippet 12</strong> <em>Call from T-SQL to Java with Parameters</em></p>

<p>The code in <em>Code Snippet 12</em> is almost identical to what we see in <em>Code Snippet 4</em>, apart from that we no longer call into a method, (<code>adder</code>), but instead a class: <code>JavaTest1</code>. Unfortunately, when we run the code in <em>Code Snippet 12</em> we get an exception:</p>

<pre><code class="language-sql">Started executing query at Line 17
Msg 39004, Level 16, State 20, Line 0

A 'Java' script error occurred during execution of 
  'sp_execute_external_script' with HRESULT 0x80004004.

STDOUT message(s) from external script: 
2019-05-25 08:24:25.01  Error: 
         Unsupported executor version encountered

Total execution time: 00:00:01.230
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Exception</em></p>

<p>The exception is, as we see in <em>Code Snippet 13</em>: <code>Unsupported executor version encountered</code>, hmm what is that? Go back and look at <em>Code Snippet 2</em>, and the beginning of the <code>AbstractSqlServerExtensionExecutor</code> class:</p>

<pre><code class="language-java">public abstract class AbstractSqlServerExtensionExecutor {
  /* Supported versions of the Java extension */
  public final int SQLSERVER_JAVA_LANG_EXTENSION_V1 = 1;

  /* Members used by the extension to determine application specifics */
  protected int executorExtensionVersion;
  protected String executorInputDatasetClassName;
  protected String executorOutputDatasetClassName;

  ...

}
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>AbstractSqlServerExtensionExecutor</em></p>

<p>Notice in <em>Code Snippet 14</em> the four members:</p>

<ul>
<li><code>public final int SQLSERVER_JAVA_LANG_EXTENSION_V1 = 1;</code></li>
<li><code>protected int executorExtensionVersion;</code></li>
<li><code>protected String executorInputDatasetClassName;</code></li>
<li><code>protected String executorOutputDatasetClassName;</code></li>
</ul>

<p>The four members above are there for the Java language extension to use. They indicate what version of the extension it is and what class to use for input and output dataset. These are required, and we set them like so:</p>

<pre><code class="language-java">...
public class JavaTest1 extends AbstractSqlServerExtensionExecutor {
    
    public JavaTest1() {
        executorExtensionVersion = SQLSERVER_JAVA_LANG_EXTENSION_V1;
        executorInputDatasetClassName = PrimitiveDataset.class.getName();
        executorOutputDatasetClassName = PrimitiveDataset.class.getName();
    }
  
  public PrimitiveDataset execute(PrimitiveDataset input, 
                                  LinkedHashMap&lt;String, 
                                  Object&gt; params) {...}
}
</code></pre>

<p><strong>Code Snippet 15:</strong> <em>Executor Version and Data Set Class Names</em></p>

<p>As we see in <em>Code Snippet 15</em> we set the members in the class <code>ctor</code>, and when we have done it we:</p>

<ul>
<li>Re-build the <code>.jar</code>.</li>
<li>Drop the external library.</li>
<li>Re-create the external library as in <em>Code Snippet 11</em>.</li>
</ul>

<p>When we now execute the code in <em>Code Snippet 12</em>:</p>

<p><img src="/images/posts/sql_2k19_java_sdk_success_1.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Success</em></p>

<p>So, after we have set the various member values, all works OK. It is worth noticing that even though we do not pass any datasets, we still need to set the values for <code>executorInputDatasetClassName</code> and <code>executorOutputDatasetClassName</code>. Having said that, let us look at how we use datasets.</p>

<p>To look at datasets we want to pass in data from the table <code>dbo.tb_Rand10</code>, in fact, we want to pass in the <code>RowID</code>, <code>x</code>, and <code>y</code> columns: <code>SELECT * FROM dbo.tb_Rand10</code>. In our Java code, we then add the value of the <code>x</code>, and <code>y</code> columns together and return a dataset containing the <code>RowID</code> and the result. So we create a new class, (and source file), <code>JavaTest2</code>. In the <code>execute</code> method, we do as follows:</p>

<pre><code class="language-java">public PrimitiveDataset execute(PrimitiveDataset input, LinkedHashMap&lt;String, Object&gt; params) {

    /*
      grab the RowID, x and y columns
      and convert them into arrays
    */
    int[] rowIds = input.getIntColumn(0);
    int[] xCol = input.getIntColumn(1);
    int[] yCol = input.getIntColumn(2);
    int rowCount = rowIds.length;

    //arrays for output data
    int[] outIds = new int[rowCount];
    int[] outRes = new int[rowCount];

    for(int i = 0; i &lt; rowCount; i++) {
        int x = xCol[i];
        int y = yCol[i];
        outIds[i] = rowIds[i];
        outRes[i] = x + y;
    }

    //Create the return dataset
    PrimitiveDataset outData = new PrimitiveDataset();
    //set up metadata
    outData.addColumnMetadata(0, &quot;RowID&quot;, java.sql.Types.INTEGER, 0, 0);
    outData.addColumnMetadata(1, &quot;Result&quot;, java.sql.Types.INTEGER, 0, 0);
    
    //add the arrays to the dataset
    outData.addIntColumn(0, outIds, null);
    outData.addIntColumn(1, outRes, null);
            
    return outData;

}

</code></pre>

<p><strong>Code Snippet 16:</strong> <em>Input and Output Datasets</em></p>

<p>In the <code>execute</code> method in <em>Code Snippet 16</em> we see how we expect the Java language extension to pass in an instance of a <code>PrimitiveDataset</code> as the <code>input</code> parameter. In our code, we then:</p>

<ul>
<li>Take the individual columns and convert them to arrays.</li>
<li>Create two output arrays, one for the <code>RowID</code>, and one for the result.</li>
</ul>

<p>When we have the output arrays, we loop the input arrays, and:</p>

<ul>
<li>Assign the <code>RowID</code> to the array for <code>RowID</code>.</li>
<li>Get the values for the <code>x</code> and <code>y</code> column arrays.</li>
<li>Add them together and assign the value to the output result array, (<code>outRes</code>).</li>
</ul>

<p>We then create an instance of the <code>PrimitiveDataset</code> class, and:</p>

<ul>
<li>Add column meta data for the columns we want to return.</li>
<li>Assign the output arrays to the output columns.</li>
<li>Finally we return the <code>PrimitiveDataset</code> instance.</li>
</ul>

<p>We can now compile the code and create a <code>.jar</code> file, and deploy to the database as we did after <em>Code Snippet 15</em>. The code to call into the class looks like so:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'sql.JavaTest2'
, @input_data_1 = N'SELECT * FROM dbo.tb_Rand10'
WITH RESULT SETS ((RowID int, Result int))
GO
</code></pre>

<p><strong>Code Snippet 17:</strong> <em>SQL Code to Pass in Data</em></p>

<p>In <em>Code Snippet 17</em> we pass in data via the <code>@input_data_1</code> parameter, and we use the <code>WITH RESULT SETS</code> to format the output. The result when we execute looks like so:</p>

<p><img src="/images/posts/sql_2k19_java_sdk_success_2.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Data Passing</em></p>

<p>We see in <em>Figure 5</em> that our code is working, and we get back the result of adding the <code>x</code>, and <code>y</code> columns. Happy Days!</p>

<h2 id="summary">Summary</h2>

<p>In this post, we set out to look at how the introduction of the Java Language Extension SDK changes the programming model when writing Java code that should be called from SQL Server. However, before we started to look into the programming model, we looked at how we can add dependencies to <em>VS Code</em> and the <em>Maven</em> extension. We saw that:</p>

<ul>
<li>We add a <code>&lt;dependency&gt;</code> to the <code>&lt;dependencies&gt;</code> section.</li>
<li>The <code>&lt;dependency&gt;</code> consists (at least) of <code>groupId</code>, <code>artifactId</code>, and <code>version</code>.</li>
<li>The <code>groupId</code>, <code>artifactId</code>, and <code>version</code> should match the directory structure of the local <em>Maven</em> repository.</li>
<li><code>artifactId</code> corresponds to the dependency file, sans extension.</li>
<li>The name of the dependency file we copy to the local repository must include the <code>&lt;version&gt;</code> number.</li>
</ul>

<p>So what about the SDK programming model? We saw that:</p>

<ul>
<li>Our classes which we want to call into need to inherit from <code>AbstractSqlServerExtensionExecutor</code>.</li>
<li>We have to implement an &ldquo;entry-point&rdquo; method: <code>execute</code>, which is what the Java language extension calls.</li>
<li>We no longer need to create class member variables for parameters, as the <code>execute</code> method accepts a <code>LinkedHashMap</code> corresponding to the parameters we want to pass in.</li>
<li>We no longer need to create class member variables for input dataset , as the <code>execute</code> method accepts a concrete implementation of <code>AbstractSqlServerExtensionDataset</code>.</li>
<li>The SDK contains a concrete implementation of <code>AbstractSqlServerExtensionDataset</code>: <code>PrimitiveDataset</code>.</li>
<li>For return datasets we use a concrete implementation of <code>AbstractSqlServerExtensionDataset</code>, for example <code>PrimitiveDataset</code>.</li>
<li>The class we call into needs to expose certain members indicating version of the language extension and class name of the <code>AbstractSqlServerExtensionDataset</code> implementation.</li>
</ul>

<p>This post was a high level overview of the new programming model using the SDK, and I have only &ldquo;scraped the surface&rdquo; on certain parts of it. Expect follow-up posts going deeper into the programming model, for example how to handle <code>null</code> values within the <code>AbstractSqlServerExtensionDataset</code>.</p>

<p><strong>STOP THE PRESSES</strong></p>

<p>While I wrote this blog post Microsoft released SQL Server CTP 3.0, which introduces further changes to the Extension Language programming model. Instead of delaying this post, I cover that in future posts.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 20, 2019]]></title>
    <link href="http://nielsberglund.com/2019/05/19/interesting-stuff---week-20-2019/" rel="alternate" type="text/html"/>
    <updated>2019-05-19T16:28:12+02:00</updated>
    <id>http://nielsberglund.com/2019/05/19/interesting-stuff---week-20-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/default-implementations-in-interfaces/">Default implementations in interfaces</a>. A blog post introducing a new feature in C# 8.0: default method implementations in interfaces. This comes in real handy if you, for example, want to add new methods to an existing interface.</li>
<li><a href="https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-core-3-0/">Performance Improvements in .NET Core 3.0</a>. A blog post which takes a tour through some of the many improvements, big and small, that have gone into the .NET Core 3.0 runtime and core libraries in order to make applications and services leaner and faster.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/h2o-driverless-ai">H2O&rsquo;s Driverless AI: An AI that Creates AI</a>.  An <a href="https://www.infoq.com/">InfoQ</a> presentation where the presenter shares an approach on automating ML using H2Oâ€™s Driverless AI. Driverless AI employs the techniques of expert data scientists in an easy-to-use application that helps scale data science efforts; empowers data scientists to work on projects faster using automation and state-of-the-art computing power from GPUs to accomplish tasks in minutes that used to take months. Very cool!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<p>I attended the <a href="https://kafka-summit.org/events/kafka-summit-london-2019/">Kafka Summit</a>, in London the week of May 13. The conference was very well organized, and I came away impressed by that. However, I am not that impressed by the speakers at the conference. Don&rsquo;t get me wrong, the Confluent speakers were all top-notch, engaging and presenting interesting concepts. What not impressed me was the 3rd party speakers. In my opinion, the topics were not centred around Kafka, and the speakers were in general, not that engaging.</p>

<p>Anyway, below is a couple of links related to announcements during the conference.</p>

<ul>
<li><a href="https://www.confluent.io/blog/announcing-confluent-community-catalyst-program">Announcing the Confluent Community Catalyst Program</a>. The conference started with <a href="https://twitter.com/tlberglund">Tim Berglund</a> announcing the Confluent Community Catalyst Program, an MVP like program for Kafka.</li>
<li><a href="https://www.confluent.io/blog/introducing-cloud-native-experience-for-apache-kafka-in-confluent-cloud">Introducing a Cloud-Native Experience for Apache Kafka in Confluent Cloud</a>. As part of the keynote, Neha Narkhede, (co-founder of Confluent), announced the availability of Apache Kafka as a service in the cloud. She demonstrated the ease of setting up Kafka in the cloud - 5 seconds to fully functional Kafka! Kafka as a service is initially available on AWS and Google Cloud, let us hope it comes to Azure soon!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What Is Niels Doing)</h2>

<p>The CTP 2.5 release of SQL Server 2019 changed a lot regarding the Java language extension and how to write Java code to be executed from <code>sp_execute_external_script</code>. I am at the moment writing a blog post, where I look at the changes to the programming model. I plan to try and publish it in about a week.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 19, 2019]]></title>
    <link href="http://nielsberglund.com/2019/05/11/interesting-stuff---week-19-2019/" rel="alternate" type="text/html"/>
    <updated>2019-05-11T06:39:50+02:00</updated>
    <id>http://nielsberglund.com/2019/05/11/interesting-stuff---week-19-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/net-core-is-the-future-of-net/">.NET Core is the Future of .NET</a>. .NET is Dead! Long Live .NET! Somewhat melodramatic, but anyway. So, in this blog post Microsoft announces what almost everyone already knew - that .NET Framework 4.8 is the last major version of .NET Framework. Going forward Microsoft&rsquo;s efforts will be on .NET Core.<br /></li>
<li><a href="https://devblogs.microsoft.com/dotnet/introducing-net-5/">Introducing .NET 5</a>. Hot on the heels of the blog post above, announcing the death of .NET Framework, comes this post, laying out the future of .NET Core, .NET 5.</li>
<li><a href="https://devblogs.microsoft.com/dotnet/introducing-diagnostics-improvements-in-net-core-3-0/">Introducing diagnostics improvements in .NET Core 3.0</a>. Yet another .NET Core post. This post discusses a suite of tools that utilize new features in the .NET runtime that makes it easier to diagnose and solve performance problems.</li>
</ul>

<h2 id="data-science-machine-learning">Data Science / Machine Learning</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-ml-net-1-0/">Announcing ML.NET 1.0</a>. I have during the last months now and then posted in these &ldquo;roundups&rdquo; about new releases of ML.NET. Microsoft has now released version 1.0 with a lot of interesting new features, and that is what this post is about.</li>
<li><a href="https://www.infoq.com/presentations/h2o-model-spark">Productionizing H2O Models with Apache Spark</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation demonstrating the creation of pipelines integrating H2O machine learning models and their deployments using Scala or Python.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/05/kafka-zeebe-streams-workflows">Event Streams and Workflow Engines â€“ Kafka and Zeebe</a>. An <a href="https://www.infoq.com/">InfoQ</a> discussing how Kafka fits in an Event-Driven Architecture, and how workflow engines can handle complex business processes. The article also mentioned how Zeebe, a new highly scalable workflow engine, can be used with Kafka.</li>
<li><a href="https://www.confluent.io/blog/apache-kafka-data-access-semantics-consumers-and-membership">Apache Kafka Data Access Semantics: Consumers and Membership</a>. This is an article discussing in detail how the Kafka consumer works. It also talks about consumer groups, how their state is saved, and consistency is ensured. It discusses how consumer groups are managed in a distributed way, and finally, the article looks at the rebalance protocol.</li>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-4-four-pillars-of-event-streaming-microservices">Journey to Event Driven â€“ Part 4: Four Pillars of Event Streaming Microservices</a>. This is the fourth &ldquo;episode&rdquo; in the &ldquo;Journey to Event Driven&rdquo;. This time the discussion is around the four individual parts that make up event streaming. I cannot wait to hear more about it next week at the Kafka Summit in London!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 18, 2019]]></title>
    <link href="http://nielsberglund.com/2019/05/05/interesting-stuff---week-18-2019/" rel="alternate" type="text/html"/>
    <updated>2019-05-05T07:13:49+02:00</updated>
    <id>http://nielsberglund.com/2019/05/05/interesting-stuff---week-18-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li>[Designing Distributed Systems with TLA+][]. An <a href="https://www.infoq.com/">InfoQ</a> presentation where the presenter discusses the ideas behind TLA+, which is a specification language that describes a system, its properties, and how it works.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/using-net-and-docker-together-dockercon-2019-update/">Using .NET and Docker Together â€“ DockerCon 2019 Update</a>. This post is about the improvements and new features in .NET Core 3.0 related to Docker and running your code in Docker.</li>
</ul>

<h2 id="databases">Databases</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/yugabytedb">YugaByte DB - A Planet-scale Database for Low Latency Transactional Apps</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation introducing and demoing YugaByte DB, a large scale DB, highlighting distributed transactions with global consistency.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://databricks.com/blog/2019/05/02/detecting-financial-fraud-at-scale-with-decision-trees-and-mlflow-on-databricks.html">Detecting Financial Fraud at Scale with Decision Trees and MLflow on Databricks</a>. An excellent post about how to use Databricks to detect fraud. Why I like this article is because of the sample code, it makes it easy to follow along.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/optimizing-kafka-streams-applications">Optimizing Kafka Streams Applications</a>. This article discusses how one can optimize Kafka Stream applications based on the new processor topology optimization framework which Kafka Streams 2.1 introduced.</li>
<li><a href="https://www.confluent.io/blog/pipelinedb-team-joins-confluent">The PipelineDB Team Joins Confluent</a>. I had no idea that <a href="https://www.pipelinedb.com/">PipelineDB</a> existed before this blog post. In my mind, PipelineDB joining Confluent can be huge, and I cannot wait to see what they dream up.</li>
<li><a href="https://www.buzzsprout.com/186154/1073627-load-balanced-apache-kafka-derivco-s-globally-distributed-gaming-business">Load-Balanced Apache Kafka: Derivco&rsquo;s Globally Distributed Gaming Business</a>. My colleague <a href="https://twitter.com/charllamprecht">Charl Lamprecht</a> and I had the pleasure of being interviewed by Tim Berglund (no relations) for a Kafka podcast. We, or rather Charl as I had audio issues, spoke about Kafka, load balancing via F5&rsquo;s and the journey we have had to get Kafka implemented in <a href="/derivco">Derivco</a>.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 17, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/28/interesting-stuff---week-17-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-28T08:12:38+02:00</updated>
    <id>http://nielsberglund.com/2019/04/28/interesting-stuff---week-17-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/introducing-net-for-apache-spark/">Introducing .NET for ApacheÂ® Sparkâ„¢ Preview</a>. What the title says! Microsoft has released a preview of .NET that you can use together with Apache Spark. It is built on the Spark interop layer, designed to provide high-performance bindings to multiple languages. Being able to write C# code for Spark is so awesome; hopefully, we can soon use it in Notebooks as well.</li>
<li><a href="https://towardsdatascience.com/why-kubernetes-is-a-great-choice-for-data-scientists-e130603b9b2d">Why Kubernetes is a Great Choice for Data Scientists</a>. This is an interesting post discussing how Kubernetes can be used in a data science world.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/">Reliable Microservices Data Exchange With the Outbox Pattern</a>. At <a href="/derivco">work</a> we have started looking at <a href="https://twitter.com/debezium">Debezium</a> as a way to get data from the database into other systems, and while I was investigating this, I came across the linked blog-post. If you are interested in how to turn your databases into event stream sources, then this post is a must read!</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://docs.microsoft.com/en-us/sql/sql-server/sql-server-ver15-release-notes?view=sqlallproducts-allversions">SQL Server 2019 preview release notes</a>. Earlier this week, Microsoft released SQL Server 2019 preview CTP 2.5. Some very cool new features! Go and get it!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 16, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/21/interesting-stuff---week-16-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-21T16:36:40+02:00</updated>
    <id>http://nielsberglund.com/2019/04/21/interesting-stuff---week-16-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-net-core-3-preview-4/">Announcing .NET Core 3 Preview 4</a>. Some new interesting features in Preview 4 of .NET Core 3.0. Hope we&rsquo;ll see RTM soon.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb4b">Learn Enough Docker to be Useful Part 1: The Conceptual Landscape</a>. This post is the first &ldquo;episode&rdquo; in a series about how to learn Docker. It is excellent, and for a Docker newbie as myself quite invaluable!</li>
<li><a href="https://towardsdatascience.com/key-kubernetes-concepts-62939f4bc08e">Key Kubernetes Concepts</a>. This article covers essential Kubernetes concepts, and itâ€™ll help you make a mental model of the most important Kubernetes terms to speed your understanding of the technology.</li>
<li><a href="https://towardsdatascience.com/https-medium-com-bachwehbi-data-lake-an-asset-or-a-liability-c424c74cfde8">Data Lake: an asset or a liability?</a>. This post looks at several important points to take into account when starting a Data Lake project.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/04/18/the-april-release-of-azure-data-studio-is-now-available/">The April release of Azure Data Studio is now available</a>. As the title says; Microsoft has released a new version (April 2019) of Azure Data Studio. There are quite a few new interesting features, and I cannot wait to try out the <a href="https://microsoft.github.io/SandDance/">SandDance</a> extension.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/how-to-create-your-own-deep-learning-project-in-azure-509660d8297">How to create your own Deep Learning Project in Azure</a>. In this article, the author takes us through how to use Azure Databricks with Tensorflow and Keras to build a deep learning project.</li>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/04/16/automated-machine-learning-from-sql-server-with-azure-machine-learning/">Automated machine learning from SQL Server with Azure Machine Learning</a>. This post discusses how to leverage Azure Machine Learning Service from SQL Server Machine Learning Services.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-summit-new-york-2019-session-videos">Kafka Summit New York 2019 Session Videos</a>. The Kafka Summit took place in New York earlier this month. This post links to the session videos.</li>
<li><a href="https://www.confluent.io/blog/dawn-of-devops-managing-and-evolving-schemas-with-confluent-control-center">Dawn of DevOps: Managing and Evolving Schemas with Confluent Control Center</a>. This post is the first in a three-part series of DevOps related &ldquo;stuff&rdquo;. This first post looks at how to use Confluence Control Center to manage and evolve schemas.</li>
<li><a href="https://towardsdatascience.com/beat-cache-invalidation-in-asp-net-core-using-kafka-and-debezium-65cd1d80554d">Beat Cache Invalidation in ASP.NET Core Using Kafka and Debezium</a>. This article discusses how to create a better in-memory cache in ASP.NET Core by using Change Data Capture on a database to send events to Apache Kafka via Debezium.</li>
<li><a href="https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/">Pivoting Aggregates in Ksql</a>. This is an excellent post by <a href="https://twitter.com/rmoff">Robin</a> where he show how we can do pivoting of aggregates in KSQL.</li>
</ul>

<h2 id="sql-server-machine-learning-services">SQL Server Machine Learning Services</h2>

<ul>
<li><a href="/2019/04/21/installing-r-packages-in-sql-server-machine-learning-services---iv-permissions/">Installing R Packages in SQL Server Machine Learning Services - IV: Permissions</a>. In this post, I look at permissions required when using <code>CREATE EXTERNAL LIBRARY</code> as well as ownership of the created libraries.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing R Packages in SQL Server Machine Learning Services - IV: Permissions]]></title>
    <link href="http://nielsberglund.com/2019/04/21/installing-r-packages-in-sql-server-machine-learning-services---iv-permissions/" rel="alternate" type="text/html"/>
    <updated>2019-04-21T11:15:19+02:00</updated>
    <id>http://nielsberglund.com/2019/04/21/installing-r-packages-in-sql-server-machine-learning-services---iv-permissions/</id>
    <content type="html"><![CDATA[<p>This post is the fourth in a series about installing R packages in <strong>SQL Server Machine Learning Services</strong> (SQL Server ML Services). To see all posts in the series go to <a href="/sql_server_ml_services_install_packages"><strong>Install R Packages in SQL Server ML Services Series</strong></a>.</p>

<p>Why this series came about is a colleague of mine <a href="https://www.linkedin.com/in/dane-bax/">Dane</a> pinged me and asked if I had any advice as he had issues installing an R package into one of their SQL Server instances. I tried to help him and then thought it would make a good topic for a blog post. Of course, at that time I didn&rsquo;t think it would be more posts than one, but here we are.</p>

<p>In this post, we look at:</p>

<ul>
<li>What permissions <code>CREATE EXTERNAL LIBRARY</code> requires.</li>
<li>The ability to create external libraries with different owners and what impact it has.</li>
</ul>

<p></p>

<p>Let us do a recap to see where we are.</p>

<h2 id="recap">Recap</h2>

<p>In the last post; <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> we looked at how to deploy R packages to SQL Server without having to have file system access to the machine SQL Server runs on.</p>

<p>We achieve this by creating an external library, using a DDL statement <code>CREATE EXTERNAL LIBRARY</code>, on the database we want to use the R package on. What <code>CREATE EXTERNAL LIBRARY</code> does, is it uploads package files to a database from a file path or byte stream. The signature looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM (CONTENT = { &lt;file_spec&gt; }  
    [, PLATFORM = &lt;platform&gt; ]) 
WITH ( LANGUAGE = '&lt;language&gt;' )  
[ ; ] 
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>The arguments we see in <em>Code Snippet 1</em> are:</p>

<ul>
<li><code>library_name</code>: A unique name for the package. The unique:ness is based on the name and the principal id under which it is created. We look closer at that in this post.</li>
<li><code>owner_name</code>: This optional parameter specifies the name of the user or role that owns the external library. More about that later in this post as well.</li>
<li><code>file_spec</code>: The <code>file_spec</code> specifies the content of the package for a specific platform, and it can either be in the form of a file location (local path/network path) or a hex literal.</li>
<li><code>platform</code>: An optional parameter and right now only Windows is supported.</li>
<li><code>language</code>: Specifies the language of the package. In SQL Server 2017 the only supported language is R.</li>
</ul>

<p>One of the examples we used throughout the post looked like this:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R'); 
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create External Library</em></p>

<p>In <em>Code Snippet 2</em> we:</p>

<ul>
<li>Name the external library <code>randomForest</code>.</li>
<li>Indicate where the package file is (it has to be a zipped file).</li>
<li>Set R as the language.</li>
</ul>

<p>The code works fine, but the problem is that the package file has to be in a location where SQL Server can read the file, and this - most likely - requires access to the box where SQL Server is installed.</p>

<p>In the <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">previous post</a> we discussed how we could create an external library from the hex-literal of the package, and we mentioned two different ways to accomplish this:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create an external library from the R package based on the file path in a local SQL Server where we have access to the file system (like <code>localhost</code>).</li>
<li>Get the binary representation from the <code>content</code> column in <code>sys.external_library_files</code> via some XML &ldquo;magic&rdquo;.</li>
<li>Assign the retrieved value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 3 above (local database).</li>
</ol>

<p>Alternatively, you can connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="housekeeping">Housekeeping</h2>

<p>Before we &ldquo;dive&rdquo; into today&rsquo;s topics let us look at the code we use today. This section is here for those of who want to follow along in what we are doing in the post.</p>

<pre><code class="language-sql">USE master;
GO

DROP DATABASE IF EXISTS DataScienceDB;
GO

IF EXISTS(SELECT 1 FROM sys.server_principals WHERE name = 'dane')
BEGIN
  DROP LOGIN dane;
END

CREATE LOGIN dane
WITH PASSWORD = 'password1234$';

IF EXISTS(SELECT 1 FROM sys.server_principals WHERE name = 'nielsb')
BEGIN
  DROP LOGIN nielsb;
END

CREATE LOGIN nielsb
WITH PASSWORD = 'password1234$';

CREATE DATABASE DataScienceDB;
GO

USE DataScienceDB;
GO

CREATE USER dane
FROM LOGIN dane;

CREATE USER nielsb
FROM LOGIN nielsb;

ALTER ROLE db_owner
  ADD MEMBER nielsb;
GO

USE master;
GO

GRANT EXECUTE ON sp_execute_external_script TO public;
GO

USE DataScienceDB;
GO

GRANT EXECUTE ANY EXTERNAL SCRIPT TO dane;
GRANT EXECUTE ANY EXTERNAL SCRIPT TO nielsb;
GO

USE DataScienceDB;
GO
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Create Logins, Database and Users</em></p>

<p>In <em>Code Snippet 3</em> we create some logins as well as a database and in that database users for the logins. As you see, we do continue with the &ldquo;theme&rdquo; of Dane the data scientist wanting to do &ldquo;stuff&rdquo; in the database. As <code>nielsb</code> is seen to be &ldquo;trustworthy&rdquo; (take that Dane), we add him to the <code>db_owner</code> role.</p>

<p>In the last part of <em>Code Snippet 3</em> we assign some permissions to <code>sp_execute_external_script</code>, as we did in the post <a href="/2018/06/24/sp_execute_external_script-and-permissions/">sp_execute_external_script and Permissions</a>.</p>

<p>Oh, and if you want to follow along, ensure you download the <code>randomForest</code> package from <a href="https://cran.r-project.org/bin/windows/contrib/3.6/randomForest_4.6-14.zip">here</a>.</p>

<h2 id="permissions">Permissions</h2>

<p>Let us look at what permissions we need when creating an external library. Here is what we do:</p>

<ul>
<li>Log on to SQL Server and the <code>DataScienceDB</code> database as <code>sa</code>.</li>
<li>Drop the <code>randomForest</code> external library if you have created it: <code>DROP EXTERNAL LIBRARY randomForest</code>.</li>
<li>Restart the <em>Launchpad</em> service, this is to clean up properly.</li>
</ul>

<p>After we restart the <em>Launchpad</em> service we want to create an external library as the user <code>dane</code>:</p>

<pre><code class="language-sql">EXECUTE AS USER = 'dane';

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R');
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Creating External Library as Dane</em></p>

<p>In <em>Code Snippet 4</em> we see how we emulate being logged in as user <code>dane</code>: <code>EXECUTE AS USER = 'dane'</code> and how we then execute. Unfortunately, when we run the code we get an error:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_perm_error1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Permission Error</em></p>

<p>In <em>Figure 1</em> we see that <code>dane</code> does not have permission to <code>CREATE EXTERNAL LIBRARY</code>. We can fix that quickly:</p>

<pre><code class="language-sql">REVERT

GRANT CREATE EXTERNAL LIBRARY TO Dane;

EXECUTE AS USER = 'dane';

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R');
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Grant Permissions</em></p>

<p>In <em>Code Snippet 5</em> we:</p>

<ul>
<li><code>REVERT</code> back from the <code>dane</code> user to <code>sa</code>.</li>
<li><code>GRANT</code> permissions to <code>dane</code> to create external libraries.</li>
<li>Switch back to <code>dane</code>.</li>
<li>Execute as <code>dane</code>.</li>
</ul>

<p>However, when we execute as <code>dane</code> we get another error:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_perm_error2.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Impersonation Error</em></p>

<p>We have moved past the permission error, as we in <em>Figure 2</em> see that we do not get the permission error, but we get another error, something about impersonation. What is this about, can it be related to what roles <code>dane</code> is in (remember he is only part of <code>PUBLIC</code>)? Let us test that theory, and let us use <code>nielsb</code> who is more trusted than <code>dane</code>, and is part of <code>db_owner</code>.</p>

<p>So what we do is we copy the code in <em>Code Snippet 5</em>, but replace <code>EXECUTE AS USER = 'dane'</code> with <code>EXECUTE AS USER = 'nielsb'</code>. The assumption is that being part of <code>db_owner</code> should fix this, but when <code>nielsb</code> executes he gets the same error as in <em>Figure 2</em>.</p>

<blockquote>
<p><strong>NOTE:</strong> Notice that we did not have to give <code>nielsb</code> explicit permissions to create external libraries. He has those permissions implicitly just by being part of the <code>db_owner</code> role.</p>
</blockquote>

<p>The problem we run into here is that even if you have the correct permissions to create an external library, you do not have the correct permissions to execute something that reads from the file system. So how do we solve this, we have two options:</p>

<ol>
<li>Add the user to the <code>sysadmin</code> server role.</li>
<li>Create the external library from the package hex-literal.</li>
</ol>

<p>Option 1 is quick and dirty, but I would not recommend it (<code>dane</code> as <code>sysadmin</code>???!!!). Option 2 is better and seeing that you most likely use hex-literal anyway when you deploy to a remote SQL Server it makes sense.</p>

<p>So if you want to follow along in this post, I recommend you go and read up on, in <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a>, how to generate a hex literal from an R Package. We continue when you are back.</p>

<p>Welcome back!</p>

<p>After having read the <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">post</a> above we now have a hex-literal for the <code>randomForest</code> package. Let <code>dane</code> use that to create an external library from:</p>

<pre><code class="language-sql">REVERT

EXECUTE AS USER = 'dane';

DECLARE @hexLit varbinary(max) = 
0x504B03040A00000000009982964C0000000000000000000000000D00000072...
4154494f4e95514d6f83300c3d0f89ff60e504520b1dbd4c953854d5a61dda1e...
...

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = @hexLit)
WITH (LANGUAGE = 'R');
GO

SELECT * FROM sys.external_libraries
</code></pre>

<p><strong>Code Snippet 6:</strong>  <em>Create External Library from Hex Literal Variable</em></p>

<p>In <em>Code Snippet 6</em> we see how we:</p>

<ul>
<li>Emulate <code>dane</code>.</li>
<li>Assign the hex-literal value to the variable.</li>
<li>Call <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ul>

<p>All works OK, but the last <code>SELECT</code> does not return anything. Did we silently fail? Let us try to find out:</p>

<pre><code class="language-sql">REVERT

SELECT * FROM sys.external_libraries
</code></pre>

<p><strong>Code Snippet 7:</strong>  <em>Retrieving External Libraries as sa</em></p>

<p>We see in <em>Code Snippet 7</em> how:</p>

<ul>
<li>We<code>REVERT</code> back to <code>sa.</code></li>
<li>We do a <code>SELECT</code> against <code>sys.external_libraries</code>.</li>
</ul>

<p>When we run the code, the result is like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_view_libs1.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Result of Selecting as sa</em></p>

<p>Aha, <em>Figure 3</em> shows us that <code>dane</code> managed to create the external library, cool! If we now want to drop the library, only <code>dane</code> can do that, and he needs to have <code>ALTER EXTERNAL LIBRARY</code> permissions. We discuss more why <code>dane</code> is the only one that can drop the library later in this post, together with why I have outlined three of the columns in <em>Figure 3</em>.</p>

<blockquote>
<p><strong>NOTE:</strong> The reason <code>dane</code> does not get any results when he tries to <code>SELECT</code> against <code>sys.external_libraries</code> is because of a bug in SQL Server 2017. That particular bug is fixed in CU2, so it should not be an issue.</p>
</blockquote>

<h4 id="permissions-summary">Permissions Summary</h4>

<p>Let us do a quick summary of what we have discussed so far:</p>

<ul>
<li>To create an external library from a hex-literal you need to be part of the <code>db_owner</code> role, or have explicit <code>CREATE EXTERNAL LIBRARY</code> permissions.</li>
<li>To create an external library from a file path you need to be part of the <code>sysadmin</code> server role.</li>
</ul>

<h2 id="authorization-ownership">Authorization &amp; Ownership</h2>

<p>Now, when <code>dane</code> has created an external library let us just check that <code>dane</code> actually can use it:</p>

<pre><code class="language-sql">REVERT

EXECUTE AS USER = 'dane';

EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'library(&quot;randomForest&quot;)'
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Execute as dane Using External Library</em></p>

<p>When we run the code in <em>Code Snippet 8</em> it all works! Let us now see what happens when <code>sa</code> tries to execute:</p>

<pre><code class="language-sql">REVERT

EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'library(&quot;randomForest&quot;)'
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Execute as sa Using External Library</em></p>

<p>We see in <em>Code Snippet 9</em> how we <code>REVERT</code> back to <code>sa</code>, (as that was what we logged in as), and we then call <code>sp_execute_external_script</code>. However, when we execute, the result is:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_exec_error1.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Error When Executing as sa</em></p>

<p>That is strange, the error we see in <em>Figure 4</em> says that the <code>randomForest</code> package does not exist, even though <em>Figure 3</em> shows it. The reason for this can be explained by looking at <em>Figure 3</em> more closely, and especially the three outlined columns: <code>principal_id</code>, <code>scope</code>, and <code>scope_desc</code>.</p>

<p>We see in <em>Figure 3</em> how the <code>principal_id</code> column, (outlined in red), has a value of 5, which happens to be the database principal id of <code>dane</code>. When you create an external library, and you do not specifically set a value for <code>owner_name</code> you become the owner. So what about the two columns outlined in yellow; <code>scope</code>, and <code>scope_desc</code>. They define who can use the library, and any library with an owner other than <code>dbo</code> is private, which means that only the owner can use it. So that explains, (from above), why only <code>dane</code> can drop the library.</p>

<p>So what about <code>nielsb</code>, he is part of the <code>db_owner</code> role, what happens when he creates an external library? Well, do what we did in <em>Code Snippet 6</em>, but replace <code>EXECUTE AS USER = 'dane'</code> with <code>EXECUTE AS USER = 'nielsb'</code>, and run the code. Since <code>nielsb</code> is part of <code>db_owner</code> the <code>SELECT</code> statement works and returns this:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_view_libs2.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Multiple Libraries - I</em></p>

<p>We now have two <code>randomForest</code> libraries, as we see in <em>Figure 5</em>, and these two libraries have different owners as we see from the <code>principal_id</code> (5 for <code>dane</code>, and 6 for <code>nielsb</code>). They are both <code>PRIVATE</code> in scope, so only <code>dane</code> can use the external library with an id of 1, and <code>nielsb</code> only the library with an id of 2. If <code>sa</code> tried to run the code in <em>Code Snippet 9</em> it would fail as in <em>Figure 4</em>.</p>

<p>The above makes sense, kind of. The question is why the library <code>nielsb</code> created is <code>PRIVATE</code> as <code>nielsb</code> belongs to the <code>db_owner</code> role? The answer is what I wrote above, about not setting a value for <code>owner_name</code>. As <code>nielsb</code> did not indicate an owner name, he became the owner, and any libraries not owned by the <code>dbo</code> principal is always <code>PRIVATE</code>. However, seeing that <code>nielsb</code> is in the <code>db_owner</code> role, he can run some code like this:</p>

<pre><code class="language-sql">REVERT

EXECUTE AS USER = 'nielsb';

DECLARE @hexLit varbinary(max) = 
0x504B03040A00000000009982964C0000000000000000000000000D00000072...
4154494f4e95514d6f83300c3d0f89ff60e504520b1dbd4c953854d5a61dda1e...
...

CREATE EXTERNAL LIBRARY randomForest
AUTHORIZATION dbo
FROM (CONTENT = @hexLit)
WITH (LANGUAGE = 'R');
GO

SELECT * FROM sys.external_libraries
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Create External Library with dbo as Owner</em></p>

<p>In <em>Code Snippet 10</em> we see how we set the <code>owner_name</code> to <code>dbo</code>, and when we run the code the result of the <code>SELECT</code> is like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_view_libs3.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>Multiple Libraries - II</em></p>

<p>We see <em>Figure 6</em> 3 libraries and the last one has a <code>principal_id</code> of 1 (<code>dbo</code>), and the scope is <code>PUBLIC</code>. If you want to you can <code>REVERT</code> back to <code>sa</code> and execute the code in <em>Code Snippet 9</em>. This time it works, as one of the <code>randomForest</code> libraries are <code>PUBLIC</code>.</p>

<blockquote>
<p><strong>NOTE:</strong> No, <code>dane</code> cannot set the <code>owner_name</code> to <code>dbo</code> as he does not have sufficient privileges, (he is not part of <code>db_owner</code>).</p>
</blockquote>

<p>We have now three different libraries with the same name, how does the engine know what library to load, and from where? That is a good question, let us run some code we used in the <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">previous post</a>:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'
                    OutputDataSet &lt;- data.frame(
                    installed.packages()[,c(&quot;Package&quot;, &quot;LibPath&quot;)]);'
WITH RESULT SETS ((Package nvarchar(255), LibPath nvarchar(2000)));
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>View R Packages</em></p>

<p>The code in <em>Code Snippet 11</em> retrieves installed R packages, and if we run the code as <code>sa</code> we get the following result:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_lib_path1.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>Randomforest Library Path for sa</em></p>

<p>What is interesting in <em>Figure 7</em> is that we only see one <code>randomForest</code> library, whereas if we execute the same code as <code>dane</code> we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_lib_path2.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Randomforest Library Path for dane</em></p>

<p>When we look at <em>Figure 8</em> we see two different library paths (where the package is) for the two <code>randomForest</code> packages. We see how they differ based on database id, (5 in both cases), and principal id, where the first one has a principal id of 5, (<code>dane</code>), and the second 1, (<code>dbo</code>). What we have seen here explains the error we saw in <em>Figure 4</em> when we tried to execute as <code>sa</code> - the package was not available to <code>sa</code>. We can also assume that packages load based on principal id, and the resolution logic and order is like so:</p>

<ol>
<li>Load a package which matches on name and principal id.</li>
<li>Load a package which matches on name and is public.</li>
<li>Load a package which matches on name and is located in the default library path.</li>
</ol>

<h2 id="summary">Summary</h2>

<p>In this post, we looked at permissions required when creating external libraries, and also ownership of the libraries.</p>

<p>To create an external library, you need to have explicit <code>CREATE EXTERNAL LIBRARY</code> permissions, or be - at least - part of the <code>db_owner</code> role. If you want to create a library based on a package path, instead of a hex-literal, you need to also to be in the <code>sysadmin</code> server role.</p>

<p>When you create an external library the library is owned by you, and can only be used by you - it is <code>PRIVATE</code>. However, if you set the <code>owner_name</code> to <code>dbo</code>, the library is <code>PUBLIC</code> and can be used by any user.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 15, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/14/interesting-stuff---week-15-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-14T18:24:53+02:00</updated>
    <id>http://nielsberglund.com/2019/04/14/interesting-stuff---week-15-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/steeltoe-pcf">Enabling .NET Apps with Monitoring and Management Using Steeltoe</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation discussing using the Steeltoe Management framework to enable a .NET application with performance monitoring, management diagnostic endpoints, and distributed tracing on PCF.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="http://highscalability.com/blog/2019/4/8/from-bare-metal-to-kubernetes.html">From Bare-Metal To Kubernetes</a>. A very interesting blog post which talks about going from a bare metal infrastructure to a highly scalable Kubernets infrastructure running in the cloud. If you are thinking about moving to Kubernetes, the post is well worth a read.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="http://muratbuffalo.blogspot.com/2019/04/azure-cosmos-db-microsofts-cloud-born.html">Azure Cosmos DB: Microsoft&rsquo;s Cloud-Born Globally Distributed Database</a>. An excellent blog post by <a href="https://twitter.com/muratdemirbas">Murat</a> where he discusses the workings of Azure Cosmos DB. This post is a must read if you are interested in the inner workings of Cosmos DB.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/monitoring-data-replication-in-multi-datacenter-apache-kafka-deployments">Monitoring Data Replication in Multi-Datacenter Apache Kafka Deployments</a>. A blog post which describes how to use Confluent Replicator and Confluent Control Center to monitor Kafka deployment and replication between multiple data centers.</li>
</ul>

<h2 id="sql-server-machine-learning-services">SQL Server Machine Learning Services</h2>

<ul>
<li><a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a>. Six months after I posted the <a href="/2018/06/30/installing-r-packages-in-sql-server-machine-learning-services---ii/">second post</a> in the <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series I posted the third &ldquo;episode&rdquo;. In this post, we look at how to install R packages in SQL Server Machine Learning Services using the T-SQL DDL command <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing R Packages in SQL Server Machine Learning Services - III]]></title>
    <link href="http://nielsberglund.com/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/" rel="alternate" type="text/html"/>
    <updated>2019-04-10T06:36:16+02:00</updated>
    <id>http://nielsberglund.com/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/</id>
    <content type="html"><![CDATA[<p>This post is the third in a series about installing R packages in <strong>SQL Server Machine Learning Services</strong> (SQL Server ML Services). To see all posts in the series go to <a href="/sql_server_ml_services_install_packages"><strong>Install R Packages in SQL Server ML Services Series</strong></a>.</p>

<p>Why this series came about is a colleague of mine <a href="https://www.linkedin.com/in/dane-bax/">Dane</a> pinged me and asked if I had any advice as he had issues installing an R package into one of their SQL Server instances. I tried to help him and then thought it would make a good topic for a blog post. Of course, at that time I didn&rsquo;t think it would be more posts than one, but here we are.</p>

<p>In this post, we look at how we can use T-SQL and DDL commands to install packages in a remote SQL Server.</p>

<p></p>

<p>Let us do a recap to see where we are.</p>

<h2 id="recap">Recap</h2>

<p>The first <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">post</a> in the series gave an overview of what ways we can install packages in the external R engine in SQL Server ML Services:</p>

<ul>
<li>R packet managers</li>
<li>T-SQL</li>
<li>RevoScaleR</li>
</ul>

<p>The <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">post</a> then went into details about using R packet managers, where an R packet manager is an R command line tool or GUI installed on the SQL Server Machine Learning Services machine. The packet manager should be run with elevated permissions and target the R engine for the instance on which you want to install the package. The easiest is to use either of the R tools that come as part of SQL Server&rsquo;s R service:</p>

<ul>
<li>The command line tool: <code>Rterm.exe</code>.</li>
<li>The GUI: <code>Rgui.exe</code>.</li>
</ul>

<p>These two packet managers live in the <code>\\&lt;path_to_SQL_Server_instance&gt;\R_SERVICES\bin\x64</code> directory. When you install packages via an R packet manager, they can only be installed to the default packet library for that instance. You find the library at: <code>\\&lt;path_to_SQL_Server_instance&gt;\R_SERVICES\library</code>.  The file system folder for this library has restricted access and you need elevated permissions to write to this folder. Typical code for installing packages from a packet manager can look like so:</p>

<pre><code class="language-r"># set the library path
libPath &lt;- C:\\path_to_SQL_Server_instance&gt;\\R_SERVICES\\library
install.packages(&quot;pkg_name&quot;, lib = libPath, 
                  repos = &quot;url_for_the_repo&quot;, 
                  dependencies = TRUE)
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Install Packages Command</em></p>

<p>In <em>Code Snippet 1</em> we use <code>install.packages</code> to install &ldquo;pkg_name&rdquo; to a hardcoded library path.</p>

<p>Using an R Package manager is the most straight forward way to install R packages, but the downside with it is that you need admin rights on the SQL Server box. Having admin rights on a SQL Server box in production can be an issue, and in <a href="/2018/06/30/installing-r-packages-in-sql-server-machine-learning-services---ii/">Installing R Packages in SQL Server Machine Learning Services - II</a> we looked at how we can install packages without having admin rights, by using RevoScaleR:</p>

<ul>
<li>To use RevoScaleR for package installation both the SQL Server instance as well as the database need to be enabled for package management. You enable package management via <code>RegisterRExt.exe</code> tool and the <code>/installpkgmgmt</code> option. There are additional flags for database enabling, authentication and so forth.</li>
<li>When enabling the database the process creates a table, stored procedures and roles.</li>
<li>For a user to be able to install packages he needs to have necessary permissions on <code>sp_execute_external_script</code> as well as the <code>EXECUTE ANY EXTERNAL SCRIPT</code> permission. He also needs to be in a role which allows him to install packages.</li>
<li>The roles that the enabling process creates are: <code>rpkgs-users</code>, <code>rpkgs-private</code> and <code>rpkgs-shared</code>.</li>
<li>The roles which allow the user to install packages are <code>rpkgs-private</code> and <code>rpkgs-shared</code> (and <code>db_owner</code>).</li>
<li>The roles define the scope of the installed packages: <code>private</code> and <code>shared</code>.</li>
<li>When a user installs a package with <code>private</code> scope, only he can see and use the package.</li>
<li>If the user installs a package with <code>shared</code> scope, all users in any of the roles, including <code>rpkgs-users</code> can use that package. The user needs to be in the <code>rpkgs-shared</code> (or <code>db_owner</code>) to install a <code>shared</code> package.</li>
<li>You use the function <code>rxInstallPackages</code> to install a package, and the function needs to run in an <em>SQLCC</em>.</li>
<li>When the user calls <code>rxInstallPackages</code> he needs to define which scope the package has through the <code>scope</code> argument. If the <code>scope</code> is not defined, it defaults to <code>private</code>.</li>
<li>To use a package, either in <code>private</code> or <code>shared</code> scope, the code needs to run in <em>SQLCC</em>.</li>
<li>For a package that does not know <em>SQLCC</em>, the functions in the package can be run via <code>rxExec</code>.</li>
</ul>

<h2 id="housekeeping">Housekeeping</h2>

<p>Before we &ldquo;dive&rdquo; into today&rsquo;s topics let us look at the code we use today. This section is here for those of you who want to follow along in what we are doing in the post.</p>

<pre><code class="language-sql">USE master;
GO

DROP DATABASE IF EXISTS DataScienceDB;
GO

DROP DATABASE IF EXISTS DataScienceDBRemote;
GO

CREATE DATABASE DataScienceDB;
GO

CREATE DATABASE DataScienceDBRemote;
GO
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create Databases</em></p>

<p>In <em>Code Snippet 2</em> we create two databases; <code>DataScienceDB</code> and <code>DataScienceDBRemote</code> where the latter is to emulate a database on a remote SQL Server instance. In previous posts, we have created logins and users, but in this post, we only log in as <code>sa</code>.</p>

<h2 id="installing-r-packages-using-t-sql">Installing R Packages Using T-SQL</h2>

<p>In the <em>Recap</em> above we said that in previous posts we have looked at installing R packages either by using R package managers on the SQL Server box, or doing it remotely via script using RevoScaleR. The third option we have is to do it via a T-SQL statement. More specifically through a statement introduced in SQL Server 2017: <code>CREATE EXTERNAL LIBRARY</code>.</p>

<blockquote>
<p><strong>NOTE:</strong> In SQL Server 2017 only R packages are supported whereas, in SQL Server 2019 R, Python and Java are supported. For both SQL Server 2017 and 2019 (up to and including CTP 2.3) only the Windows platform is supported. For SQL Server 2019, Linux may be added as a supported platform in later CTP releases.</p>
</blockquote>

<p>What <code>CREATE EXTERNAL LIBRARY</code> does is it uploads package files to a database from a file path or byte stream. The signature looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM (CONTENT = { &lt;file_spec&gt; }  
    [, PLATFORM = &lt;platform&gt; ]) 
WITH ( LANGUAGE = '&lt;language&gt;' )  
[ ; ] 
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Signature CREATE EXTERNAL LIBARY</em></p>

<p>The arguments we see in <em>Code Snippet 3</em> are:</p>

<ul>
<li><code>library_name</code>: A unique name for the package. When we create an external library for an R package, the name has to be the actual package name. While this may seem obvious, I mention it as when you create external libraries for Java code the name does not matter. We discussed this in the <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a> post. When I say the package name has to be unique, the unique:ness is based on the name and the principal id under which it is created. We talk more about that in a future post.</li>
<li><code>owner_name</code>: This optional parameter specifies the name of the user or role that owns the external library. More about this in a future post as well.</li>
<li><code>file_spec</code>: The <code>file_spec</code> specifies the content of the package for a specific platform, and it can either be in the form of a file location (local path/network path) or a hex literal. If we want to install an R package from a file location, the package needs to be in the form of a zipped archive file. If we install based on a hex-literal, the hex-literal need to derive from the package zip file.</li>
<li><code>platform</code>: The <code>PLATFORM</code> parameter, which defines the platform for the content of the library. The <code>PLATFORM</code> parameter defaults to the platform on which SQL Server runs on, and since <code>CREATE EXTERNAL LIBRARY</code> is only supported on Windows, for now, we do not set it.</li>
<li><code>language</code>: Specifies the language of the package. For this post we only deal with <code>R</code>, and - as I mentioned above - in SQL Server 2017, R is the only language supported.</li>
</ul>

<h2 id="using-create-external-library">Using CREATE EXTERNAL LIBRARY</h2>

<p>To see how to use <code>CREATE EXTERNAL LIBRARY</code> we want to install the <code>randomForest</code> package into our <code>DataScienceDB</code> database. We start with downloading the <code>randomForest</code> zip archive to a directory which is readable by SQL Server. I have it at <code>W:\randomForest_4.6-14.zip</code>. We log in to the server and database as <code>dbo</code> (<code>sa</code> login), and we are ready to execute the <code>CREATE EXTERNAL LIBRARY</code> DDL:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R'); 
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create External Library</em></p>

<p>As we see in <em>Code Snippet 4</em> I name the external library <code>randomForest</code>, as that is the name of the R package, and I set the location of where the package <code>zip</code> file is. Before we execute the code in <em>Code Snippet 4</em>, let us look at what R packages we have installed already:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'
                    OutputDataSet &lt;- data.frame(
                    installed.packages()[,c(&quot;Package&quot;, &quot;LibPath&quot;)]);'
WITH RESULT SETS ((Package nvarchar(255), LibPath nvarchar(2000)));
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>View R Packages</em></p>

<p>When we execute the code in <em>Code Snippet 5</em> we see something like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_inst_pkgs.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>View Installed R Packages - I</em></p>

<p>In <em>Figure 1</em> we see some of the installed R packages and notice that we do not see randomForest. Also, notice the <code>LibPath</code> column outlined in red. Remember how I mentioned in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a> how, when using SQL Server ML Services, we install packages to a specific library which SQL Server then loads the packages from. That location is the <code>LibPath</code> in <em>Figure 1</em>.</p>

<blockquote>
<p><strong>NOTE:</strong> As we see later in this post, what I said above about only one location is not entirely true.</p>
</blockquote>

<p>The last thing to do before we execute the code in <em>Code Snippet 4</em> is to browse around in <em>File Explorer</em> and look at a directory under <code>C:\&lt;path_to_SQL_instance&gt;\MSSQL</code>. When we look around we see a directory named <code>ExternalLibraries</code>, and when we &ldquo;drill&rdquo; into it we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib1.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>ExternalLibraries Directory</em></p>

<p>Hmm, what is so interesting with this directory we see in <em>Figure 2</em>, it has a subdirectory named <code>R</code>, but otherwise, it is empty? Well, the name is interesting: <code>ExternalLibraries</code>. I wonder if it has anything to do with creating external libraries? So to find out we execute the code in <em>Code Snippet 4</em>.</p>

<p>Strange, after we execute the code in <em>Code Snippet 4</em> nothing changes in the directories we look at. Are we wrong in our assumptions about the directories, or did the code fail? In either case, how can we find out?</p>

<p>Creating an external library is very similar to creating an SQLCLR assembly, and if you have ever created an SQLCLR assembly you are probably aware of a couple of catalog views that gives us information about the assemblies:</p>

<ul>
<li><code>sys.assemblies</code>: base catalog view for assemblies with one row per assembly created in the database.</li>
<li><code>sys.assembly_files</code>: contains the binary representation of the assembly files.</li>
</ul>

<p>For external libraries we have similar catalog views:</p>

<ul>
<li><code>sys.external_libraries</code>: base catalog view for external libraries with one row per external library created in the database.</li>
<li><code>sys.external_library_files</code>: contains the binary representation of the external library files.</li>
</ul>

<p>So, if we successfully created the external library we <em>should</em> see something in <code>sys.external_libraries</code>:</p>

<pre><code class="language-sql">SELECT * 
FROM sys.external_libraries;
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>View External Libraries</em></p>

<p>When we execute the code in <em>Code Snippet 6</em> we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Installed External Library</em></p>

<p>Yes, when we look at <em>Figure 3</em> we see that we have created an external library. The columns we see represents:</p>

<ul>
<li><code>external_library_id</code>: the id of the external library as assigned by the database.</li>
<li><code>name</code>: name given to it during creation.</li>
<li><code>principal_id</code>: id of the owner, (principal), of the library.</li>
<li><code>language</code>: name of the language of the library. As mentioned before; in SQL Server 2017, only R, in SQL Server 2019; R, Python, and/or Java.</li>
<li><code>scope</code>: defines who can access the library, 0 for <code>PUBLIC</code>, 1 for <code>PRIVATE</code>. More about that in a.</li>
<li><code>scope_desc</code>: literal description of the scope.</li>
</ul>

<p>Let us see if we can use it the external library:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'library(&quot;randomForest&quot;)'
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Load R Package</em></p>

<p>Admittedly the code in <em>Code Snippet 6</em> does not accomplish much, but when we execute it we can tell whether we have succeeded in creating the external library:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib2.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Execute randomForest</em></p>

<p>From what is outlined in red in <em>Figure 4</em> we see that we have successfully executed against the <code>randomForest</code> package. We also see how external libraries only get loaded and &ldquo;properly&rdquo; installed at first use (blue outline). Cool, so that worked. What about the <code>ExternalLibraries</code> directory:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib3.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>ExternalLibraries after First Execution</em></p>

<p>So, our assumption above regarding <code>ExternalLibraries</code> were correct; the directory contains the actual packages for the external libraries we create. We see in <em>Figure 5</em> how there are new directories, and how we have a <code>randomForest</code> directory which contains the <code>randomForest</code> package.</p>

<blockquote>
<p><strong>NOTE:</strong> The number 5 in <em>Figure 5</em> refers to the database id, and the number 1 beneath the 5 is the id of the external library (<code>external_library_id</code>). So the databases have their own top-level directory, named after the database id. Underneath the database id directory is the individual external library directories identified by the external library id.</p>
</blockquote>

<p>When we execute the code in <em>Code Snippet 5</em> we get:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib4.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>View Installed R Packages - II</em></p>

<p>We now see in <em>Figure 6</em> how the <code>randomForest</code> package comes up as an installed packet (outlined in red), and we see the installation path (highlighted in yellow), and this is where it loads from. So what I said in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a> about SQL only loads packages from one directory is not entirely true, SQL Server can load packages from different locations.</p>

<p>What we have seen so far looks quite good, but the problem is similar to what we discussed in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a>:</p>

<ul>
<li>In the post we said we needed elevated access to the box where the SQL Server instance is.</li>
<li>Here we need access to a directory to which we can copy the package(s) we want to create the external library(s) from, and SQL Server needs read access to that directory. This directory is most likely on the SQL Server server, so we still have the same problem as before.</li>
</ul>

<p>Fortunately, there is a way to solve this. Remember how we said above that the <code>file_spec</code> parameter which, up until now, has been a file path, also can be a hex-literal.</p>

<h2 id="hex-literal-create-external-library">Hex Literal &amp; CREATE EXTERNAL LIBRARY</h2>

<p>The question is then how do I get the hex-literal for a package?</p>

<blockquote>
<p><strong>NOTE:</strong> What follows related to hex literal is more or less a copy from my post <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a>.</p>
</blockquote>

<p>The hex-literal is the actual binary representation of the package, so let us look at a couple of ways we can get hold of the binary package representation:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-database">Local Database</h4>

<p>We know (from above) that the catalog view <code>sys.external_library_files</code> contains the binary representation of the package, and we see that using a query like so:</p>

<pre><code class="language-sql">SELECT l.external_library_id, l.name, lf.content
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest'
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>View External Library</em></p>

<p>In <em>Code Snippet 7</em> we <code>SELECT</code> out the library id, name from the <code>sys.external_libraries</code> view, and <code>content</code> from <code>sys.external_library_files</code>. When we run the code the result looks like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib_content1.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>Binary Representation</em></p>

<p>What we see highlighted in <em>Figure 7</em> is the <code>content</code> column, and we see it contains the hex-literal for the <code>randomForest</code> package.</p>

<p>So if we want to create an external library on a remote SQL Server on which we do not have access to the file system, but we have access to a local SQL Server, we can do this:</p>

<ul>
<li>Create an external library in a database on the local machine, like in <em>Code Snippet 4</em>.</li>
<li>Get the hex-literal from the <code>content</code> column and save it.</li>
</ul>

<p>The naive way, (what I did initially), to get the hex-literal is to use code like this:</p>

<pre><code class="language-sql">DECLARE @hexLit varbinary(max);

SELECT @hexLit = lf.content
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest' 

PRINT @hexLit;
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Get the Hex Literal</em></p>

<p>To get the hex-literal, we see in <em>Code Snippet 8</em> how we:</p>

<ul>
<li>Declare a <code>varbinary(max)</code> variable into which we <code>SELECT</code> the <code>content</code> column.</li>
<li>Print that variable so we can use it.</li>
</ul>

<p>When we execute the code, it looks like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib_hexlit.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Selecting out Hex Literal</em></p>

<p>In <em>Figure 8</em> we see part of the hex literal. However, I mentioned above that what we see in <em>Code Snippet 8</em> is a naive way to do it, and - in most cases - it does not work. Sure you get something that looks like your hex-literal, but if you compare the size of the printed output of the variable, with the size of the value in the column, you see how the size in the column is much bigger. This is because when you do a <code>PRINT</code> either in SSMS or Azure Data Studio the output is limited to a max size of 8000.</p>

<blockquote>
<p><strong>NOTE:</strong> In the <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a> post I used the method above, and it worked. The reason was that the <code>.jar</code> file I wanted to create an external library from, had a size of ~1.5k.</p>
</blockquote>

<p>So what do we do if we want to capture the value of the variable? Well, by using some xml &ldquo;magic&rdquo; we can achieve what we want:</p>

<pre><code class="language-sql">SELECT CONVERT(varchar(max), lf.content, 1)
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest'
FOR XML PATH('');
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Output as XML</em></p>

<p>We see that the code in <em>Code Snippet 9</em> is not that much different from <em>Code Snippet 8</em>. Instead of selecting the <code>content</code> column value into a variable which we <code>PRINT</code>, we <code>CONVERT</code> the binary value to <code>varchar(max)</code> and then indicate we want it exposed as xml (<code>FOR XML PATH('')</code>). When we execute the result is like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_hexlit_xml.png" alt="" /></p>

<p><strong>Figure 9:</strong> <em>Hex Literal XML</em></p>

<p>When you see <em>Figure 9</em> you may ask what the difference is from what we have seen before? When we copy out the content of the column, will we not get just a part of the full value? The answer to that is yes, however, as the column data type is xml, and if we click on it we see something different:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_hexlit_aml_output.png" alt="" /></p>

<p><strong>Figure 10:</strong> <em>XML Output</em></p>

<p>When we clicked on the column a new file opens, and in that file, we get the full hex-literal value, as we see in <em>Figure 10</em>. We can now use the full hex literal to create the <code>randomForest</code> external library on another SQL Server instance.</p>

<p>In this post I do not have access to a remote SQL Server, so what we do instead is that we emulate doing it; we do it against the second database we created in <em>Code Snippet 2</em>; <code>DataScienceDBRemote</code>. After we ensure we have the full hex literal saved off somewhere we:</p>

<ul>
<li>Switch over to <code>DataScienceDBRemote</code> (as <code>sa</code>).</li>
<li>Open a new query window.</li>
</ul>

<p>In the new query window we declare a new variable, let us call it <code>@hexLit</code>, as a <code>varbinary(max)</code>, and we assign the hex literal from <code>DataScienceDB</code> to the variable:</p>

<pre><code class="language-sql">USE DataScienceDBRemote;
GO

DECLARE @hexLit varbinary(max) = 0x504B03040A00000000009982964...
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Assign Hex Literal Value to Variable</em></p>

<p>When we have declared the variable and assigned the hex-literal value to it, we can use it in <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-sql">USE DataScienceDBRemote;
GO

DECLARE @hexLit varbinary(max) = 
0x504B03040A00000000009982964C0000000000000000000000000D00000072...
...

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = @hexLit)
WITH (LANGUAGE = 'R');
GO

SELECT * FROM sys.external_libraries;
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Create External Library from Hex Literal Variable</em></p>

<p>Finally, we execute the code in <em>Code Snippet 11</em> and the <code>SELECT</code> shows us that we now have an external library named <code>randomForest</code> in the &ldquo;remote&rdquo; database.</p>

<p>So this is one way we can get a binary for a package. It may, however, be somewhat convoluted, so let us look at the second way.</p>

<h4 id="generate-binary-from-code">Generate Binary from Code</h4>

<p>Compared to the above, to get the binary representation based on code is probably somewhat easier, and I decided to use Python to create a script which writes the package binary to a file:</p>

<pre><code class="language-python">import binascii

packageFile = input(&quot;Provide full path to the R package \ 
                    file you want to use - \
                    Example: 'W:\\randomForest_4.6-14.zip': &quot;)
fileName = input(&quot;Provide name of the file \
                  you want to create to write the binary to: &quot;)

with open(packageFile, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

f = open(fileName, &quot;w+&quot;)
f.write(hex_bytes)
f.close()
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Python Script to Generate File with Hex Literal</em></p>

<p>We see in <em>Code Snippet 12</em> how the script:</p>

<ul>
<li>Asks for what package zip file to use.</li>
<li>What name to give the output file.</li>
<li>Generates the binary.</li>
<li>Saves it into a file.</li>
</ul>

<p>We now take the code in <em>Code Snippet 12</em> and copy it into a Python script file, for example <code>createBinary.py</code>. When we have the Python file we execute from the command prompt like so:</p>

<pre><code class="language-bash">$ python .\createBinary.py
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Run Python Script</em></p>

<p>After we run the script as per <em>Code Snippet 13</em> we open the created file and grab the hex-literal. We now follow the same procedure as we did in <em>Code Snippet 10</em> and <em>Code Snippet 11</em>, without having the package installed as an external library on the local machine.</p>

<p>However, why do copy and paste when we can connect directly from Python to the remote database and execute <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-python">import pyodbc
import binascii

extLibName = input(&quot;Provide a unique name for \
                   the external library you want to create: &quot;)
packageFile = input(&quot;Provide full path to the zip \
                  file you want to use - \
                  Example: 'W:\\randomForest_4.6-14.zip': &quot;)
dbServer = input(&quot;Provide name/ip address of your \
                  database server. If instance also instance name \ 
                  - Example: 'mydbServer\myInstance: &quot;)
dataBase = input(&quot;Provide name of the database where you \
                  want to create the external library: &quot;)
userName = input(&quot;Provide the user name with which you \
                   want to connect to the server: &quot;)
password = input(&quot;Provide password with which to \
                  connect to the database: &quot;)

with open(packageFile, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

drvr = '{ODBC Driver 17 for SQL Server}'
connStr = f'DRIVER={drvr};SERVER={dbServer};DATABASE={dataBase};UID={userName};PWD={password}'
conn = pyodbc.connect(connStr)
cursor = conn.cursor()

execStmt = f'CREATE EXTERNAL LIBRARY {extLibName}\n'
execStmt = execStmt + f'FROM (CONTENT = {hex_bytes})\n'
execStmt = execStmt + f&quot;WITH (LANGUAGE = 'R');\n&quot;

cursor.execute(execStmt)
conn.commit()    
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>Execute Directly Against the Remote Database</em></p>

<p>So, what do we do in <em>Code Snippet 14</em>? Well, we use the same code as in <em>Code Snippet 12</em> to generate the binary representation. However, instead of writing it to a file we connect to the database using the <code>pyodbc</code> module, and the latest SQL Server ODBC driver. The <code>hex_bytes</code> variable is now a parameter in the <code>CREATE EXTERNAL LIBRARY</code> statement. The name of the external library is passed in as a parameter together with database connection details. It is worth noting that the way the script captures the password variable is not particularly secure. Instead of <code>input</code>, we should use <code>getpass</code> or something similar.</p>

<blockquote>
<p><strong>NOTE:</strong> Unless the user with which you connect is part of the <code>db_owner</code> role, the user needs explicit permissions to execute <code>CREATE EXTERNAL LIBRARY</code>. A future post covers permissions for <code>CREATE EXTERNAL LIBRARY</code>.</p>
</blockquote>

<p>To run this, we do as we did in <em>Code Snippet 12</em>; we copy the code into a Python file and run it from the command line. The code should run OK, and we have created an external library in a database in a remote SQL Server (well, in my case an emulated remote SQL Server).</p>

<h2 id="summary">Summary</h2>

<p>In this post, we set out to solve the issue of how to deploy an R package without having access to the filesystem of the SQL Server where we want to deploy the package to.</p>

<p>We have seen two ways of doing it:</p>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create an external library from the R package based on the file path in a local SQL Server where we have access to the filesystem (like <code>localhost</code>).</li>
<li>Get the binary representation from the <code>content</code> column in <code>sys.external_library_files</code> via some XML &ldquo;magic&rdquo;.</li>
<li>Assign the retrieved value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 3 above (local database).</li>
</ol>

<p>Alternatively, you can connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 14, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/07/interesting-stuff---week-14-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-07T19:33:23+02:00</updated>
    <id>http://nielsberglund.com/2019/04/07/interesting-stuff---week-14-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/starling-bank">Building a Reliable Cloud-Based Bank in Java</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation discussing the experience of Starling Bank, a mobile-only, cloud-based bank that launched in the UK in 2017. The presenter looks at the system architecture of the bank, the design principles that give them the ability to release quickly and reliably, and why they decided to build the back end using Java.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><p><a href="https://www.confluent.io/blog/introducing-confluent-platform-5-2">Introducing Confluent Platform 5.2</a>. During the week Confluent announced the release of Confluent Platform 5., and with it some exciting new features:</p>

<ul>
<li>Confluent Platform is free for single node clusters, it is like a developer edition!</li>
<li>The <code>librdkafka</code> library is now in version 1.0. That is interesting as it brings this library closer to parity with the Java client for Kafka.</li>
<li>New and enhanced query expressions in KSQL.</li>
</ul></li>

<li><p><a href="https://www.confluent.io/blog/putting-events-in-their-place-with-dynamic-routing">Putting Events in Their Place with Dynamic Routing</a>. This is a blog post about how Kafka Streams are a powerful way to enrich data streaming through event-driven architectures. We can dynamically route events to topics, even pulling in the output topic information from another end data system.</p></li>

<li><p><a href="https://www.infoq.com/presentations/starling-bank">KSQL: Whatâ€™s New in 5.2</a>. As I mentioned above, there are new features in KSQL 5.2, and in this blog post <a href="https://twitter.com/rmoff">Robin</a> discusses some of them!</p></li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 13, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/31/interesting-stuff---week-13-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-31T08:43:04+02:00</updated>
    <id>http://nielsberglund.com/2019/03/31/interesting-stuff---week-13-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://blog.acolyer.org/2019/03/29/calvin-fast-distributed-transactions-for-partitioned-database-systems/">Calvin: fast distributed transactions for partitioned database systems</a>. In this white-paper dissection by <a href="https://twitter.com/adriancolyer">Adrian</a>, he looks at <a href="https://github.com/yaledb/calvin">Calvin</a> which is a transaction scheduling and data replication layer that uses a deterministic ordering guarantee to reduce the high contention costs associated with distributed transactions significantly.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/27/sql-server-2019-community-technology-preview-2-4-is-now-available/">SQL Server 2019 community technology preview 2.4 is now available</a>. What the title says. I downloaded the CTP a couple of days ago, and when I am done with this post, I will install it. Oh, word of warning - if you want to install the <strong>SQL Server 2019 Big Data Cluster</strong>, please remember to uninstall and reinstall <code>mssqlctl</code>, so you get the latest version.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/importance-of-distributed-tracing-for-apache-kafka-based-applications">The Importance of Distributed Tracing for Apache-Kafka-Based Applications</a>. This blog post looks at how to instrument Kafka-based applications with distributed tracing capabilities to make dataflows between event-based components more visible. Very interesting!</li>
<li><a href="https://www.confluent.io/blog/consuming-messages-out-of-apache-kafka-in-a-browser/2">Consuming Messages Out of Apache Kafka in a Browser</a>. The post covers what the title says; how to consume Kafka messages in a browser.</li>
<li><a href="https://rmoff.net/2019/03/28/exploring-ksql-stream-stream-joins/">Exploring KSQL Stream-Stream Joins</a>. This is an excellent post by <a href="https://twitter.com/rmoff">Robin</a> where he covers KSQL and stream to stream joins! I need to go off and <del>play with</del> research this now!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (<em>What Is Niels Doing</em>)</h2>

<p>I am still working on the post about <code>CREATE EXTERNAL LIBRARY</code> in the <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series. Expect it towards the end of this coming week.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 12, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/24/interesting-stuff---week-12-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-24T08:37:01+02:00</updated>
    <id>http://nielsberglund.com/2019/03/24/interesting-stuff---week-12-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/csharp-testing-strategy-tools">Unit Testing Strategies &amp; Patterns in C#</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses design principles and ways to make C# code testable, as well as using testing tools such as Moq, Autofixture, &amp; MsTest.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://medium.com/google-cloud/istio-routing-basics-14feab3c040e">Istio Routing Basics</a>. So, <a href="https://cloud.google.com/istio/">Istio</a> is an open source service mesh, and this blog post covers the basics of Istio and shows what it takes to build an Istio enabled &ldquo;Hello World&rdquo; application.</li>
<li><a href="https://medium.com/@masroor.hasan/tracing-infrastructure-with-jaeger-on-kubernetes-6800132a677">Distributed Tracing Infrastructure with Jaeger on Kubernetes</a>. The blog post I link to here looks at distributed tracing on Kubernetes using Jaeger.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/18/the-march-release-of-azure-data-studio-is-now-available/">The March release of Azure Data Studio is now available</a>. What the title says! There are quite a few new features in the March release of Azure Data Studio, among them: support for SQL Notebooks, PowerShell extension, and PostgresSQL support. Go and get it!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-streams-take-on-watermarks-and-triggers">Kafka Streamsâ€™ Take on Watermarks and Triggers</a>. This blog post discusses a new Kafka Streams operator: <code>Suppress</code>. It gives you the ability to control when to forward KTable updates. The <code>Suppress</code> operator comes in very handy in various CEP scenarios: &ldquo;tell me when someone has done &ldquo;a&rdquo; more than &ldquo;x&rdquo; times within &ldquo;y&rdquo; time period&rdquo;. What normally happens is that if someone achieves the &ldquo;a&rdquo;, &ldquo;x&rdquo; times within the &ldquo;y&rdquo; time period every following &ldquo;a&rdquo; would trigger as well. With <code>Suppress</code> you - wait for it - suppress the extra &ldquo;a&rdquo;, until the end of the time period.<br /></li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (<em>What Is Niels Doing</em>)</h2>

<p>Since I did the two posts about <code>CREATE EXTERNAL LIBRARY</code> for Java code (<a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">here</a> and <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">here</a>), I thought it would be a good idea to finish off my <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series. So, I am at the moment working on a post discussing <code>CREATE EXTERNAL LIBRARY</code> in the R world. The post is somewhat like the ones covering Java, but it also covers permissions etc.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 11, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/17/interesting-stuff---week-11-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-17T21:16:22+02:00</updated>
    <id>http://nielsberglund.com/2019/03/17/interesting-stuff---week-11-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/net-core-container-images-now-published-to-microsoft-container-registry/">.NET Core Container Images now Published to Microsoft Container Registry</a>. A post discussing how Microsoft are now publishing .NET Core container images to Microsoft Container Registry (MCR).</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/istio-microservices">Reducing Microservices Architecture Complexity with Istio and Kubernetes</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation which introduces Istio, and explains how the service mesh works, the technology behind it, and how to use it with microservices.</li>
<li><a href="https://www.infoq.com/news/2019/03/microservices-recommendations">Recommendations When Starting with Microservices: Ben Sigelman at QCon London</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article about the mistakes Google made in he beginning when adopting a microservices architecture, and recommendations to avoid making these mistakes when starting with microservices.</li>
</ul>

<h2 id="data-science-machine-learning">Data Science / Machine Learning</h2>

<ul>
<li><a href="https://towardsdatascience.com/machine-learning-with-big-data-86bcb39f2f0b">Machine Learning with Big Data</a>. Data is on overdrive. Itâ€™s being generated at break-neck pace. How do we analyze all this data? This article discusses how to easily create a scalable and parallelized machine learning platform on the cloud to process large-scale data.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://eng.uber.com/dbevents-ingestion-framework/">DBEvents: A Standardized Framework for Efficiently Ingesting Data into Uberâ€™s Apache Hadoop Data Lake</a>. This blog post looks at Uber&rsquo;s  DBEvents, a change data capture system designed for high data quality and freshness. It facilitates bootstrapping, ingesting a snapshot of an existing table, and incremental, streaming updates.</li>
<li><a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues">Kafka Connect Deep Dive â€“ Error Handling and Dead Letter Queues</a>. In this blog post <a href="https://twitter.com/rmoff">Robin Moffat</a> looks at several common patterns for handling Kafka Connect problems and examines how the patterns can be implemented.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a>. This post by yours truly looks at how to use <code>CREATE EXTERNAL LIBRARY</code> to deploy Java code without having access to SQL Server&rsquo;s filesystem.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019, Java &amp; External Libraries - II]]></title>
    <link href="http://nielsberglund.com/2019/03/17/sql-server-2019-java--external-libraries---ii/" rel="alternate" type="text/html"/>
    <updated>2019-03-17T17:13:45+02:00</updated>
    <id>http://nielsberglund.com/2019/03/17/sql-server-2019-java--external-libraries---ii/</id>
    <content type="html"><![CDATA[<p>This post is part of the <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a> series of posts, and it is the second post discussing SQL Server 2019, Java and the creation and use of external libraries.</p>

<p>In the previous post about external libraries, we said that they were beneficial as they reduced complexities when deploying code, but there were still some caveats. So, in this post, we look at how to overcome those caveats</p>

<p></p>

<h2 id="recap">Recap</h2>

<p>Let us start with a recap of what we covered in the previous post.</p>

<p>In the last post we saw how we can make the use of Java in SQL Server somewhat less complex (permissions, code paths, etc.), by using external libraries.</p>

<p>We create the external library using the DDL statement <code>CREATE EXTERNAL LIBRARY</code>, and we saw in the post that the signature, somewhat simplified, looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>To be able to use external libraries for your Java code, the code need be packaged either in a <code>.jar</code> file or your class files need to be archived into a <code>.zip</code> file. We give the external library a name, in the <code>file_spec</code> we point to where the file resides, and finally, we set the <code>LANGUAGE</code> parameter to <code>Java</code>:</p>

<pre><code class="language-sql">USE JavaTest;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create External Library</em></p>

<p>The code we see in <em>Code Snippet 2</em> is fairly self-explanatory, where we name the external library <code>myCalc</code> and the code is at <code>W:\javacodepath\MyCalcJar.jar</code>. What is interesting when creating external libraries for Java is that the name does not matter (apart from that it has to be unique).</p>

<p>To see that it has worked we use catalog views to investigate:</p>

<pre><code class="language-sql">SELECT el.name, el.[language], ef.content
FROM sys.external_libraries el
JOIN sys.external_library_files ef
  ON el.external_library_id = ef.external_library_id
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>View External Libraries</em></p>

<p>In <em>Code Snippet 3</em> we do a <code>SELECT</code> against <code>sys.external_libraries</code> and <code>sys.external_library_files</code>, and when we execute the result looks like so:</p>

<p><img src="/images/posts/sql_2k19_java_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>External Libraries View</em></p>

<p>We see in <em>Figure 1</em> some information about the external library. The <code>content</code> column outlined in red is interesting in that it contains the binary representation of the external library. This is like assemblies in SQLCLR. They are persisted to system tables and, when needed, loaded from the tables based on the binary representation. External libraries are the same, persisted to system tables, and when needed they are loaded from those tables.</p>

<p>So by loading the code from the database, we no longer need to worry about permissions and where to load the code from. An additional benefit is that the external libraries are database bound. If you backup and restore the database to another machine, the external libraries are there, as opposed to if you load them from a file location.</p>

<p>As good as this is, there is a problem or rather a caveat. What we have done so far requires the code for the external library to be in a location SQL Server can read. I as a developer may not have access to the file system of the SQL box. So in the rest of this post, we look at some options how we can create an external library on a remote SQL Server, where we do not have access to the file system, but we can access the SQL Server instance via SSMS or in my case, <a href="https://github.com/Microsoft/azuredatastudio">Azure Data Studio</a>.</p>

<h2 id="demo-code">Demo Code</h2>

<p>Before diving into what we want to do, let us look at the code we use today (it looks very similar to the code in the previous post):</p>

<pre><code class="language-sql">USE master
GO

DROP DATABASE IF EXISTS JavaTest;
GO

DROP DATABASE IF EXISTS JavaTestLocal;
GO

DROP DATABASE IF EXISTS JavaTestRemote;
GO

CREATE DATABASE JavaTestLocal;
GO

CREATE DATABASE JavaTestRemote;
GO
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create Databases</em></p>

<p>We see in <em>Code Snippet 4</em> how we create a couple of databases. Since I do not have access to a remote SQL Server right now, I emulate the remote SQL by the <code>JavaTestRemote</code> database. Oh, and the first database I drop, that is the one we used in the previous post. We also need some Java code. We assume the code below is in a source file named <code>Calculator.java</code>:</p>

<pre><code class="language-java">public class Calculator {
    public static short numberOfOutputCols;
    public static int x;
    public static int y;

    static public int[] outputDataCol1;
    static public boolean[][] outputNullMap;

    public static void adder() {
        numberOfOutputCols = 1;
        outputDataCol1 = new int[1];
        outputDataCol1[0] = x + y;
        outputNullMap = new boolean[1][1];
    }
}
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Java Calculator</em></p>

<p>The code in <em>Code Snippet 5</em> is the same we used in <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>. As I mentioned in the <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">last post</a> that if you wonder about the variables in the code, the other posts in the Java <a href="/s2k19_ext_framework_java">series</a> discuss them in detail.</p>

<p>The last thing to do before we can talk about how to solve the issue with having to have access to the file system of the box SQL Server is on is to compile the code in <em>Code Snippet 5</em> and create a <code>.jar</code> for it:</p>

<pre><code class="language-java">$ javac .\Calculator.java
$ jar -cf MyCalcJar.jar .\Calculator.class
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Compile and Create a jar File</em></p>

<p>After running the code in <em>Code Snippet 6</em> we have a <code>.jar</code> file which we use to create the external library.</p>

<h2 id="external-library">External Library</h2>

<p>The question is now how to create the external library on a remote SQL Server instance if we do not have access to the file system on that server? Let us look at <code>CREATE EXTERNAL LIBRARY</code>&rsquo;s signature again (we saw it in the previous <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">post</a>):</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]  
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>Remember how we said in <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>, that <code>file_spec</code> points to the content of the package/code, and we saw in <em>Code Snippet 2</em> how we set <code>file_spec</code> to the path of the file.</p>

<p>However, we also said in the last <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">post</a> that <code>file_spec</code> can be a hex literal, similar to what we do when we create assemblies in SQLCLR. The hex literal is the actual binary representation of the package, and if we can get hold of the binary somehow we are &ldquo;golden&rdquo;. So, let us look at a couple of ways we can get hold of the binary package representation:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-database">Local Database</h4>

<p>Let us start with a way to get the binary from a local database.</p>

<blockquote>
<p><strong>NOTE:</strong> This is similar to what we do at <a href="/derivco">Derivco</a> when we generate SQL statements to deploy SQLCLR assemblies.</p>
</blockquote>

<p>We see in <em>Figure 1</em> the <code>content</code> column, which we said before contains the binary representation of the package. What we do is to log on to the local database <code>JavaTestLocal</code>, and create the external library from the <code>.jar</code> file we created in <em>Code Snippet 6</em>:</p>

<pre><code class="language-sql">USE JavaTestLocal;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Create Local External Library</em></p>

<p>As SQL Server is installed on my local dev-machine, and SQL Server has access to the <code>W:\javacodepath</code> path, the code in <em>Code Snippet 8</em> executes ok.</p>

<p>We know from <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a> and from the summary above how the binary representation of the package is stored in the <code>content</code> column of the <code>sys.external_library_files</code> catalog view. Let us grab the content of the <code>content</code> column:</p>

<pre><code class="language-sql">USE JavaTestLocal;
GO

DECLARE @binrep varbinary(max);

SELECT @binrep = lf.content
FROM sys.external_library_files lf
JOIN sys.external_libraries l
  ON lf.external_library_id = l.external_library_id
WHERE l.name = 'myCalc';

PRINT @binrep;
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Retrieve the Binary Representation</em></p>

<p>We see in <em>Code Snippet 9</em> how we <code>DECLARE</code> a variable <code>@binrep</code> which is a <code>varbinary</code>, and then we <code>SELECT</code> the value of the <code>content</code> column into the variable. We finally <code>PRINT</code> the content of the variable and we get something like so when we execute:</p>

<blockquote>
<p><strong>EDIT (2019-04-10):</strong> The above method works only with packages with a size less than 8k. See <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> for an explanation, and a way around it.</p>
</blockquote>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_binrep.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Binary Representation</em></p>

<p>In <em>Figure 2</em> we see part of the binary value of the package. We copy that into a new query window connected to the remote server and database, and we do a new <code>CREATE EXTERNAL LIBRARY</code>, but instead of a file-path for the <code>CONTENT</code> parameter we paste in the binary representation:</p>

<pre><code class="language-sql">USE JavaTestRemote;
GO

CREATE EXTERNAL LIBRARY myCalcRemote
FROM (CONTENT = 0x504B03041400080808007B34684E...)
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Use Binary as CONTENT</em></p>

<p>We see how the <code>CONTENT</code> parameter in <em>Code Snippet 10</em> now contains the binary value of the external library. After we execute the code in <em>Code Snippet 10</em> we test to see that it has worked by executing on the remote SQL Server:</p>

<pre><code class="language-sql">USE JavaTestRemote;
GO

EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int',
@x = 21,
@y = 21;
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Execute Against Calculator.adder</em></p>

<p>The result of running the code in <em>Code Snippet 11</em> is:</p>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_queryres1.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Result</em></p>

<p>From what we see in <em>Figure 3</em>, everything has worked.</p>

<p>We used the binary representation of an external library on our local SQL Server instance to create an external library on a remote instance. We do this without having access to the remote file system.</p>

<p>That is all well and good, but what if we do not have access to a local SQL Server?</p>

<h4 id="generate-binary-from-code">Generate Binary from Code</h4>

<p>The second way we can get the binary representation is to generate it from code. When I started looking into this post and how to generate the binary representation I first started with C# as I am a .NET guy. However, boy, that was a lot of code (slight exaggeration), and wouldn&rsquo;t it be &ldquo;cool&rdquo; if I could just run a script, and send in a file-path to the package? Everyone told me that Python is what all the &ldquo;cool kids&rdquo; use, so I decided to go with Python, and this is the code I started with:</p>

<pre><code class="language-python">import binascii

filePath = &quot;W:\\javacodepath\\MyCalcJar.jar&quot;

with open(filePath, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify( \
                       bytearray(myArr)).decode('utf-8')

print(hex_bytes)
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Generate Binary from Python</em></p>

<p>When we look at the code in <em>Code Snippet 12</em> we see how:</p>

<ul>
<li>I <code>import</code> the <code>binascii</code> module which contains a number of methods to convert between binary and various ASCII-encoded binary representations.</li>
<li>I hardcode (for now) the file-path to where the <code>.jar</code> file is.</li>
<li>I open the file in binary mode. The <code>&quot;rb&quot;</code> in the <code>open(filePath, &quot;rb&quot;)</code> indicates I want the file as binary.</li>
<li>I read the file into a byte array (<code>myArr</code>).</li>
<li>I turn the byte-array into hex representation, and then I print the hex representation.</li>
</ul>

<p>The code is in a source file named <code>outputBinary.py</code>, and when I execute it from a command prompt I see the following:</p>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_python1.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Python Output</em></p>

<p>The (cropped) binary output in <em>Figure 4</em> is the same as we used in <em>Code Snippet 10</em>. We can now copy the output as we see in <em>Figure 4</em> and do exactly what we did before.</p>

<p>However, why do copy and paste when we can connect directly from Python to the remote database and execute <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-python">import pyodbc
import binascii

filePath = &quot;W:\\javacodepath\\MyCalcJar.jar&quot;
extLibName = 'myCalcRemote'

with open(filePath, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

# connect to db

dbServer = 'localhost\s2k19_ctp23_1'
dataBase = 'JavaTestRemote'
userName = '&lt;some_user_name'
password = '&lt;some_pwd&gt;'

drvr = '{ODBC Driver 17 for SQL Server}'
connStr = f'DRIVER={drvr};SERVER={dbServer};DATABASE={dataBase};UID={userName};PWD={password}'
conn = pyodbc.connect(connStr)
cursor = conn.cursor()

execStmt = f'CREATE EXTERNAL LIBRARY {extLibName}\n'
execStmt = execStmt + f'FROM (CONTENT = {hex_bytes})\n'
execStmt = execStmt + f&quot;WITH (LANGUAGE = 'Java');\n&quot;

cursor.execute(execStmt)
conn.commit()
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Create External Library from Python Code</em></p>

<p>Before we look at the code in <em>Code Snippet 13</em> let us drop the external library we just created in the remote SQL Server instance: <code>DROP EXTERNAL LIBRARY myCalcRemote</code>. This to ensure we are back in a state with no external libraries installed.</p>

<p>So, what do we do in <em>Code Snippet 13</em>? Well, we use the same code as in <em>Code Snippet 12</em> to generate the binary representation, but we do not do a <code>PRINT</code> of it. Instead, we connect to the database using the <code>pyodbc</code> module, and the latest SQL Server ODBC driver. The <code>hex_bytes</code> variable is now a parameter in the <code>CREATE EXTERNAL LIBRARY</code> statement, and we have a hardcoded variable for the name of the external library.</p>

<p>As the code is just sample code, the connection details for the database is also hardcoded. In a real-world scenario, the script should prompt for the various details; file path, name, connection details etc., and assign the inputs to the variables:</p>

<pre><code class="language-python">extLibName = input(&quot;Provide a unique name for \
                   the external library you want to create: &quot;)
filePath = input(&quot;Provide full path to the JAR \
                  file you want to use - \
                  Example: 'W:\\javacodepath\\myJarFile.jar': &quot;)
dbServer = input(&quot;Provide name/ip address of your \
                  database server. If instance also instance name \ 
                  - Example: 'mydbServer\myInstance: &quot;)
dataBase = input(&quot;Provide name of the database where you \
                  want to create the external library: &quot;)
userName = input(&quot;Provide the user name with which you \
                   want to connect to the server: &quot;)
password = input(&quot;Provide password with which to \
                  connect to the database: &quot;)
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>Input Variables</em></p>

<p>It is worth noting that the way the script captures the password variable is not particularly secure. Instead of <code>input</code>, we should use <code>getpass</code> or something similar.</p>

<blockquote>
<p><strong>NOTE:</strong> Unless the user with which you connect is part of <code>db_owner</code>, the user needs explicit permissions to execute <code>CREATE EXTERNAL LIBRARY</code>.</p>
</blockquote>

<p>To test this, you replace the variables in <em>Code Snippet 13</em> with relevant values for your environment and run the code. The code should run OK, and you have now created an external library in a database in a remote SQL Server (well, in my case an emulated remote SQL Server).</p>

<h2 id="summary">Summary</h2>

<p>In this post, we set out to solve the issue of how to create an external library of some Java code without having access to the filesystem of the SQL Server where we want to create the external library.</p>

<p>We have seen two ways of doing it:</p>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create the external assembly from a file-path in a local SQL Server where we have access to the filesystem (like <code>localhost</code>).</li>
<li>Copy the binary representation from the <code>content</code> column in <code>sys.external_library_files</code>.</li>
<li>Assign the copied value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 2 above (local database).</li>
</ol>

<p>Alternatively, you in addition to generate the binary in the script, connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 10, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/10/interesting-stuff---week-10-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-10T13:14:44+02:00</updated>
    <id>http://nielsberglund.com/2019/03/10/interesting-stuff---week-10-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://blog.acolyer.org/2019/03/08/a-generalised-solution-to-distributed-consensus/">A generalised solution to distributed consensus</a>. Distributed consensus is hard! In this blog post <a href="https://twitter.com/adriancolyer">Adrian</a> dissects a white-paper which re-examines the foundations of distributed consensus.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/microsoft-opens-first-datacenters-in-africa-with-general-availability-of-microsoft-azure/">Microsoft opens first datacenters in Africa with general availability of Microsoft Azure</a>. I guess the title says it all! On March 6, Microsoft opened two data centers in South Africa: South Africa North (Johannesburg) and South Africa West (Cape Town). At the moment the offerings are somewhat sparse, but I have no doubt we&rsquo;ll soon see quite a lot of services.</li>
<li><a href="https://azure.microsoft.com/en-us/blog/service-fabric-processor-in-public-preview/">Service Fabric Processor in public preview</a>. Azure Event Hub is an elegant way to ingest data into the Azure ecosystem, and Service Fabric is awesome for hosting and running microservices. Quite often some of the services need to consume from Azure Event Hubs, and until now you have had to write your own consumer, most likely based on <em>Event Processor Host</em>. That changes now with the preview of <em>Service Fabric Processor</em>, which is a new library for consuming events from an Event Hub that is directly integrated with Service Fabric. Awesome!</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-net-core-3-preview-3/">Announcing .NET Core 3 Preview 3</a>. What the title says; .NET Core 3 Preview 3 is available for download. Go and get it!</li>
<li><a href="https://devblogs.microsoft.com/dotnet/collecting-net-core-linux-container-cpu-traces-from-a-sidecar-container/">Collecting .NET Core Linux Container CPU Traces from a Sidecar Container</a>. This blog post gives a step-by-step guide of using a sidecar container to collect CPU trace of an ASP.NET application running in a Linux container.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://101.datascience.community/2019/03/07/microsoft-launches-data-science-certifications/">MICROSOFT LAUNCHES DATA SCIENCE CERTIFICATIONS</a>. In this blog post <a href="https://twitter.com/ryanswanstrom">Ryan</a> discusses 3 new certifications Microsoft recently announced aimed at Data Scientists/Engineers. I have always been skeptic to certifications by vendors, brain dumps anyone, but I will definitely have a look at this.<br /></li>
<li><a href="https://eng.uber.com/machine-learning-capacity-safety/">Using Machine Learning to Ensure the Capacity Safety of Individual Microservices</a>. This is a very interesting post by Uber&rsquo;s engineering team, discussing how they apply Machine Learning to forecast micro-services issues!</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>. Earlier today I published this post, in which I talk about how to deploy Java code to a database, so it can be loaded from there.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019, Java &amp; External Libraries - I]]></title>
    <link href="http://nielsberglund.com/2019/03/10/sql-server-2019-java--external-libraries---i/" rel="alternate" type="text/html"/>
    <updated>2019-03-10T10:22:51+02:00</updated>
    <id>http://nielsberglund.com/2019/03/10/sql-server-2019-java--external-libraries---i/</id>
    <content type="html"><![CDATA[<p>A couple of months ago I wrote a series of posts about one of the new features in SQL Server 2019; the ability to call out to Java code from inside SQL Server.</p>

<p>To see the posts, go to <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a>.</p>

<p>In the posts, we discussed how the Java extension differs from R and Python in that R and Python are an integrated part of the SQL Server install (when enabling in-database analytics), but Java is not. In other words, the use of the Java extension requires Java to be installed beforehand, and this then has implications on permissions. We also discussed how Java is a compiled language, and we execute against a method in a class, whereas with R and Python we send a script to the external engine. The consequence of this is that when we execute Java code, we need to indicate where the compiled code resides, and those locations need specific permissions.</p>

<p>All this creates a level of complexity, and it would potentially be easier if we load the Java code from a well-known place, where we do not need to worry about permissions and so forth.</p>

<p>This post is the first of a couple where we see how new functionality in SQL Server 2019 CTP 2.3 can help.</p>

<p></p>

<h2 id="code-background">Code &amp; Background</h2>

<p>Let us start with looking at the code we use today, and also remind ourselves of some of the complexities when calling Java from SQL server.</p>

<p>So, the code:</p>

<pre><code class="language-java">public class Calculator {
    public static short numberOfOutputCols;
    public static int x;
    public static int y;

    static public int[] outputDataCol1;
    static public boolean[][] outputNullMap;

    public static void adder() {
        numberOfOutputCols = 1;
        outputDataCol1 = new int[1];
        outputDataCol1[0] = x + y;
        outputNullMap = new boolean[1][1];
    }

}
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Java Calculator</em></p>

<p>As we see in *Code Snippet 1`, the code is very simple, and we have seen variants of it in my other <a href="/s2k19_ext_framework_java">Java posts</a>. If you wonder about some of the variables in the code, the previous <a href="/s2k19_ext_framework_java">posts</a> discuss them in detail.</p>

<p>To use the code from SQL Server, we compile the source file <code>Calculator.java</code>: <code>$ javac Calculator.java</code>, into a <code>.class</code> file: <code>Calculator.class</code>.
After compilation, we can now place the <code>Calculator.class</code> in any of the locations a pre-defined <code>CLASSPATH</code> environment variable points to. To call the <code>adder</code> method from inside SQL Server we execute like so:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
    @language = N'Java',
    @script = N'Calulator.adder',
    @params = N'@x int, @y int',
    @x = 21,
    @y = 21;
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Execute from SQL Server</em></p>

<p>By the fact that the <code>.class</code> file is in a <code>CLASSPATH</code> location, the code in <em>Code Snippet 2</em> succeeds, <strong>IF</strong> the right permissions exist on the location.</p>

<blockquote>
<p><strong>NOTE:</strong> The required permission is <code>READ</code> for the <code>ALL APPLICATION PACKAGES</code> group.</p>
</blockquote>

<p>Having the code in a <code>CLASSPATH</code> location is one way to load and execute the code. Another way is to have the code in an arbitrary location and explicitly set a parameter in the SQL call to point to that location:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
    @language = N'Java',
    @script = N'Calculator.adder',
    @params = N'@x int, @y int, @CLASSPATH nvarchar(512)',
    @x = 21,
    @y = 21,
    @CLASSPATH = N'W:\javacodepath';
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Using @CLASSPATH Parameter</em></p>

<p>In <em>Code Snippet 3</em> we see how we set a parameter <code>CLASSPATH</code> to point to where the code is. The permission requirements for this scenario are the same as for when we have a defined <code>CLASSPATH</code>: the location need <code>READ</code> permission for the <code>ALL APPLICATION PACKAGES</code> group.</p>

<blockquote>
<p><strong>NOTE:</strong> You may wonder where the <code>CLASSPATH</code> parameter in <em>Code Snippet 3</em> comes from, as it is not part of the signature of <code>sp_execute_external_script</code>? This parameter is a well-known parameter for the SQL Server Java language extension, and if this parameter exists the extension sets the <code>--classpath</code> option in the <code>java</code> command.</p>
</blockquote>

<p>In the code snippets above we execute against <code>.class</code> files. In the &ldquo;real world&rdquo; however you are unlikely to do that, but instead, you use <code>.jar</code> files. So let us see how we do that from SQL Server. First, we compile the <code>.java</code> source, followed by creating the <code>.jar</code>:</p>

<pre><code class="language-java">$ javac .\Calculator.java
$ jar -cf MyCalcJar.jar .\Calculator.class
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create a jar File</em></p>

<p>After we have created the <code>MyCalcJar.jar</code> as in <em>Code Snippet 4</em>, we copy the <code>.jar</code> to either the <code>CLASSPATH</code> location or an arbitrary location. To execute we call it like so:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int, @CLASSPATH nvarchar(max)',
@x = 21,
@y = 21,
@CLASSPATH = N'W:\javacodepath\MyCalcJar.jar'
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Execute Against a jar File</em></p>

<p>We see in <em>Code Snippet 5</em> how we when we execute against a <code>.jar</code> need to:</p>

<ul>
<li>Set the path to the <code>.jar</code>, using the using the <code>CLASSPATH</code> parameter. This is required <strong>even</strong> if the <code>.jar</code> is in the actual <code>CLASSPATH</code>.</li>
<li>Include the name of the <code>.jar</code> file.</li>
</ul>

<p>We also need to ensure that the permissions mentioned above exist where ever the <code>.jar</code> is.</p>

<p>So the examples above re-enforce what we mentioned in the beginning, Java incurs some complexity which we do not have when executing R/Python code:</p>

<ul>
<li>Where to load the code from.</li>
<li>Permissions on said location.</li>
</ul>

<p>Apart from pointing out the complexities at the beginning of this post I also mentioned that new functionality in SQL Server 2019 CTP 2.3 helps to solve this. That functionality is the ability to create external libraries.</p>

<h2 id="external-libraries">External Libraries</h2>

<p>External libraries in SQL Server enables the ability to load artefacts needed for any new language runtimes and OS platforms supported by SQL Server from the database. For example, if you need an R package that is not part of the default install of the engine you can upload to the database the particular R package as an external library and use it from the database in question. An external library is similar to a CLR assembly in that the actual library exists in the database as a byte-stream <del>and SQL Server loads it from the database</del>.</p>

<blockquote>
<p><strong>EDIT (2019-04-10):</strong> *It so turns out that what I wrote about SQL Server loading from the database is not correct. It loads the pakage(s) from the external library path.  See <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> for more around this.</p>
</blockquote>

<p>You create an external library in a similar to how you create a CLR assembly; you use a DDL statement <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]  
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>In <em>Code Snippet 6</em> we see the signature for <code>CREATE EXTERNAL LIBRARY</code>. We see only the main parts:</p>

<ul>
<li><code>library_name</code> - the name we want the library to have. When we create an external library for Java code we can assign any name we want. However, when we create an external library for R, the name must be the same as what we refer to the package when we load it in the external script.</li>
<li><code>owner_name</code> - optional, and it specifies the name of the user or role that owns the external library.</li>
<li><code>file_spec</code> - this is the content of the package/code. For Java it has to be a <code>.jar</code> file, or a <code>.zip</code> file with relevant <code>.class</code> files in it. The <code>file_spec</code> can be either a path to the file, or a byte array. Part of the <code>file_spec</code> is also the platform on which SQL Server is running. For now, only Windows is supported.</li>
<li><code>language</code> - the language of the package/code.</li>
</ul>

<blockquote>
<p><strong>NOTE:</strong> I mentioned above that we see the main parts of <code>CREATE EXTERNAL LIBRARY</code>, and we have not drilled down in detail. If you are interested in the details look <a href="https://docs.microsoft.com/en-us/sql/t-sql/statements/create-external-library-transact-sql?view=sql-server-ver15">here</a>.</p>
</blockquote>

<p>To see this in practice, we need first to create a database: <code>CREATE DATABASE JavaTest</code>, (we can obviously use an existing db as well). Then, based on the code in <em>Code Snippet 4</em> and <em>Code Snippet 5</em>, the call to create an external library for our calculator looks like so:</p>

<pre><code class="language-sql">USE JavaTest;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Create External Library</em></p>

<p>What we see in <em>Code Snippet 7</em> is how we create an external library named <code>myCalc</code>, where the external library is based on a <code>.jar</code> file at <code>W:\javacodepath\MyCalcJar.jar</code>. The last thing we do is to indicate that the language is <code>Java</code>. As the only platform supported right now is Windows, we do not bother with the <code>PLATFORM</code> parameter.</p>

<p>To verify this works after we execute the code in <em>Code Snippet 7</em> we use exactly the same code as in <em>Code Snippet 2</em>:</p>

<pre><code class="language-sql">USE JavaTest;
GO

EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int',
@x = 21,
@y = 21;
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Execute Java Code Loaded from Database</em></p>

<p>In <em>Code Snippet 8</em> we see how we no longer define the <code>.jar</code> file as a parameter, (what we had to do in <em>Code Snippet 5</em>), but when we execute all works OK.</p>

<p>The question is now where the <code>.jar</code>,(or <code>.zip</code>), loads from. The answer to that is, (like with SQLCLR), that it loads from system tables in the database. When we create an SQLCLR assembly in a database, SQL Server stores the assembly in system tables, and we use catalog views to view the assemblies: <code>sys.assemblies</code>, <code>sys.assembly_files</code>, and so on. External libraries do not use the same underlying tables or catalog views, but to see the external libraries you use:</p>

<ul>
<li><code>sys.external_libraries</code> - contains a row for each external library that has been uploaded into the database.</li>
<li><code>sys.external_library_files</code> - lists a row for each file in the external library.</li>
<li><code>sys.external_libraries_installed</code> - shows what libraries have been loaded, e.g. used.</li>
</ul>

<p>An example of this:</p>

<pre><code class="language-sql">SELECT el.name, el.[language], ef.content
FROM sys.external_libraries el
JOIN sys.external_library_files ef
  ON el.external_library_id = ef.external_library_id
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>View External Libraries</em></p>

<p>When we run the code in <em>Code Snippet 9</em> we get:</p>

<p><img src="/images/posts/sql_2k19_java_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>External Libraries View</em></p>

<p>We see in <em>Figure 1</em> some information about the external library. The <code>content</code> column outlined in red is interesting in that it contains the binary representation of the external library.</p>

<h2 id="summary">Summary</h2>

<p>In this post, we saw how we can make the use of Java in SQL Server somewhat less complex (permissions, code paths, etc.), by using external libraries.</p>

<p>To be able to use external libraries for your Java code, the code need be packaged either in a <code>.jar</code> file, or your class files need to be archived into a <code>.zip</code> file.</p>

<p>We create the external library using the DDL statement <code>CREATE EXTERNAL LIBRARY</code> where we:</p>

<ul>
<li>Define a name for the library.</li>
<li>Indicate where the <code>.jar</code> or <code>.zip</code> file is.</li>
<li>Set the language to Java.</li>
</ul>

<p>When we execute against the code we no longer need to have the code copied to the <code>CLASSPATH</code> or define a <code>@CLASSPATH</code> parameter, and no special permissions are required. Well, you need permissions to execute <code>sp_execute_external_script</code> but apart from that nothing else.</p>

<p>When we call <code>sp_execute_external_script</code> SQL Server loads the code from a system table, and we can view what external libraries exist in the database by using the <code>sys.external_libraries</code> and <code>sys.external_library_files</code> catalog views.</p>

<p>As good as all this sounds, there is one minor, (well perhaps not so minor), detail to be aware of: the way we create external libraries in this post - from a file path - requires SQL Server to be able to read from that path. In a production environment that may not be possible, so in a future post we look at how to overcome that.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 9, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/03/interesting-stuff---week-9-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-03T10:54:21+02:00</updated>
    <id>http://nielsberglund.com/2019/03/03/interesting-stuff---week-9-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/architecting-transactional-system">Achieving High Throughput with Reliability in Transactional Systems</a>. This presentation from <a href="https://www.infoq.com/">InfoQ</a> discusses architecting and designing a high performance, throughput &amp; data processing transactional system and real-time access to large datasets via APIs.</li>
<li><a href="https://www.infoq.com/presentations/monolith-microservices-refactoring-analysis-tools">Getting from Monolith to Microservices</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation looks at strategies to break a monolith, from the front-end to the back, including database refactoring and analysis tools to see dependencies in legacy code.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/training-your-first-classifier-with-spark-and-scala-893d7c6f7d88">Training Your First Classifier with Spark and Scala</a>. This post is an excellent introduction to machine learning with Spark and Scala.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.ververica.com/blog/monitoring-apache-flink-applications-101">Monitoring Apache Flink Applications 101</a>. This blog post provides an introduction to Apache Flinkâ€™s built-in monitoring and metrics system, that allows developers to monitor their Flink jobs effectively.</li>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-3-affinity-between-events-streams-serverless">Journey to Event Driven â€“ Part 3: The Affinity Between Events, Streams and Serverless</a>. This post is the third part in the <a href="https://www.confluent.io/blog/journey-to-event-driven-part-1-why-event-first-thinking-changes-everything">Journey to Eventdriven</a> series, and it looks at how event-driven streaming architectures fit with serverless.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/01/sql-server-2019-community-technology-preview-2-3-is-now-available/">SQL Server 2019 community technology preview 2.3 is now available</a>. What the title of the post says: CTP2.3 of SQL Server 2019 is now available for download. I have already downloaded and installed the Windows version, and right now I am in the process of installing the SQL Server 2019 Big Data Cluster on Azure Kubernetes Service. Happy Days!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 8, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/24/interesting-stuff---week-8-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-24T10:08:50+02:00</updated>
    <id>http://nielsberglund.com/2019/02/24/interesting-stuff---week-8-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<p>For some reason I did not find that much interesting to me this week, but here is what caught my eye.</p>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.ververica.com/blog/batch-as-a-special-case-of-streaming-and-alibabas-contribution-of-blink">Batch as a Special Case of Streaming and Alibaba&rsquo;s contribution of Blink</a>. This post discusses the in-house improvements to Flink batch processing Alibaba has done and contributed to open source. Oh, when you read the post, and you wonder what Ververica is, read <a href="https://www.ververica.com/blog/introducing-our-new-name">this post</a>.</li>
<li><a href="https://www.infoq.com/presentations/apache-flink-streaming-app">Patterns of Streaming Applications</a>. This presentation from <a href="https://www.infoq.com/">InfoQ</a> talks about a blueprint for streaming data architectures and a review of desirable features of a streaming engine. The presentation also discusses streaming application patterns and anti-patterns, and use cases and concrete examples using Apache Flink.</li>
<li><a href="https://www.infoq.com/presentations/wepay-database-streaming">The Whys and Hows of Database Streaming</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses how database streaming is becoming more and more essential and the many functions that database streaming serves. The presentation also covers challenges faced with streaming peer-to-peer distributed databases.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
</feed>

