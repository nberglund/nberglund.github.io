<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Niels Berglund</title>
  <link href="http://nielsberglund.com/atom.xml" rel="self"/>
  <link href="http://nielsberglund.com"/>
  <updated>2019-05-11T06:39:50+02:00</updated>
  <id>http://nielsberglund.com/</id>
  <generator uri="http://gohugo.io/">Hugo</generator>

  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 19, 2019]]></title>
    <link href="http://nielsberglund.com/2019/05/11/interesting-stuff---week-19-2019/" rel="alternate" type="text/html"/>
    <updated>2019-05-11T06:39:50+02:00</updated>
    <id>http://nielsberglund.com/2019/05/11/interesting-stuff---week-19-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/net-core-is-the-future-of-net/">.NET Core is the Future of .NET</a>. .NET is Dead! Long Live .NET! Somewhat melodramatic, but anyway. So, in this blog post Microsoft announces what almost everyone already knew - that .NET Framework 4.8 is the last major version of .NET Framework. Going forward Microsoft&rsquo;s efforts will be on .NET Core.<br /></li>
<li><a href="https://devblogs.microsoft.com/dotnet/introducing-net-5/">Introducing .NET 5</a>. Hot on the heels of the blog post above, announcing the death of .NET Framework, comes this post, laying out the future of .NET Core, .NET 5.</li>
<li><a href="https://devblogs.microsoft.com/dotnet/introducing-diagnostics-improvements-in-net-core-3-0/">Introducing diagnostics improvements in .NET Core 3.0</a>. Yet another .NET Core post. This post discusses a suite of tools that utilize new features in the .NET runtime that makes it easier to diagnose and solve performance problems.</li>
</ul>

<h2 id="data-science-machine-learning">Data Science / Machine Learning</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-ml-net-1-0/">Announcing ML.NET 1.0</a>. I have during the last months now and then posted in these &ldquo;roundups&rdquo; about new releases of ML.NET. Microsoft has now released version 1.0 with a lot of interesting new features, and that is what this post is about.</li>
<li><a href="https://www.infoq.com/presentations/h2o-model-spark">Productionizing H2O Models with Apache Spark</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation demonstrating the creation of pipelines integrating H2O machine learning models and their deployments using Scala or Python.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/05/kafka-zeebe-streams-workflows">Event Streams and Workflow Engines – Kafka and Zeebe</a>. An <a href="https://www.infoq.com/">InfoQ</a> discussing how Kafka fits in an Event-Driven Architecture, and how workflow engines can handle complex business processes. The article also mentioned how Zeebe, a new highly scalable workflow engine, can be used with Kafka.</li>
<li><a href="https://www.confluent.io/blog/apache-kafka-data-access-semantics-consumers-and-membership">Apache Kafka Data Access Semantics: Consumers and Membership</a>. This is an article discussing in detail how the Kafka consumer works. It also talks about consumer groups, how their state is saved, and consistency is ensured. It discusses how consumer groups are managed in a distributed way, and finally, the article looks at the rebalance protocol.</li>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-4-four-pillars-of-event-streaming-microservices">Journey to Event Driven – Part 4: Four Pillars of Event Streaming Microservices</a>. This is the fourth &ldquo;episode&rdquo; in the &ldquo;Journey to Event Driven&rdquo;. This time the discussion is around the four individual parts that make up event streaming. I cannot wait to hear more about it next week at the Kafka Summit in London!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 18, 2019]]></title>
    <link href="http://nielsberglund.com/2019/05/05/interesting-stuff---week-18-2019/" rel="alternate" type="text/html"/>
    <updated>2019-05-05T07:13:49+02:00</updated>
    <id>http://nielsberglund.com/2019/05/05/interesting-stuff---week-18-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li>[Designing Distributed Systems with TLA+][]. An <a href="https://www.infoq.com/">InfoQ</a> presentation where the presenter discusses the ideas behind TLA+, which is a specification language that describes a system, its properties, and how it works.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/using-net-and-docker-together-dockercon-2019-update/">Using .NET and Docker Together – DockerCon 2019 Update</a>. This post is about the improvements and new features in .NET Core 3.0 related to Docker and running your code in Docker.</li>
</ul>

<h2 id="databases">Databases</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/yugabytedb">YugaByte DB - A Planet-scale Database for Low Latency Transactional Apps</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation introducing and demoing YugaByte DB, a large scale DB, highlighting distributed transactions with global consistency.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://databricks.com/blog/2019/05/02/detecting-financial-fraud-at-scale-with-decision-trees-and-mlflow-on-databricks.html">Detecting Financial Fraud at Scale with Decision Trees and MLflow on Databricks</a>. An excellent post about how to use Databricks to detect fraud. Why I like this article is because of the sample code, it makes it easy to follow along.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/optimizing-kafka-streams-applications">Optimizing Kafka Streams Applications</a>. This article discusses how one can optimize Kafka Stream applications based on the new processor topology optimization framework which Kafka Streams 2.1 introduced.</li>
<li><a href="https://www.confluent.io/blog/pipelinedb-team-joins-confluent">The PipelineDB Team Joins Confluent</a>. I had no idea that <a href="https://www.pipelinedb.com/">PipelineDB</a> existed before this blog post. In my mind, PipelineDB joining Confluent can be huge, and I cannot wait to see what they dream up.</li>
<li><a href="https://www.buzzsprout.com/186154/1073627-load-balanced-apache-kafka-derivco-s-globally-distributed-gaming-business">Load-Balanced Apache Kafka: Derivco&rsquo;s Globally Distributed Gaming Business</a>. My colleague <a href="https://twitter.com/charllamprecht">Charl Lamprecht</a> and I had the pleasure of being interviewed by Tim Berglund (no relations) for a Kafka podcast. We, or rather Charl as I had audio issues, spoke about Kafka, load balancing via F5&rsquo;s and the journey we have had to get Kafka implemented in <a href="/derivco">Derivco</a>.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 17, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/28/interesting-stuff---week-17-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-28T08:12:38+02:00</updated>
    <id>http://nielsberglund.com/2019/04/28/interesting-stuff---week-17-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/introducing-net-for-apache-spark/">Introducing .NET for Apache® Spark™ Preview</a>. What the title says! Microsoft has released a preview of .NET that you can use together with Apache Spark. It is built on the Spark interop layer, designed to provide high-performance bindings to multiple languages. Being able to write C# code for Spark is so awesome; hopefully, we can soon use it in Notebooks as well.</li>
<li><a href="https://towardsdatascience.com/why-kubernetes-is-a-great-choice-for-data-scientists-e130603b9b2d">Why Kubernetes is a Great Choice for Data Scientists</a>. This is an interesting post discussing how Kubernetes can be used in a data science world.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/">Reliable Microservices Data Exchange With the Outbox Pattern</a>. At <a href="/derivco">work</a> we have started looking at <a href="https://twitter.com/debezium">Debezium</a> as a way to get data from the database into other systems, and while I was investigating this, I came across the linked blog-post. If you are interested in how to turn your databases into event stream sources, then this post is a must read!</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://docs.microsoft.com/en-us/sql/sql-server/sql-server-ver15-release-notes?view=sqlallproducts-allversions">SQL Server 2019 preview release notes</a>. Earlier this week, Microsoft released SQL Server 2019 preview CTP 2.5. Some very cool new features! Go and get it!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 16, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/21/interesting-stuff---week-16-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-21T16:36:40+02:00</updated>
    <id>http://nielsberglund.com/2019/04/21/interesting-stuff---week-16-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-net-core-3-preview-4/">Announcing .NET Core 3 Preview 4</a>. Some new interesting features in Preview 4 of .NET Core 3.0. Hope we&rsquo;ll see RTM soon.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://towardsdatascience.com/learn-enough-docker-to-be-useful-b7ba70caeb4b">Learn Enough Docker to be Useful Part 1: The Conceptual Landscape</a>. This post is the first &ldquo;episode&rdquo; in a series about how to learn Docker. It is excellent, and for a Docker newbie as myself quite invaluable!</li>
<li><a href="https://towardsdatascience.com/key-kubernetes-concepts-62939f4bc08e">Key Kubernetes Concepts</a>. This article covers essential Kubernetes concepts, and it’ll help you make a mental model of the most important Kubernetes terms to speed your understanding of the technology.</li>
<li><a href="https://towardsdatascience.com/https-medium-com-bachwehbi-data-lake-an-asset-or-a-liability-c424c74cfde8">Data Lake: an asset or a liability?</a>. This post looks at several important points to take into account when starting a Data Lake project.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/04/18/the-april-release-of-azure-data-studio-is-now-available/">The April release of Azure Data Studio is now available</a>. As the title says; Microsoft has released a new version (April 2019) of Azure Data Studio. There are quite a few new interesting features, and I cannot wait to try out the <a href="https://microsoft.github.io/SandDance/">SandDance</a> extension.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/how-to-create-your-own-deep-learning-project-in-azure-509660d8297">How to create your own Deep Learning Project in Azure</a>. In this article, the author takes us through how to use Azure Databricks with Tensorflow and Keras to build a deep learning project.</li>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/04/16/automated-machine-learning-from-sql-server-with-azure-machine-learning/">Automated machine learning from SQL Server with Azure Machine Learning</a>. This post discusses how to leverage Azure Machine Learning Service from SQL Server Machine Learning Services.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-summit-new-york-2019-session-videos">Kafka Summit New York 2019 Session Videos</a>. The Kafka Summit took place in New York earlier this month. This post links to the session videos.</li>
<li><a href="https://www.confluent.io/blog/dawn-of-devops-managing-and-evolving-schemas-with-confluent-control-center">Dawn of DevOps: Managing and Evolving Schemas with Confluent Control Center</a>. This post is the first in a three-part series of DevOps related &ldquo;stuff&rdquo;. This first post looks at how to use Confluence Control Center to manage and evolve schemas.</li>
<li><a href="https://towardsdatascience.com/beat-cache-invalidation-in-asp-net-core-using-kafka-and-debezium-65cd1d80554d">Beat Cache Invalidation in ASP.NET Core Using Kafka and Debezium</a>. This article discusses how to create a better in-memory cache in ASP.NET Core by using Change Data Capture on a database to send events to Apache Kafka via Debezium.</li>
<li><a href="https://rmoff.net/2019/04/17/pivoting-aggregates-in-ksql/">Pivoting Aggregates in Ksql</a>. This is an excellent post by <a href="https://twitter.com/rmoff">Robin</a> where he show how we can do pivoting of aggregates in KSQL.</li>
</ul>

<h2 id="sql-server-machine-learning-services">SQL Server Machine Learning Services</h2>

<ul>
<li><a href="/2019/04/21/installing-r-packages-in-sql-server-machine-learning-services---iv-permissions/">Installing R Packages in SQL Server Machine Learning Services - IV: Permissions</a>. In this post, I look at permissions required when using <code>CREATE EXTERNAL LIBRARY</code> as well as ownership of the created libraries.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing R Packages in SQL Server Machine Learning Services - IV: Permissions]]></title>
    <link href="http://nielsberglund.com/2019/04/21/installing-r-packages-in-sql-server-machine-learning-services---iv-permissions/" rel="alternate" type="text/html"/>
    <updated>2019-04-21T11:15:19+02:00</updated>
    <id>http://nielsberglund.com/2019/04/21/installing-r-packages-in-sql-server-machine-learning-services---iv-permissions/</id>
    <content type="html"><![CDATA[<p>This post is the fourth in a series about installing R packages in <strong>SQL Server Machine Learning Services</strong> (SQL Server ML Services). To see all posts in the series go to <a href="/sql_server_ml_services_install_packages"><strong>Install R Packages in SQL Server ML Services Series</strong></a>.</p>

<p>Why this series came about is a colleague of mine <a href="https://www.linkedin.com/in/dane-bax/">Dane</a> pinged me and asked if I had any advice as he had issues installing an R package into one of their SQL Server instances. I tried to help him and then thought it would make a good topic for a blog post. Of course, at that time I didn&rsquo;t think it would be more posts than one, but here we are.</p>

<p>In this post, we look at:</p>

<ul>
<li>What permissions <code>CREATE EXTERNAL LIBRARY</code> requires.</li>
<li>The ability to create external libraries with different owners and what impact it has.</li>
</ul>

<p></p>

<p>Let us do a recap to see where we are.</p>

<h2 id="recap">Recap</h2>

<p>In the last post; <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> we looked at how to deploy R packages to SQL Server without having to have file system access to the machine SQL Server runs on.</p>

<p>We achieve this by creating an external library, using a DDL statement <code>CREATE EXTERNAL LIBRARY</code>, on the database we want to use the R package on. What <code>CREATE EXTERNAL LIBRARY</code> does, is it uploads package files to a database from a file path or byte stream. The signature looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM (CONTENT = { &lt;file_spec&gt; }  
    [, PLATFORM = &lt;platform&gt; ]) 
WITH ( LANGUAGE = '&lt;language&gt;' )  
[ ; ] 
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>The arguments we see in <em>Code Snippet 1</em> are:</p>

<ul>
<li><code>library_name</code>: A unique name for the package. The unique:ness is based on the name and the principal id under which it is created. We look closer at that in this post.</li>
<li><code>owner_name</code>: This optional parameter specifies the name of the user or role that owns the external library. More about that later in this post as well.</li>
<li><code>file_spec</code>: The <code>file_spec</code> specifies the content of the package for a specific platform, and it can either be in the form of a file location (local path/network path) or a hex literal.</li>
<li><code>platform</code>: An optional parameter and right now only Windows is supported.</li>
<li><code>language</code>: Specifies the language of the package. In SQL Server 2017 the only supported language is R.</li>
</ul>

<p>One of the examples we used throughout the post looked like this:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R'); 
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create External Library</em></p>

<p>In <em>Code Snippet 2</em> we:</p>

<ul>
<li>Name the external library <code>randomForest</code>.</li>
<li>Indicate where the package file is (it has to be a zipped file).</li>
<li>Set R as the language.</li>
</ul>

<p>The code works fine, but the problem is that the package file has to be in a location where SQL Server can read the file, and this - most likely - requires access to the box where SQL Server is installed.</p>

<p>In the <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">previous post</a> we discussed how we could create an external library from the hex-literal of the package, and we mentioned two different ways to accomplish this:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create an external library from the R package based on the file path in a local SQL Server where we have access to the file system (like <code>localhost</code>).</li>
<li>Get the binary representation from the <code>content</code> column in <code>sys.external_library_files</code> via some XML &ldquo;magic&rdquo;.</li>
<li>Assign the retrieved value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 3 above (local database).</li>
</ol>

<p>Alternatively, you can connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="housekeeping">Housekeeping</h2>

<p>Before we &ldquo;dive&rdquo; into today&rsquo;s topics let us look at the code we use today. This section is here for those of who want to follow along in what we are doing in the post.</p>

<pre><code class="language-sql">USE master;
GO

DROP DATABASE IF EXISTS DataScienceDB;
GO

IF EXISTS(SELECT 1 FROM sys.server_principals WHERE name = 'dane')
BEGIN
  DROP LOGIN dane;
END

CREATE LOGIN dane
WITH PASSWORD = 'password1234$';

IF EXISTS(SELECT 1 FROM sys.server_principals WHERE name = 'nielsb')
BEGIN
  DROP LOGIN nielsb;
END

CREATE LOGIN nielsb
WITH PASSWORD = 'password1234$';

CREATE DATABASE DataScienceDB;
GO

USE DataScienceDB;
GO

CREATE USER dane
FROM LOGIN dane;

CREATE USER nielsb
FROM LOGIN nielsb;

ALTER ROLE db_owner
  ADD MEMBER nielsb;
GO

USE master;
GO

GRANT EXECUTE ON sp_execute_external_script TO public;
GO

USE DataScienceDB;
GO

GRANT EXECUTE ANY EXTERNAL SCRIPT TO dane;
GRANT EXECUTE ANY EXTERNAL SCRIPT TO nielsb;
GO

USE DataScienceDB;
GO
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Create Logins, Database and Users</em></p>

<p>In <em>Code Snippet 3</em> we create some logins as well as a database and in that database users for the logins. As you see, we do continue with the &ldquo;theme&rdquo; of Dane the data scientist wanting to do &ldquo;stuff&rdquo; in the database. As <code>nielsb</code> is seen to be &ldquo;trustworthy&rdquo; (take that Dane), we add him to the <code>db_owner</code> role.</p>

<p>In the last part of <em>Code Snippet 3</em> we assign some permissions to <code>sp_execute_external_script</code>, as we did in the post <a href="/2018/06/24/sp_execute_external_script-and-permissions/">sp_execute_external_script and Permissions</a>.</p>

<p>Oh, and if you want to follow along, ensure you download the <code>randomForest</code> package from <a href="https://cran.r-project.org/bin/windows/contrib/3.6/randomForest_4.6-14.zip">here</a>.</p>

<h2 id="permissions">Permissions</h2>

<p>Let us look at what permissions we need when creating an external library. Here is what we do:</p>

<ul>
<li>Log on to SQL Server and the <code>DataScienceDB</code> database as <code>sa</code>.</li>
<li>Drop the <code>randomForest</code> external library if you have created it: <code>DROP EXTERNAL LIBRARY randomForest</code>.</li>
<li>Restart the <em>Launchpad</em> service, this is to clean up properly.</li>
</ul>

<p>After we restart the <em>Launchpad</em> service we want to create an external library as the user <code>dane</code>:</p>

<pre><code class="language-sql">EXECUTE AS USER = 'dane';

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R');
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Creating External Library as Dane</em></p>

<p>In <em>Code Snippet 4</em> we see how we emulate being logged in as user <code>dane</code>: <code>EXECUTE AS USER = 'dane'</code> and how we then execute. Unfortunately, when we run the code we get an error:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_perm_error1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Permission Error</em></p>

<p>In <em>Figure 1</em> we see that <code>dane</code> does not have permission to <code>CREATE EXTERNAL LIBRARY</code>. We can fix that quickly:</p>

<pre><code class="language-sql">REVERT

GRANT CREATE EXTERNAL LIBRARY TO Dane;

EXECUTE AS USER = 'dane';

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R');
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Grant Permissions</em></p>

<p>In <em>Code Snippet 5</em> we:</p>

<ul>
<li><code>REVERT</code> back from the <code>dane</code> user to <code>sa</code>.</li>
<li><code>GRANT</code> permissions to <code>dane</code> to create external libraries.</li>
<li>Switch back to <code>dane</code>.</li>
<li>Execute as <code>dane</code>.</li>
</ul>

<p>However, when we execute as <code>dane</code> we get another error:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_perm_error2.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Impersonation Error</em></p>

<p>We have moved past the permission error, as we in <em>Figure 2</em> see that we do not get the permission error, but we get another error, something about impersonation. What is this about, can it be related to what roles <code>dane</code> is in (remember he is only part of <code>PUBLIC</code>)? Let us test that theory, and let us use <code>nielsb</code> who is more trusted than <code>dane</code>, and is part of <code>db_owner</code>.</p>

<p>So what we do is we copy the code in <em>Code Snippet 5</em>, but replace <code>EXECUTE AS USER = 'dane'</code> with <code>EXECUTE AS USER = 'nielsb'</code>. The assumption is that being part of <code>db_owner</code> should fix this, but when <code>nielsb</code> executes he gets the same error as in <em>Figure 2</em>.</p>

<blockquote>
<p><strong>NOTE:</strong> Notice that we did not have to give <code>nielsb</code> explicit permissions to create external libraries. He has those permissions implicitly just by being part of the <code>db_owner</code> role.</p>
</blockquote>

<p>The problem we run into here is that even if you have the correct permissions to create an external library, you do not have the correct permissions to execute something that reads from the file system. So how do we solve this, we have two options:</p>

<ol>
<li>Add the user to the <code>sysadmin</code> server role.</li>
<li>Create the external library from the package hex-literal.</li>
</ol>

<p>Option 1 is quick and dirty, but I would not recommend it (<code>dane</code> as <code>sysadmin</code>???!!!). Option 2 is better and seeing that you most likely use hex-literal anyway when you deploy to a remote SQL Server it makes sense.</p>

<p>So if you want to follow along in this post, I recommend you go and read up on, in <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a>, how to generate a hex literal from an R Package. We continue when you are back.</p>

<p>Welcome back!</p>

<p>After having read the <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">post</a> above we now have a hex-literal for the <code>randomForest</code> package. Let <code>dane</code> use that to create an external library from:</p>

<pre><code class="language-sql">REVERT

EXECUTE AS USER = 'dane';

DECLARE @hexLit varbinary(max) = 
0x504B03040A00000000009982964C0000000000000000000000000D00000072...
4154494f4e95514d6f83300c3d0f89ff60e504520b1dbd4c953854d5a61dda1e...
...

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = @hexLit)
WITH (LANGUAGE = 'R');
GO

SELECT * FROM sys.external_libraries
</code></pre>

<p><strong>Code Snippet 6:</strong>  <em>Create External Library from Hex Literal Variable</em></p>

<p>In <em>Code Snippet 6</em> we see how we:</p>

<ul>
<li>Emulate <code>dane</code>.</li>
<li>Assign the hex-literal value to the variable.</li>
<li>Call <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ul>

<p>All works OK, but the last <code>SELECT</code> does not return anything. Did we silently fail? Let us try to find out:</p>

<pre><code class="language-sql">REVERT

SELECT * FROM sys.external_libraries
</code></pre>

<p><strong>Code Snippet 7:</strong>  <em>Retrieving External Libraries as sa</em></p>

<p>We see in <em>Code Snippet 7</em> how:</p>

<ul>
<li>We<code>REVERT</code> back to <code>sa.</code></li>
<li>We do a <code>SELECT</code> against <code>sys.external_libraries</code>.</li>
</ul>

<p>When we run the code, the result is like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_view_libs1.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Result of Selecting as sa</em></p>

<p>Aha, <em>Figure 3</em> shows us that <code>dane</code> managed to create the external library, cool! If we now want to drop the library, only <code>dane</code> can do that, and he needs to have <code>ALTER EXTERNAL LIBRARY</code> permissions. We discuss more why <code>dane</code> is the only one that can drop the library later in this post, together with why I have outlined three of the columns in <em>Figure 3</em>.</p>

<blockquote>
<p><strong>NOTE:</strong> The reason <code>dane</code> does not get any results when he tries to <code>SELECT</code> against <code>sys.external_libraries</code> is because of a bug in SQL Server 2017. That particular bug is fixed in CU2, so it should not be an issue.</p>
</blockquote>

<h4 id="permissions-summary">Permissions Summary</h4>

<p>Let us do a quick summary of what we have discussed so far:</p>

<ul>
<li>To create an external library from a hex-literal you need to be part of the <code>db_owner</code> role, or have explicit <code>CREATE EXTERNAL LIBRARY</code> permissions.</li>
<li>To create an external library from a file path you need to be part of the <code>sysadmin</code> server role.</li>
</ul>

<h2 id="authorization-ownership">Authorization &amp; Ownership</h2>

<p>Now, when <code>dane</code> has created an external library let us just check that <code>dane</code> actually can use it:</p>

<pre><code class="language-sql">REVERT

EXECUTE AS USER = 'dane';

EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'library(&quot;randomForest&quot;)'
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Execute as dane Using External Library</em></p>

<p>When we run the code in <em>Code Snippet 8</em> it all works! Let us now see what happens when <code>sa</code> tries to execute:</p>

<pre><code class="language-sql">REVERT

EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'library(&quot;randomForest&quot;)'
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Execute as sa Using External Library</em></p>

<p>We see in <em>Code Snippet 9</em> how we <code>REVERT</code> back to <code>sa</code>, (as that was what we logged in as), and we then call <code>sp_execute_external_script</code>. However, when we execute, the result is:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_exec_error1.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Error When Executing as sa</em></p>

<p>That is strange, the error we see in <em>Figure 4</em> says that the <code>randomForest</code> package does not exist, even though <em>Figure 3</em> shows it. The reason for this can be explained by looking at <em>Figure 3</em> more closely, and especially the three outlined columns: <code>principal_id</code>, <code>scope</code>, and <code>scope_desc</code>.</p>

<p>We see in <em>Figure 3</em> how the <code>principal_id</code> column, (outlined in red), has a value of 5, which happens to be the database principal id of <code>dane</code>. When you create an external library, and you do not specifically set a value for <code>owner_name</code> you become the owner. So what about the two columns outlined in yellow; <code>scope</code>, and <code>scope_desc</code>. They define who can use the library, and any library with an owner other than <code>dbo</code> is private, which means that only the owner can use it. So that explains, (from above), why only <code>dane</code> can drop the library.</p>

<p>So what about <code>nielsb</code>, he is part of the <code>db_owner</code> role, what happens when he creates an external library? Well, do what we did in <em>Code Snippet 6</em>, but replace <code>EXECUTE AS USER = 'dane'</code> with <code>EXECUTE AS USER = 'nielsb'</code>, and run the code. Since <code>nielsb</code> is part of <code>db_owner</code> the <code>SELECT</code> statement works and returns this:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_view_libs2.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Multiple Libraries - I</em></p>

<p>We now have two <code>randomForest</code> libraries, as we see in <em>Figure 5</em>, and these two libraries have different owners as we see from the <code>principal_id</code> (5 for <code>dane</code>, and 6 for <code>nielsb</code>). They are both <code>PRIVATE</code> in scope, so only <code>dane</code> can use the external library with an id of 1, and <code>nielsb</code> only the library with an id of 2. If <code>sa</code> tried to run the code in <em>Code Snippet 9</em> it would fail as in <em>Figure 4</em>.</p>

<p>The above makes sense, kind of. The question is why the library <code>nielsb</code> created is <code>PRIVATE</code> as <code>nielsb</code> belongs to the <code>db_owner</code> role? The answer is what I wrote above, about not setting a value for <code>owner_name</code>. As <code>nielsb</code> did not indicate an owner name, he became the owner, and any libraries not owned by the <code>dbo</code> principal is always <code>PRIVATE</code>. However, seeing that <code>nielsb</code> is in the <code>db_owner</code> role, he can run some code like this:</p>

<pre><code class="language-sql">REVERT

EXECUTE AS USER = 'nielsb';

DECLARE @hexLit varbinary(max) = 
0x504B03040A00000000009982964C0000000000000000000000000D00000072...
4154494f4e95514d6f83300c3d0f89ff60e504520b1dbd4c953854d5a61dda1e...
...

CREATE EXTERNAL LIBRARY randomForest
AUTHORIZATION dbo
FROM (CONTENT = @hexLit)
WITH (LANGUAGE = 'R');
GO

SELECT * FROM sys.external_libraries
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Create External Library with dbo as Owner</em></p>

<p>In <em>Code Snippet 10</em> we see how we set the <code>owner_name</code> to <code>dbo</code>, and when we run the code the result of the <code>SELECT</code> is like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_view_libs3.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>Multiple Libraries - II</em></p>

<p>We see <em>Figure 6</em> 3 libraries and the last one has a <code>principal_id</code> of 1 (<code>dbo</code>), and the scope is <code>PUBLIC</code>. If you want to you can <code>REVERT</code> back to <code>sa</code> and execute the code in <em>Code Snippet 9</em>. This time it works, as one of the <code>randomForest</code> libraries are <code>PUBLIC</code>.</p>

<blockquote>
<p><strong>NOTE:</strong> No, <code>dane</code> cannot set the <code>owner_name</code> to <code>dbo</code> as he does not have sufficient privileges, (he is not part of <code>db_owner</code>).</p>
</blockquote>

<p>We have now three different libraries with the same name, how does the engine know what library to load, and from where? That is a good question, let us run some code we used in the <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">previous post</a>:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'
                    OutputDataSet &lt;- data.frame(
                    installed.packages()[,c(&quot;Package&quot;, &quot;LibPath&quot;)]);'
WITH RESULT SETS ((Package nvarchar(255), LibPath nvarchar(2000)));
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>View R Packages</em></p>

<p>The code in <em>Code Snippet 11</em> retrieves installed R packages, and if we run the code as <code>sa</code> we get the following result:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_lib_path1.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>Randomforest Library Path for sa</em></p>

<p>What is interesting in <em>Figure 7</em> is that we only see one <code>randomForest</code> library, whereas if we execute the same code as <code>dane</code> we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs4_lib_path2.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Randomforest Library Path for dane</em></p>

<p>When we look at <em>Figure 8</em> we see two different library paths (where the package is) for the two <code>randomForest</code> packages. We see how they differ based on database id, (5 in both cases), and principal id, where the first one has a principal id of 5, (<code>dane</code>), and the second 1, (<code>dbo</code>). What we have seen here explains the error we saw in <em>Figure 4</em> when we tried to execute as <code>sa</code> - the package was not available to <code>sa</code>. We can also assume that packages load based on principal id, and the resolution logic and order is like so:</p>

<ol>
<li>Load a package which matches on name and principal id.</li>
<li>Load a package which matches on name and is public.</li>
<li>Load a package which matches on name and is located in the default library path.</li>
</ol>

<h2 id="summary">Summary</h2>

<p>In this post, we looked at permissions required when creating external libraries, and also ownership of the libraries.</p>

<p>To create an external library, you need to have explicit <code>CREATE EXTERNAL LIBRARY</code> permissions, or be - at least - part of the <code>db_owner</code> role. If you want to create a library based on a package path, instead of a hex-literal, you need to also to be in the <code>sysadmin</code> server role.</p>

<p>When you create an external library the library is owned by you, and can only be used by you - it is <code>PRIVATE</code>. However, if you set the <code>owner_name</code> to <code>dbo</code>, the library is <code>PUBLIC</code> and can be used by any user.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 15, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/14/interesting-stuff---week-15-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-14T18:24:53+02:00</updated>
    <id>http://nielsberglund.com/2019/04/14/interesting-stuff---week-15-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/steeltoe-pcf">Enabling .NET Apps with Monitoring and Management Using Steeltoe</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation discussing using the Steeltoe Management framework to enable a .NET application with performance monitoring, management diagnostic endpoints, and distributed tracing on PCF.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="http://highscalability.com/blog/2019/4/8/from-bare-metal-to-kubernetes.html">From Bare-Metal To Kubernetes</a>. A very interesting blog post which talks about going from a bare metal infrastructure to a highly scalable Kubernets infrastructure running in the cloud. If you are thinking about moving to Kubernetes, the post is well worth a read.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="http://muratbuffalo.blogspot.com/2019/04/azure-cosmos-db-microsofts-cloud-born.html">Azure Cosmos DB: Microsoft&rsquo;s Cloud-Born Globally Distributed Database</a>. An excellent blog post by <a href="https://twitter.com/muratdemirbas">Murat</a> where he discusses the workings of Azure Cosmos DB. This post is a must read if you are interested in the inner workings of Cosmos DB.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/monitoring-data-replication-in-multi-datacenter-apache-kafka-deployments">Monitoring Data Replication in Multi-Datacenter Apache Kafka Deployments</a>. A blog post which describes how to use Confluent Replicator and Confluent Control Center to monitor Kafka deployment and replication between multiple data centers.</li>
</ul>

<h2 id="sql-server-machine-learning-services">SQL Server Machine Learning Services</h2>

<ul>
<li><a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a>. Six months after I posted the <a href="/2018/06/30/installing-r-packages-in-sql-server-machine-learning-services---ii/">second post</a> in the <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series I posted the third &ldquo;episode&rdquo;. In this post, we look at how to install R packages in SQL Server Machine Learning Services using the T-SQL DDL command <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Installing R Packages in SQL Server Machine Learning Services - III]]></title>
    <link href="http://nielsberglund.com/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/" rel="alternate" type="text/html"/>
    <updated>2019-04-10T06:36:16+02:00</updated>
    <id>http://nielsberglund.com/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/</id>
    <content type="html"><![CDATA[<p>This post is the third in a series about installing R packages in <strong>SQL Server Machine Learning Services</strong> (SQL Server ML Services). To see all posts in the series go to <a href="/sql_server_ml_services_install_packages"><strong>Install R Packages in SQL Server ML Services Series</strong></a>.</p>

<p>Why this series came about is a colleague of mine <a href="https://www.linkedin.com/in/dane-bax/">Dane</a> pinged me and asked if I had any advice as he had issues installing an R package into one of their SQL Server instances. I tried to help him and then thought it would make a good topic for a blog post. Of course, at that time I didn&rsquo;t think it would be more posts than one, but here we are.</p>

<p>In this post, we look at how we can use T-SQL and DDL commands to install packages in a remote SQL Server.</p>

<p></p>

<p>Let us do a recap to see where we are.</p>

<h2 id="recap">Recap</h2>

<p>The first <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">post</a> in the series gave an overview of what ways we can install packages in the external R engine in SQL Server ML Services:</p>

<ul>
<li>R packet managers</li>
<li>T-SQL</li>
<li>RevoScaleR</li>
</ul>

<p>The <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">post</a> then went into details about using R packet managers, where an R packet manager is an R command line tool or GUI installed on the SQL Server Machine Learning Services machine. The packet manager should be run with elevated permissions and target the R engine for the instance on which you want to install the package. The easiest is to use either of the R tools that come as part of SQL Server&rsquo;s R service:</p>

<ul>
<li>The command line tool: <code>Rterm.exe</code>.</li>
<li>The GUI: <code>Rgui.exe</code>.</li>
</ul>

<p>These two packet managers live in the <code>\\&lt;path_to_SQL_Server_instance&gt;\R_SERVICES\bin\x64</code> directory. When you install packages via an R packet manager, they can only be installed to the default packet library for that instance. You find the library at: <code>\\&lt;path_to_SQL_Server_instance&gt;\R_SERVICES\library</code>.  The file system folder for this library has restricted access and you need elevated permissions to write to this folder. Typical code for installing packages from a packet manager can look like so:</p>

<pre><code class="language-r"># set the library path
libPath &lt;- C:\\path_to_SQL_Server_instance&gt;\\R_SERVICES\\library
install.packages(&quot;pkg_name&quot;, lib = libPath, 
                  repos = &quot;url_for_the_repo&quot;, 
                  dependencies = TRUE)
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Install Packages Command</em></p>

<p>In <em>Code Snippet 1</em> we use <code>install.packages</code> to install &ldquo;pkg_name&rdquo; to a hardcoded library path.</p>

<p>Using an R Package manager is the most straight forward way to install R packages, but the downside with it is that you need admin rights on the SQL Server box. Having admin rights on a SQL Server box in production can be an issue, and in <a href="/2018/06/30/installing-r-packages-in-sql-server-machine-learning-services---ii/">Installing R Packages in SQL Server Machine Learning Services - II</a> we looked at how we can install packages without having admin rights, by using RevoScaleR:</p>

<ul>
<li>To use RevoScaleR for package installation both the SQL Server instance as well as the database need to be enabled for package management. You enable package management via <code>RegisterRExt.exe</code> tool and the <code>/installpkgmgmt</code> option. There are additional flags for database enabling, authentication and so forth.</li>
<li>When enabling the database the process creates a table, stored procedures and roles.</li>
<li>For a user to be able to install packages he needs to have necessary permissions on <code>sp_execute_external_script</code> as well as the <code>EXECUTE ANY EXTERNAL SCRIPT</code> permission. He also needs to be in a role which allows him to install packages.</li>
<li>The roles that the enabling process creates are: <code>rpkgs-users</code>, <code>rpkgs-private</code> and <code>rpkgs-shared</code>.</li>
<li>The roles which allow the user to install packages are <code>rpkgs-private</code> and <code>rpkgs-shared</code> (and <code>db_owner</code>).</li>
<li>The roles define the scope of the installed packages: <code>private</code> and <code>shared</code>.</li>
<li>When a user installs a package with <code>private</code> scope, only he can see and use the package.</li>
<li>If the user installs a package with <code>shared</code> scope, all users in any of the roles, including <code>rpkgs-users</code> can use that package. The user needs to be in the <code>rpkgs-shared</code> (or <code>db_owner</code>) to install a <code>shared</code> package.</li>
<li>You use the function <code>rxInstallPackages</code> to install a package, and the function needs to run in an <em>SQLCC</em>.</li>
<li>When the user calls <code>rxInstallPackages</code> he needs to define which scope the package has through the <code>scope</code> argument. If the <code>scope</code> is not defined, it defaults to <code>private</code>.</li>
<li>To use a package, either in <code>private</code> or <code>shared</code> scope, the code needs to run in <em>SQLCC</em>.</li>
<li>For a package that does not know <em>SQLCC</em>, the functions in the package can be run via <code>rxExec</code>.</li>
</ul>

<h2 id="housekeeping">Housekeeping</h2>

<p>Before we &ldquo;dive&rdquo; into today&rsquo;s topics let us look at the code we use today. This section is here for those of you who want to follow along in what we are doing in the post.</p>

<pre><code class="language-sql">USE master;
GO

DROP DATABASE IF EXISTS DataScienceDB;
GO

DROP DATABASE IF EXISTS DataScienceDBRemote;
GO

CREATE DATABASE DataScienceDB;
GO

CREATE DATABASE DataScienceDBRemote;
GO
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create Databases</em></p>

<p>In <em>Code Snippet 2</em> we create two databases; <code>DataScienceDB</code> and <code>DataScienceDBRemote</code> where the latter is to emulate a database on a remote SQL Server instance. In previous posts, we have created logins and users, but in this post, we only log in as <code>sa</code>.</p>

<h2 id="installing-r-packages-using-t-sql">Installing R Packages Using T-SQL</h2>

<p>In the <em>Recap</em> above we said that in previous posts we have looked at installing R packages either by using R package managers on the SQL Server box, or doing it remotely via script using RevoScaleR. The third option we have is to do it via a T-SQL statement. More specifically through a statement introduced in SQL Server 2017: <code>CREATE EXTERNAL LIBRARY</code>.</p>

<blockquote>
<p><strong>NOTE:</strong> In SQL Server 2017 only R packages are supported whereas, in SQL Server 2019 R, Python and Java are supported. For both SQL Server 2017 and 2019 (up to and including CTP 2.3) only the Windows platform is supported. For SQL Server 2019, Linux may be added as a supported platform in later CTP releases.</p>
</blockquote>

<p>What <code>CREATE EXTERNAL LIBRARY</code> does is it uploads package files to a database from a file path or byte stream. The signature looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM (CONTENT = { &lt;file_spec&gt; }  
    [, PLATFORM = &lt;platform&gt; ]) 
WITH ( LANGUAGE = '&lt;language&gt;' )  
[ ; ] 
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Signature CREATE EXTERNAL LIBARY</em></p>

<p>The arguments we see in <em>Code Snippet 3</em> are:</p>

<ul>
<li><code>library_name</code>: A unique name for the package. When we create an external library for an R package, the name has to be the actual package name. While this may seem obvious, I mention it as when you create external libraries for Java code the name does not matter. We discussed this in the <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a> post. When I say the package name has to be unique, the unique:ness is based on the name and the principal id under which it is created. We talk more about that in a future post.</li>
<li><code>owner_name</code>: This optional parameter specifies the name of the user or role that owns the external library. More about this in a future post as well.</li>
<li><code>file_spec</code>: The <code>file_spec</code> specifies the content of the package for a specific platform, and it can either be in the form of a file location (local path/network path) or a hex literal. If we want to install an R package from a file location, the package needs to be in the form of a zipped archive file. If we install based on a hex-literal, the hex-literal need to derive from the package zip file.</li>
<li><code>platform</code>: The <code>PLATFORM</code> parameter, which defines the platform for the content of the library. The <code>PLATFORM</code> parameter defaults to the platform on which SQL Server runs on, and since <code>CREATE EXTERNAL LIBRARY</code> is only supported on Windows, for now, we do not set it.</li>
<li><code>language</code>: Specifies the language of the package. For this post we only deal with <code>R</code>, and - as I mentioned above - in SQL Server 2017, R is the only language supported.</li>
</ul>

<h2 id="using-create-external-library">Using CREATE EXTERNAL LIBRARY</h2>

<p>To see how to use <code>CREATE EXTERNAL LIBRARY</code> we want to install the <code>randomForest</code> package into our <code>DataScienceDB</code> database. We start with downloading the <code>randomForest</code> zip archive to a directory which is readable by SQL Server. I have it at <code>W:\randomForest_4.6-14.zip</code>. We log in to the server and database as <code>dbo</code> (<code>sa</code> login), and we are ready to execute the <code>CREATE EXTERNAL LIBRARY</code> DDL:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R'); 
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create External Library</em></p>

<p>As we see in <em>Code Snippet 4</em> I name the external library <code>randomForest</code>, as that is the name of the R package, and I set the location of where the package <code>zip</code> file is. Before we execute the code in <em>Code Snippet 4</em>, let us look at what R packages we have installed already:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'
                    OutputDataSet &lt;- data.frame(
                    installed.packages()[,c(&quot;Package&quot;, &quot;LibPath&quot;)]);'
WITH RESULT SETS ((Package nvarchar(255), LibPath nvarchar(2000)));
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>View R Packages</em></p>

<p>When we execute the code in <em>Code Snippet 5</em> we see something like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_inst_pkgs.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>View Installed R Packages - I</em></p>

<p>In <em>Figure 1</em> we see some of the installed R packages and notice that we do not see randomForest. Also, notice the <code>LibPath</code> column outlined in red. Remember how I mentioned in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a> how, when using SQL Server ML Services, we install packages to a specific library which SQL Server then loads the packages from. That location is the <code>LibPath</code> in <em>Figure 1</em>.</p>

<blockquote>
<p><strong>NOTE:</strong> As we see later in this post, what I said above about only one location is not entirely true.</p>
</blockquote>

<p>The last thing to do before we execute the code in <em>Code Snippet 4</em> is to browse around in <em>File Explorer</em> and look at a directory under <code>C:\&lt;path_to_SQL_instance&gt;\MSSQL</code>. When we look around we see a directory named <code>ExternalLibraries</code>, and when we &ldquo;drill&rdquo; into it we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib1.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>ExternalLibraries Directory</em></p>

<p>Hmm, what is so interesting with this directory we see in <em>Figure 2</em>, it has a subdirectory named <code>R</code>, but otherwise, it is empty? Well, the name is interesting: <code>ExternalLibraries</code>. I wonder if it has anything to do with creating external libraries? So to find out we execute the code in <em>Code Snippet 4</em>.</p>

<p>Strange, after we execute the code in <em>Code Snippet 4</em> nothing changes in the directories we look at. Are we wrong in our assumptions about the directories, or did the code fail? In either case, how can we find out?</p>

<p>Creating an external library is very similar to creating an SQLCLR assembly, and if you have ever created an SQLCLR assembly you are probably aware of a couple of catalog views that gives us information about the assemblies:</p>

<ul>
<li><code>sys.assemblies</code>: base catalog view for assemblies with one row per assembly created in the database.</li>
<li><code>sys.assembly_files</code>: contains the binary representation of the assembly files.</li>
</ul>

<p>For external libraries we have similar catalog views:</p>

<ul>
<li><code>sys.external_libraries</code>: base catalog view for external libraries with one row per external library created in the database.</li>
<li><code>sys.external_library_files</code>: contains the binary representation of the external library files.</li>
</ul>

<p>So, if we successfully created the external library we <em>should</em> see something in <code>sys.external_libraries</code>:</p>

<pre><code class="language-sql">SELECT * 
FROM sys.external_libraries;
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>View External Libraries</em></p>

<p>When we execute the code in <em>Code Snippet 6</em> we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Installed External Library</em></p>

<p>Yes, when we look at <em>Figure 3</em> we see that we have created an external library. The columns we see represents:</p>

<ul>
<li><code>external_library_id</code>: the id of the external library as assigned by the database.</li>
<li><code>name</code>: name given to it during creation.</li>
<li><code>principal_id</code>: id of the owner, (principal), of the library.</li>
<li><code>language</code>: name of the language of the library. As mentioned before; in SQL Server 2017, only R, in SQL Server 2019; R, Python, and/or Java.</li>
<li><code>scope</code>: defines who can access the library, 0 for <code>PUBLIC</code>, 1 for <code>PRIVATE</code>. More about that in a.</li>
<li><code>scope_desc</code>: literal description of the scope.</li>
</ul>

<p>Let us see if we can use it the external library:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'library(&quot;randomForest&quot;)'
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Load R Package</em></p>

<p>Admittedly the code in <em>Code Snippet 6</em> does not accomplish much, but when we execute it we can tell whether we have succeeded in creating the external library:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib2.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Execute randomForest</em></p>

<p>From what is outlined in red in <em>Figure 4</em> we see that we have successfully executed against the <code>randomForest</code> package. We also see how external libraries only get loaded and &ldquo;properly&rdquo; installed at first use (blue outline). Cool, so that worked. What about the <code>ExternalLibraries</code> directory:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib3.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>ExternalLibraries after First Execution</em></p>

<p>So, our assumption above regarding <code>ExternalLibraries</code> were correct; the directory contains the actual packages for the external libraries we create. We see in <em>Figure 5</em> how there are new directories, and how we have a <code>randomForest</code> directory which contains the <code>randomForest</code> package.</p>

<blockquote>
<p><strong>NOTE:</strong> The number 5 in <em>Figure 5</em> refers to the database id, and the number 1 beneath the 5 is the id of the external library (<code>external_library_id</code>). So the databases have their own top-level directory, named after the database id. Underneath the database id directory is the individual external library directories identified by the external library id.</p>
</blockquote>

<p>When we execute the code in <em>Code Snippet 5</em> we get:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib4.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>View Installed R Packages - II</em></p>

<p>We now see in <em>Figure 6</em> how the <code>randomForest</code> package comes up as an installed packet (outlined in red), and we see the installation path (highlighted in yellow), and this is where it loads from. So what I said in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a> about SQL only loads packages from one directory is not entirely true, SQL Server can load packages from different locations.</p>

<p>What we have seen so far looks quite good, but the problem is similar to what we discussed in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a>:</p>

<ul>
<li>In the post we said we needed elevated access to the box where the SQL Server instance is.</li>
<li>Here we need access to a directory to which we can copy the package(s) we want to create the external library(s) from, and SQL Server needs read access to that directory. This directory is most likely on the SQL Server server, so we still have the same problem as before.</li>
</ul>

<p>Fortunately, there is a way to solve this. Remember how we said above that the <code>file_spec</code> parameter which, up until now, has been a file path, also can be a hex-literal.</p>

<h2 id="hex-literal-create-external-library">Hex Literal &amp; CREATE EXTERNAL LIBRARY</h2>

<p>The question is then how do I get the hex-literal for a package?</p>

<blockquote>
<p><strong>NOTE:</strong> What follows related to hex literal is more or less a copy from my post <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a>.</p>
</blockquote>

<p>The hex-literal is the actual binary representation of the package, so let us look at a couple of ways we can get hold of the binary package representation:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-database">Local Database</h4>

<p>We know (from above) that the catalog view <code>sys.external_library_files</code> contains the binary representation of the package, and we see that using a query like so:</p>

<pre><code class="language-sql">SELECT l.external_library_id, l.name, lf.content
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest'
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>View External Library</em></p>

<p>In <em>Code Snippet 7</em> we <code>SELECT</code> out the library id, name from the <code>sys.external_libraries</code> view, and <code>content</code> from <code>sys.external_library_files</code>. When we run the code the result looks like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib_content1.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>Binary Representation</em></p>

<p>What we see highlighted in <em>Figure 7</em> is the <code>content</code> column, and we see it contains the hex-literal for the <code>randomForest</code> package.</p>

<p>So if we want to create an external library on a remote SQL Server on which we do not have access to the file system, but we have access to a local SQL Server, we can do this:</p>

<ul>
<li>Create an external library in a database on the local machine, like in <em>Code Snippet 4</em>.</li>
<li>Get the hex-literal from the <code>content</code> column and save it.</li>
</ul>

<p>The naive way, (what I did initially), to get the hex-literal is to use code like this:</p>

<pre><code class="language-sql">DECLARE @hexLit varbinary(max);

SELECT @hexLit = lf.content
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest' 

PRINT @hexLit;
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Get the Hex Literal</em></p>

<p>To get the hex-literal, we see in <em>Code Snippet 8</em> how we:</p>

<ul>
<li>Declare a <code>varbinary(max)</code> variable into which we <code>SELECT</code> the <code>content</code> column.</li>
<li>Print that variable so we can use it.</li>
</ul>

<p>When we execute the code, it looks like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib_hexlit.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Selecting out Hex Literal</em></p>

<p>In <em>Figure 8</em> we see part of the hex literal. However, I mentioned above that what we see in <em>Code Snippet 8</em> is a naive way to do it, and - in most cases - it does not work. Sure you get something that looks like your hex-literal, but if you compare the size of the printed output of the variable, with the size of the value in the column, you see how the size in the column is much bigger. This is because when you do a <code>PRINT</code> either in SSMS or Azure Data Studio the output is limited to a max size of 8000.</p>

<blockquote>
<p><strong>NOTE:</strong> In the <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a> post I used the method above, and it worked. The reason was that the <code>.jar</code> file I wanted to create an external library from, had a size of ~1.5k.</p>
</blockquote>

<p>So what do we do if we want to capture the value of the variable? Well, by using some xml &ldquo;magic&rdquo; we can achieve what we want:</p>

<pre><code class="language-sql">SELECT CONVERT(varchar(max), lf.content, 1)
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest'
FOR XML PATH('');
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Output as XML</em></p>

<p>We see that the code in <em>Code Snippet 9</em> is not that much different from <em>Code Snippet 8</em>. Instead of selecting the <code>content</code> column value into a variable which we <code>PRINT</code>, we <code>CONVERT</code> the binary value to <code>varchar(max)</code> and then indicate we want it exposed as xml (<code>FOR XML PATH('')</code>). When we execute the result is like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_hexlit_xml.png" alt="" /></p>

<p><strong>Figure 9:</strong> <em>Hex Literal XML</em></p>

<p>When you see <em>Figure 9</em> you may ask what the difference is from what we have seen before? When we copy out the content of the column, will we not get just a part of the full value? The answer to that is yes, however, as the column data type is xml, and if we click on it we see something different:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_hexlit_aml_output.png" alt="" /></p>

<p><strong>Figure 10:</strong> <em>XML Output</em></p>

<p>When we clicked on the column a new file opens, and in that file, we get the full hex-literal value, as we see in <em>Figure 10</em>. We can now use the full hex literal to create the <code>randomForest</code> external library on another SQL Server instance.</p>

<p>In this post I do not have access to a remote SQL Server, so what we do instead is that we emulate doing it; we do it against the second database we created in <em>Code Snippet 2</em>; <code>DataScienceDBRemote</code>. After we ensure we have the full hex literal saved off somewhere we:</p>

<ul>
<li>Switch over to <code>DataScienceDBRemote</code> (as <code>sa</code>).</li>
<li>Open a new query window.</li>
</ul>

<p>In the new query window we declare a new variable, let us call it <code>@hexLit</code>, as a <code>varbinary(max)</code>, and we assign the hex literal from <code>DataScienceDB</code> to the variable:</p>

<pre><code class="language-sql">USE DataScienceDBRemote;
GO

DECLARE @hexLit varbinary(max) = 0x504B03040A00000000009982964...
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Assign Hex Literal Value to Variable</em></p>

<p>When we have declared the variable and assigned the hex-literal value to it, we can use it in <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-sql">USE DataScienceDBRemote;
GO

DECLARE @hexLit varbinary(max) = 
0x504B03040A00000000009982964C0000000000000000000000000D00000072...
...

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = @hexLit)
WITH (LANGUAGE = 'R');
GO

SELECT * FROM sys.external_libraries;
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Create External Library from Hex Literal Variable</em></p>

<p>Finally, we execute the code in <em>Code Snippet 11</em> and the <code>SELECT</code> shows us that we now have an external library named <code>randomForest</code> in the &ldquo;remote&rdquo; database.</p>

<p>So this is one way we can get a binary for a package. It may, however, be somewhat convoluted, so let us look at the second way.</p>

<h4 id="generate-binary-from-code">Generate Binary from Code</h4>

<p>Compared to the above, to get the binary representation based on code is probably somewhat easier, and I decided to use Python to create a script which writes the package binary to a file:</p>

<pre><code class="language-python">import binascii

packageFile = input(&quot;Provide full path to the R package \ 
                    file you want to use - \
                    Example: 'W:\\randomForest_4.6-14.zip': &quot;)
fileName = input(&quot;Provide name of the file \
                  you want to create to write the binary to: &quot;)

with open(packageFile, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

f = open(fileName, &quot;w+&quot;)
f.write(hex_bytes)
f.close()
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Python Script to Generate File with Hex Literal</em></p>

<p>We see in <em>Code Snippet 12</em> how the script:</p>

<ul>
<li>Asks for what package zip file to use.</li>
<li>What name to give the output file.</li>
<li>Generates the binary.</li>
<li>Saves it into a file.</li>
</ul>

<p>We now take the code in <em>Code Snippet 12</em> and copy it into a Python script file, for example <code>createBinary.py</code>. When we have the Python file we execute from the command prompt like so:</p>

<pre><code class="language-bash">$ python .\createBinary.py
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Run Python Script</em></p>

<p>After we run the script as per <em>Code Snippet 13</em> we open the created file and grab the hex-literal. We now follow the same procedure as we did in <em>Code Snippet 10</em> and <em>Code Snippet 11</em>, without having the package installed as an external library on the local machine.</p>

<p>However, why do copy and paste when we can connect directly from Python to the remote database and execute <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-python">import pyodbc
import binascii

extLibName = input(&quot;Provide a unique name for \
                   the external library you want to create: &quot;)
packageFile = input(&quot;Provide full path to the zip \
                  file you want to use - \
                  Example: 'W:\\randomForest_4.6-14.zip': &quot;)
dbServer = input(&quot;Provide name/ip address of your \
                  database server. If instance also instance name \ 
                  - Example: 'mydbServer\myInstance: &quot;)
dataBase = input(&quot;Provide name of the database where you \
                  want to create the external library: &quot;)
userName = input(&quot;Provide the user name with which you \
                   want to connect to the server: &quot;)
password = input(&quot;Provide password with which to \
                  connect to the database: &quot;)

with open(packageFile, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

drvr = '{ODBC Driver 17 for SQL Server}'
connStr = f'DRIVER={drvr};SERVER={dbServer};DATABASE={dataBase};UID={userName};PWD={password}'
conn = pyodbc.connect(connStr)
cursor = conn.cursor()

execStmt = f'CREATE EXTERNAL LIBRARY {extLibName}\n'
execStmt = execStmt + f'FROM (CONTENT = {hex_bytes})\n'
execStmt = execStmt + f&quot;WITH (LANGUAGE = 'R');\n&quot;

cursor.execute(execStmt)
conn.commit()    
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>Execute Directly Against the Remote Database</em></p>

<p>So, what do we do in <em>Code Snippet 14</em>? Well, we use the same code as in <em>Code Snippet 12</em> to generate the binary representation. However, instead of writing it to a file we connect to the database using the <code>pyodbc</code> module, and the latest SQL Server ODBC driver. The <code>hex_bytes</code> variable is now a parameter in the <code>CREATE EXTERNAL LIBRARY</code> statement. The name of the external library is passed in as a parameter together with database connection details. It is worth noting that the way the script captures the password variable is not particularly secure. Instead of <code>input</code>, we should use <code>getpass</code> or something similar.</p>

<blockquote>
<p><strong>NOTE:</strong> Unless the user with which you connect is part of the <code>db_owner</code> role, the user needs explicit permissions to execute <code>CREATE EXTERNAL LIBRARY</code>. A future post covers permissions for <code>CREATE EXTERNAL LIBRARY</code>.</p>
</blockquote>

<p>To run this, we do as we did in <em>Code Snippet 12</em>; we copy the code into a Python file and run it from the command line. The code should run OK, and we have created an external library in a database in a remote SQL Server (well, in my case an emulated remote SQL Server).</p>

<h2 id="summary">Summary</h2>

<p>In this post, we set out to solve the issue of how to deploy an R package without having access to the filesystem of the SQL Server where we want to deploy the package to.</p>

<p>We have seen two ways of doing it:</p>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create an external library from the R package based on the file path in a local SQL Server where we have access to the filesystem (like <code>localhost</code>).</li>
<li>Get the binary representation from the <code>content</code> column in <code>sys.external_library_files</code> via some XML &ldquo;magic&rdquo;.</li>
<li>Assign the retrieved value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 3 above (local database).</li>
</ol>

<p>Alternatively, you can connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 14, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/07/interesting-stuff---week-14-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-07T19:33:23+02:00</updated>
    <id>http://nielsberglund.com/2019/04/07/interesting-stuff---week-14-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/starling-bank">Building a Reliable Cloud-Based Bank in Java</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation discussing the experience of Starling Bank, a mobile-only, cloud-based bank that launched in the UK in 2017. The presenter looks at the system architecture of the bank, the design principles that give them the ability to release quickly and reliably, and why they decided to build the back end using Java.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><p><a href="https://www.confluent.io/blog/introducing-confluent-platform-5-2">Introducing Confluent Platform 5.2</a>. During the week Confluent announced the release of Confluent Platform 5., and with it some exciting new features:</p>

<ul>
<li>Confluent Platform is free for single node clusters, it is like a developer edition!</li>
<li>The <code>librdkafka</code> library is now in version 1.0. That is interesting as it brings this library closer to parity with the Java client for Kafka.</li>
<li>New and enhanced query expressions in KSQL.</li>
</ul></li>

<li><p><a href="https://www.confluent.io/blog/putting-events-in-their-place-with-dynamic-routing">Putting Events in Their Place with Dynamic Routing</a>. This is a blog post about how Kafka Streams are a powerful way to enrich data streaming through event-driven architectures. We can dynamically route events to topics, even pulling in the output topic information from another end data system.</p></li>

<li><p><a href="https://www.infoq.com/presentations/starling-bank">KSQL: What’s New in 5.2</a>. As I mentioned above, there are new features in KSQL 5.2, and in this blog post <a href="https://twitter.com/rmoff">Robin</a> discusses some of them!</p></li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 13, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/31/interesting-stuff---week-13-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-31T08:43:04+02:00</updated>
    <id>http://nielsberglund.com/2019/03/31/interesting-stuff---week-13-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://blog.acolyer.org/2019/03/29/calvin-fast-distributed-transactions-for-partitioned-database-systems/">Calvin: fast distributed transactions for partitioned database systems</a>. In this white-paper dissection by <a href="https://twitter.com/adriancolyer">Adrian</a>, he looks at <a href="https://github.com/yaledb/calvin">Calvin</a> which is a transaction scheduling and data replication layer that uses a deterministic ordering guarantee to reduce the high contention costs associated with distributed transactions significantly.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/27/sql-server-2019-community-technology-preview-2-4-is-now-available/">SQL Server 2019 community technology preview 2.4 is now available</a>. What the title says. I downloaded the CTP a couple of days ago, and when I am done with this post, I will install it. Oh, word of warning - if you want to install the <strong>SQL Server 2019 Big Data Cluster</strong>, please remember to uninstall and reinstall <code>mssqlctl</code>, so you get the latest version.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/importance-of-distributed-tracing-for-apache-kafka-based-applications">The Importance of Distributed Tracing for Apache-Kafka-Based Applications</a>. This blog post looks at how to instrument Kafka-based applications with distributed tracing capabilities to make dataflows between event-based components more visible. Very interesting!</li>
<li><a href="https://www.confluent.io/blog/consuming-messages-out-of-apache-kafka-in-a-browser/2">Consuming Messages Out of Apache Kafka in a Browser</a>. The post covers what the title says; how to consume Kafka messages in a browser.</li>
<li><a href="https://rmoff.net/2019/03/28/exploring-ksql-stream-stream-joins/">Exploring KSQL Stream-Stream Joins</a>. This is an excellent post by <a href="https://twitter.com/rmoff">Robin</a> where he covers KSQL and stream to stream joins! I need to go off and <del>play with</del> research this now!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (<em>What Is Niels Doing</em>)</h2>

<p>I am still working on the post about <code>CREATE EXTERNAL LIBRARY</code> in the <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series. Expect it towards the end of this coming week.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 12, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/24/interesting-stuff---week-12-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-24T08:37:01+02:00</updated>
    <id>http://nielsberglund.com/2019/03/24/interesting-stuff---week-12-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/csharp-testing-strategy-tools">Unit Testing Strategies &amp; Patterns in C#</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses design principles and ways to make C# code testable, as well as using testing tools such as Moq, Autofixture, &amp; MsTest.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://medium.com/google-cloud/istio-routing-basics-14feab3c040e">Istio Routing Basics</a>. So, <a href="https://cloud.google.com/istio/">Istio</a> is an open source service mesh, and this blog post covers the basics of Istio and shows what it takes to build an Istio enabled &ldquo;Hello World&rdquo; application.</li>
<li><a href="https://medium.com/@masroor.hasan/tracing-infrastructure-with-jaeger-on-kubernetes-6800132a677">Distributed Tracing Infrastructure with Jaeger on Kubernetes</a>. The blog post I link to here looks at distributed tracing on Kubernetes using Jaeger.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/18/the-march-release-of-azure-data-studio-is-now-available/">The March release of Azure Data Studio is now available</a>. What the title says! There are quite a few new features in the March release of Azure Data Studio, among them: support for SQL Notebooks, PowerShell extension, and PostgresSQL support. Go and get it!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-streams-take-on-watermarks-and-triggers">Kafka Streams’ Take on Watermarks and Triggers</a>. This blog post discusses a new Kafka Streams operator: <code>Suppress</code>. It gives you the ability to control when to forward KTable updates. The <code>Suppress</code> operator comes in very handy in various CEP scenarios: &ldquo;tell me when someone has done &ldquo;a&rdquo; more than &ldquo;x&rdquo; times within &ldquo;y&rdquo; time period&rdquo;. What normally happens is that if someone achieves the &ldquo;a&rdquo;, &ldquo;x&rdquo; times within the &ldquo;y&rdquo; time period every following &ldquo;a&rdquo; would trigger as well. With <code>Suppress</code> you - wait for it - suppress the extra &ldquo;a&rdquo;, until the end of the time period.<br /></li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (<em>What Is Niels Doing</em>)</h2>

<p>Since I did the two posts about <code>CREATE EXTERNAL LIBRARY</code> for Java code (<a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">here</a> and <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">here</a>), I thought it would be a good idea to finish off my <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series. So, I am at the moment working on a post discussing <code>CREATE EXTERNAL LIBRARY</code> in the R world. The post is somewhat like the ones covering Java, but it also covers permissions etc.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 11, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/17/interesting-stuff---week-11-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-17T21:16:22+02:00</updated>
    <id>http://nielsberglund.com/2019/03/17/interesting-stuff---week-11-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/net-core-container-images-now-published-to-microsoft-container-registry/">.NET Core Container Images now Published to Microsoft Container Registry</a>. A post discussing how Microsoft are now publishing .NET Core container images to Microsoft Container Registry (MCR).</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/istio-microservices">Reducing Microservices Architecture Complexity with Istio and Kubernetes</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation which introduces Istio, and explains how the service mesh works, the technology behind it, and how to use it with microservices.</li>
<li><a href="https://www.infoq.com/news/2019/03/microservices-recommendations">Recommendations When Starting with Microservices: Ben Sigelman at QCon London</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article about the mistakes Google made in he beginning when adopting a microservices architecture, and recommendations to avoid making these mistakes when starting with microservices.</li>
</ul>

<h2 id="data-science-machine-learning">Data Science / Machine Learning</h2>

<ul>
<li><a href="https://towardsdatascience.com/machine-learning-with-big-data-86bcb39f2f0b">Machine Learning with Big Data</a>. Data is on overdrive. It’s being generated at break-neck pace. How do we analyze all this data? This article discusses how to easily create a scalable and parallelized machine learning platform on the cloud to process large-scale data.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://eng.uber.com/dbevents-ingestion-framework/">DBEvents: A Standardized Framework for Efficiently Ingesting Data into Uber’s Apache Hadoop Data Lake</a>. This blog post looks at Uber&rsquo;s  DBEvents, a change data capture system designed for high data quality and freshness. It facilitates bootstrapping, ingesting a snapshot of an existing table, and incremental, streaming updates.</li>
<li><a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues">Kafka Connect Deep Dive – Error Handling and Dead Letter Queues</a>. In this blog post <a href="https://twitter.com/rmoff">Robin Moffat</a> looks at several common patterns for handling Kafka Connect problems and examines how the patterns can be implemented.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a>. This post by yours truly looks at how to use <code>CREATE EXTERNAL LIBRARY</code> to deploy Java code without having access to SQL Server&rsquo;s filesystem.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019, Java &amp; External Libraries - II]]></title>
    <link href="http://nielsberglund.com/2019/03/17/sql-server-2019-java--external-libraries---ii/" rel="alternate" type="text/html"/>
    <updated>2019-03-17T17:13:45+02:00</updated>
    <id>http://nielsberglund.com/2019/03/17/sql-server-2019-java--external-libraries---ii/</id>
    <content type="html"><![CDATA[<p>This post is part of the <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a> series of posts, and it is the second post discussing SQL Server 2019, Java and the creation and use of external libraries.</p>

<p>In the previous post about external libraries, we said that they were beneficial as they reduced complexities when deploying code, but there were still some caveats. So, in this post, we look at how to overcome those caveats</p>

<p></p>

<h2 id="recap">Recap</h2>

<p>Let us start with a recap of what we covered in the previous post.</p>

<p>In the last post we saw how we can make the use of Java in SQL Server somewhat less complex (permissions, code paths, etc.), by using external libraries.</p>

<p>We create the external library using the DDL statement <code>CREATE EXTERNAL LIBRARY</code>, and we saw in the post that the signature, somewhat simplified, looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>To be able to use external libraries for your Java code, the code need be packaged either in a <code>.jar</code> file or your class files need to be archived into a <code>.zip</code> file. We give the external library a name, in the <code>file_spec</code> we point to where the file resides, and finally, we set the <code>LANGUAGE</code> parameter to <code>Java</code>:</p>

<pre><code class="language-sql">USE JavaTest;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create External Library</em></p>

<p>The code we see in <em>Code Snippet 2</em> is fairly self-explanatory, where we name the external library <code>myCalc</code> and the code is at <code>W:\javacodepath\MyCalcJar.jar</code>. What is interesting when creating external libraries for Java is that the name does not matter (apart from that it has to be unique).</p>

<p>To see that it has worked we use catalog views to investigate:</p>

<pre><code class="language-sql">SELECT el.name, el.[language], ef.content
FROM sys.external_libraries el
JOIN sys.external_library_files ef
  ON el.external_library_id = ef.external_library_id
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>View External Libraries</em></p>

<p>In <em>Code Snippet 3</em> we do a <code>SELECT</code> against <code>sys.external_libraries</code> and <code>sys.external_library_files</code>, and when we execute the result looks like so:</p>

<p><img src="/images/posts/sql_2k19_java_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>External Libraries View</em></p>

<p>We see in <em>Figure 1</em> some information about the external library. The <code>content</code> column outlined in red is interesting in that it contains the binary representation of the external library. This is like assemblies in SQLCLR. They are persisted to system tables and, when needed, loaded from the tables based on the binary representation. External libraries are the same, persisted to system tables, and when needed they are loaded from those tables.</p>

<p>So by loading the code from the database, we no longer need to worry about permissions and where to load the code from. An additional benefit is that the external libraries are database bound. If you backup and restore the database to another machine, the external libraries are there, as opposed to if you load them from a file location.</p>

<p>As good as this is, there is a problem or rather a caveat. What we have done so far requires the code for the external library to be in a location SQL Server can read. I as a developer may not have access to the file system of the SQL box. So in the rest of this post, we look at some options how we can create an external library on a remote SQL Server, where we do not have access to the file system, but we can access the SQL Server instance via SSMS or in my case, <a href="https://github.com/Microsoft/azuredatastudio">Azure Data Studio</a>.</p>

<h2 id="demo-code">Demo Code</h2>

<p>Before diving into what we want to do, let us look at the code we use today (it looks very similar to the code in the previous post):</p>

<pre><code class="language-sql">USE master
GO

DROP DATABASE IF EXISTS JavaTest;
GO

DROP DATABASE IF EXISTS JavaTestLocal;
GO

DROP DATABASE IF EXISTS JavaTestRemote;
GO

CREATE DATABASE JavaTestLocal;
GO

CREATE DATABASE JavaTestRemote;
GO
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create Databases</em></p>

<p>We see in <em>Code Snippet 4</em> how we create a couple of databases. Since I do not have access to a remote SQL Server right now, I emulate the remote SQL by the <code>JavaTestRemote</code> database. Oh, and the first database I drop, that is the one we used in the previous post. We also need some Java code. We assume the code below is in a source file named <code>Calculator.java</code>:</p>

<pre><code class="language-java">public class Calculator {
    public static short numberOfOutputCols;
    public static int x;
    public static int y;

    static public int[] outputDataCol1;
    static public boolean[][] outputNullMap;

    public static void adder() {
        numberOfOutputCols = 1;
        outputDataCol1 = new int[1];
        outputDataCol1[0] = x + y;
        outputNullMap = new boolean[1][1];
    }
}
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Java Calculator</em></p>

<p>The code in <em>Code Snippet 5</em> is the same we used in <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>. As I mentioned in the <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">last post</a> that if you wonder about the variables in the code, the other posts in the Java <a href="/s2k19_ext_framework_java">series</a> discuss them in detail.</p>

<p>The last thing to do before we can talk about how to solve the issue with having to have access to the file system of the box SQL Server is on is to compile the code in <em>Code Snippet 5</em> and create a <code>.jar</code> for it:</p>

<pre><code class="language-java">$ javac .\Calculator.java
$ jar -cf MyCalcJar.jar .\Calculator.class
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Compile and Create a jar File</em></p>

<p>After running the code in <em>Code Snippet 6</em> we have a <code>.jar</code> file which we use to create the external library.</p>

<h2 id="external-library">External Library</h2>

<p>The question is now how to create the external library on a remote SQL Server instance if we do not have access to the file system on that server? Let us look at <code>CREATE EXTERNAL LIBRARY</code>&rsquo;s signature again (we saw it in the previous <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">post</a>):</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]  
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>Remember how we said in <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>, that <code>file_spec</code> points to the content of the package/code, and we saw in <em>Code Snippet 2</em> how we set <code>file_spec</code> to the path of the file.</p>

<p>However, we also said in the last <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">post</a> that <code>file_spec</code> can be a hex literal, similar to what we do when we create assemblies in SQLCLR. The hex literal is the actual binary representation of the package, and if we can get hold of the binary somehow we are &ldquo;golden&rdquo;. So, let us look at a couple of ways we can get hold of the binary package representation:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-database">Local Database</h4>

<p>Let us start with a way to get the binary from a local database.</p>

<blockquote>
<p><strong>NOTE:</strong> This is similar to what we do at <a href="/derivco">Derivco</a> when we generate SQL statements to deploy SQLCLR assemblies.</p>
</blockquote>

<p>We see in <em>Figure 1</em> the <code>content</code> column, which we said before contains the binary representation of the package. What we do is to log on to the local database <code>JavaTestLocal</code>, and create the external library from the <code>.jar</code> file we created in <em>Code Snippet 6</em>:</p>

<pre><code class="language-sql">USE JavaTestLocal;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Create Local External Library</em></p>

<p>As SQL Server is installed on my local dev-machine, and SQL Server has access to the <code>W:\javacodepath</code> path, the code in <em>Code Snippet 8</em> executes ok.</p>

<p>We know from <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a> and from the summary above how the binary representation of the package is stored in the <code>content</code> column of the <code>sys.external_library_files</code> catalog view. Let us grab the content of the <code>content</code> column:</p>

<pre><code class="language-sql">USE JavaTestLocal;
GO

DECLARE @binrep varbinary(max);

SELECT @binrep = lf.content
FROM sys.external_library_files lf
JOIN sys.external_libraries l
  ON lf.external_library_id = l.external_library_id
WHERE l.name = 'myCalc';

PRINT @binrep;
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Retrieve the Binary Representation</em></p>

<p>We see in <em>Code Snippet 9</em> how we <code>DECLARE</code> a variable <code>@binrep</code> which is a <code>varbinary</code>, and then we <code>SELECT</code> the value of the <code>content</code> column into the variable. We finally <code>PRINT</code> the content of the variable and we get something like so when we execute:</p>

<blockquote>
<p><strong>EDIT (2019-04-10):</strong> The above method works only with packages with a size less than 8k. See <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> for an explanation, and a way around it.</p>
</blockquote>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_binrep.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Binary Representation</em></p>

<p>In <em>Figure 2</em> we see part of the binary value of the package. We copy that into a new query window connected to the remote server and database, and we do a new <code>CREATE EXTERNAL LIBRARY</code>, but instead of a file-path for the <code>CONTENT</code> parameter we paste in the binary representation:</p>

<pre><code class="language-sql">USE JavaTestRemote;
GO

CREATE EXTERNAL LIBRARY myCalcRemote
FROM (CONTENT = 0x504B03041400080808007B34684E...)
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Use Binary as CONTENT</em></p>

<p>We see how the <code>CONTENT</code> parameter in <em>Code Snippet 10</em> now contains the binary value of the external library. After we execute the code in <em>Code Snippet 10</em> we test to see that it has worked by executing on the remote SQL Server:</p>

<pre><code class="language-sql">USE JavaTestRemote;
GO

EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int',
@x = 21,
@y = 21;
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Execute Against Calculator.adder</em></p>

<p>The result of running the code in <em>Code Snippet 11</em> is:</p>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_queryres1.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Result</em></p>

<p>From what we see in <em>Figure 3</em>, everything has worked.</p>

<p>We used the binary representation of an external library on our local SQL Server instance to create an external library on a remote instance. We do this without having access to the remote file system.</p>

<p>That is all well and good, but what if we do not have access to a local SQL Server?</p>

<h4 id="generate-binary-from-code">Generate Binary from Code</h4>

<p>The second way we can get the binary representation is to generate it from code. When I started looking into this post and how to generate the binary representation I first started with C# as I am a .NET guy. However, boy, that was a lot of code (slight exaggeration), and wouldn&rsquo;t it be &ldquo;cool&rdquo; if I could just run a script, and send in a file-path to the package? Everyone told me that Python is what all the &ldquo;cool kids&rdquo; use, so I decided to go with Python, and this is the code I started with:</p>

<pre><code class="language-python">import binascii

filePath = &quot;W:\\javacodepath\\MyCalcJar.jar&quot;

with open(filePath, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify( \
                       bytearray(myArr)).decode('utf-8')

print(hex_bytes)
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Generate Binary from Python</em></p>

<p>When we look at the code in <em>Code Snippet 12</em> we see how:</p>

<ul>
<li>I <code>import</code> the <code>binascii</code> module which contains a number of methods to convert between binary and various ASCII-encoded binary representations.</li>
<li>I hardcode (for now) the file-path to where the <code>.jar</code> file is.</li>
<li>I open the file in binary mode. The <code>&quot;rb&quot;</code> in the <code>open(filePath, &quot;rb&quot;)</code> indicates I want the file as binary.</li>
<li>I read the file into a byte array (<code>myArr</code>).</li>
<li>I turn the byte-array into hex representation, and then I print the hex representation.</li>
</ul>

<p>The code is in a source file named <code>outputBinary.py</code>, and when I execute it from a command prompt I see the following:</p>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_python1.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Python Output</em></p>

<p>The (cropped) binary output in <em>Figure 4</em> is the same as we used in <em>Code Snippet 10</em>. We can now copy the output as we see in <em>Figure 4</em> and do exactly what we did before.</p>

<p>However, why do copy and paste when we can connect directly from Python to the remote database and execute <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-python">import pyodbc
import binascii

filePath = &quot;W:\\javacodepath\\MyCalcJar.jar&quot;
extLibName = 'myCalcRemote'

with open(filePath, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

# connect to db

dbServer = 'localhost\s2k19_ctp23_1'
dataBase = 'JavaTestRemote'
userName = '&lt;some_user_name'
password = '&lt;some_pwd&gt;'

drvr = '{ODBC Driver 17 for SQL Server}'
connStr = f'DRIVER={drvr};SERVER={dbServer};DATABASE={dataBase};UID={userName};PWD={password}'
conn = pyodbc.connect(connStr)
cursor = conn.cursor()

execStmt = f'CREATE EXTERNAL LIBRARY {extLibName}\n'
execStmt = execStmt + f'FROM (CONTENT = {hex_bytes})\n'
execStmt = execStmt + f&quot;WITH (LANGUAGE = 'Java');\n&quot;

cursor.execute(execStmt)
conn.commit()
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Create External Library from Python Code</em></p>

<p>Before we look at the code in <em>Code Snippet 13</em> let us drop the external library we just created in the remote SQL Server instance: <code>DROP EXTERNAL LIBRARY myCalcRemote</code>. This to ensure we are back in a state with no external libraries installed.</p>

<p>So, what do we do in <em>Code Snippet 13</em>? Well, we use the same code as in <em>Code Snippet 12</em> to generate the binary representation, but we do not do a <code>PRINT</code> of it. Instead, we connect to the database using the <code>pyodbc</code> module, and the latest SQL Server ODBC driver. The <code>hex_bytes</code> variable is now a parameter in the <code>CREATE EXTERNAL LIBRARY</code> statement, and we have a hardcoded variable for the name of the external library.</p>

<p>As the code is just sample code, the connection details for the database is also hardcoded. In a real-world scenario, the script should prompt for the various details; file path, name, connection details etc., and assign the inputs to the variables:</p>

<pre><code class="language-python">extLibName = input(&quot;Provide a unique name for \
                   the external library you want to create: &quot;)
filePath = input(&quot;Provide full path to the JAR \
                  file you want to use - \
                  Example: 'W:\\javacodepath\\myJarFile.jar': &quot;)
dbServer = input(&quot;Provide name/ip address of your \
                  database server. If instance also instance name \ 
                  - Example: 'mydbServer\myInstance: &quot;)
dataBase = input(&quot;Provide name of the database where you \
                  want to create the external library: &quot;)
userName = input(&quot;Provide the user name with which you \
                   want to connect to the server: &quot;)
password = input(&quot;Provide password with which to \
                  connect to the database: &quot;)
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>Input Variables</em></p>

<p>It is worth noting that the way the script captures the password variable is not particularly secure. Instead of <code>input</code>, we should use <code>getpass</code> or something similar.</p>

<blockquote>
<p><strong>NOTE:</strong> Unless the user with which you connect is part of <code>db_owner</code>, the user needs explicit permissions to execute <code>CREATE EXTERNAL LIBRARY</code>.</p>
</blockquote>

<p>To test this, you replace the variables in <em>Code Snippet 13</em> with relevant values for your environment and run the code. The code should run OK, and you have now created an external library in a database in a remote SQL Server (well, in my case an emulated remote SQL Server).</p>

<h2 id="summary">Summary</h2>

<p>In this post, we set out to solve the issue of how to create an external library of some Java code without having access to the filesystem of the SQL Server where we want to create the external library.</p>

<p>We have seen two ways of doing it:</p>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create the external assembly from a file-path in a local SQL Server where we have access to the filesystem (like <code>localhost</code>).</li>
<li>Copy the binary representation from the <code>content</code> column in <code>sys.external_library_files</code>.</li>
<li>Assign the copied value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 2 above (local database).</li>
</ol>

<p>Alternatively, you in addition to generate the binary in the script, connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 10, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/10/interesting-stuff---week-10-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-10T13:14:44+02:00</updated>
    <id>http://nielsberglund.com/2019/03/10/interesting-stuff---week-10-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://blog.acolyer.org/2019/03/08/a-generalised-solution-to-distributed-consensus/">A generalised solution to distributed consensus</a>. Distributed consensus is hard! In this blog post <a href="https://twitter.com/adriancolyer">Adrian</a> dissects a white-paper which re-examines the foundations of distributed consensus.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/microsoft-opens-first-datacenters-in-africa-with-general-availability-of-microsoft-azure/">Microsoft opens first datacenters in Africa with general availability of Microsoft Azure</a>. I guess the title says it all! On March 6, Microsoft opened two data centers in South Africa: South Africa North (Johannesburg) and South Africa West (Cape Town). At the moment the offerings are somewhat sparse, but I have no doubt we&rsquo;ll soon see quite a lot of services.</li>
<li><a href="https://azure.microsoft.com/en-us/blog/service-fabric-processor-in-public-preview/">Service Fabric Processor in public preview</a>. Azure Event Hub is an elegant way to ingest data into the Azure ecosystem, and Service Fabric is awesome for hosting and running microservices. Quite often some of the services need to consume from Azure Event Hubs, and until now you have had to write your own consumer, most likely based on <em>Event Processor Host</em>. That changes now with the preview of <em>Service Fabric Processor</em>, which is a new library for consuming events from an Event Hub that is directly integrated with Service Fabric. Awesome!</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-net-core-3-preview-3/">Announcing .NET Core 3 Preview 3</a>. What the title says; .NET Core 3 Preview 3 is available for download. Go and get it!</li>
<li><a href="https://devblogs.microsoft.com/dotnet/collecting-net-core-linux-container-cpu-traces-from-a-sidecar-container/">Collecting .NET Core Linux Container CPU Traces from a Sidecar Container</a>. This blog post gives a step-by-step guide of using a sidecar container to collect CPU trace of an ASP.NET application running in a Linux container.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://101.datascience.community/2019/03/07/microsoft-launches-data-science-certifications/">MICROSOFT LAUNCHES DATA SCIENCE CERTIFICATIONS</a>. In this blog post <a href="https://twitter.com/ryanswanstrom">Ryan</a> discusses 3 new certifications Microsoft recently announced aimed at Data Scientists/Engineers. I have always been skeptic to certifications by vendors, brain dumps anyone, but I will definitely have a look at this.<br /></li>
<li><a href="https://eng.uber.com/machine-learning-capacity-safety/">Using Machine Learning to Ensure the Capacity Safety of Individual Microservices</a>. This is a very interesting post by Uber&rsquo;s engineering team, discussing how they apply Machine Learning to forecast micro-services issues!</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>. Earlier today I published this post, in which I talk about how to deploy Java code to a database, so it can be loaded from there.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019, Java &amp; External Libraries - I]]></title>
    <link href="http://nielsberglund.com/2019/03/10/sql-server-2019-java--external-libraries---i/" rel="alternate" type="text/html"/>
    <updated>2019-03-10T10:22:51+02:00</updated>
    <id>http://nielsberglund.com/2019/03/10/sql-server-2019-java--external-libraries---i/</id>
    <content type="html"><![CDATA[<p>A couple of months ago I wrote a series of posts about one of the new features in SQL Server 2019; the ability to call out to Java code from inside SQL Server.</p>

<p>To see the posts, go to <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a>.</p>

<p>In the posts, we discussed how the Java extension differs from R and Python in that R and Python are an integrated part of the SQL Server install (when enabling in-database analytics), but Java is not. In other words, the use of the Java extension requires Java to be installed beforehand, and this then has implications on permissions. We also discussed how Java is a compiled language, and we execute against a method in a class, whereas with R and Python we send a script to the external engine. The consequence of this is that when we execute Java code, we need to indicate where the compiled code resides, and those locations need specific permissions.</p>

<p>All this creates a level of complexity, and it would potentially be easier if we load the Java code from a well-known place, where we do not need to worry about permissions and so forth.</p>

<p>This post is the first of a couple where we see how new functionality in SQL Server 2019 CTP 2.3 can help.</p>

<p></p>

<h2 id="code-background">Code &amp; Background</h2>

<p>Let us start with looking at the code we use today, and also remind ourselves of some of the complexities when calling Java from SQL server.</p>

<p>So, the code:</p>

<pre><code class="language-java">public class Calculator {
    public static short numberOfOutputCols;
    public static int x;
    public static int y;

    static public int[] outputDataCol1;
    static public boolean[][] outputNullMap;

    public static void adder() {
        numberOfOutputCols = 1;
        outputDataCol1 = new int[1];
        outputDataCol1[0] = x + y;
        outputNullMap = new boolean[1][1];
    }

}
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Java Calculator</em></p>

<p>As we see in *Code Snippet 1`, the code is very simple, and we have seen variants of it in my other <a href="/s2k19_ext_framework_java">Java posts</a>. If you wonder about some of the variables in the code, the previous <a href="/s2k19_ext_framework_java">posts</a> discuss them in detail.</p>

<p>To use the code from SQL Server, we compile the source file <code>Calculator.java</code>: <code>$ javac Calculator.java</code>, into a <code>.class</code> file: <code>Calculator.class</code>.
After compilation, we can now place the <code>Calculator.class</code> in any of the locations a pre-defined <code>CLASSPATH</code> environment variable points to. To call the <code>adder</code> method from inside SQL Server we execute like so:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
    @language = N'Java',
    @script = N'Calulator.adder',
    @params = N'@x int, @y int',
    @x = 21,
    @y = 21;
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Execute from SQL Server</em></p>

<p>By the fact that the <code>.class</code> file is in a <code>CLASSPATH</code> location, the code in <em>Code Snippet 2</em> succeeds, <strong>IF</strong> the right permissions exist on the location.</p>

<blockquote>
<p><strong>NOTE:</strong> The required permission is <code>READ</code> for the <code>ALL APPLICATION PACKAGES</code> group.</p>
</blockquote>

<p>Having the code in a <code>CLASSPATH</code> location is one way to load and execute the code. Another way is to have the code in an arbitrary location and explicitly set a parameter in the SQL call to point to that location:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
    @language = N'Java',
    @script = N'Calculator.adder',
    @params = N'@x int, @y int, @CLASSPATH nvarchar(512)',
    @x = 21,
    @y = 21,
    @CLASSPATH = N'W:\javacodepath';
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Using @CLASSPATH Parameter</em></p>

<p>In <em>Code Snippet 3</em> we see how we set a parameter <code>CLASSPATH</code> to point to where the code is. The permission requirements for this scenario are the same as for when we have a defined <code>CLASSPATH</code>: the location need <code>READ</code> permission for the <code>ALL APPLICATION PACKAGES</code> group.</p>

<blockquote>
<p><strong>NOTE:</strong> You may wonder where the <code>CLASSPATH</code> parameter in <em>Code Snippet 3</em> comes from, as it is not part of the signature of <code>sp_execute_external_script</code>? This parameter is a well-known parameter for the SQL Server Java language extension, and if this parameter exists the extension sets the <code>--classpath</code> option in the <code>java</code> command.</p>
</blockquote>

<p>In the code snippets above we execute against <code>.class</code> files. In the &ldquo;real world&rdquo; however you are unlikely to do that, but instead, you use <code>.jar</code> files. So let us see how we do that from SQL Server. First, we compile the <code>.java</code> source, followed by creating the <code>.jar</code>:</p>

<pre><code class="language-java">$ javac .\Calculator.java
$ jar -cf MyCalcJar.jar .\Calculator.class
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create a jar File</em></p>

<p>After we have created the <code>MyCalcJar.jar</code> as in <em>Code Snippet 4</em>, we copy the <code>.jar</code> to either the <code>CLASSPATH</code> location or an arbitrary location. To execute we call it like so:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int, @CLASSPATH nvarchar(max)',
@x = 21,
@y = 21,
@CLASSPATH = N'W:\javacodepath\MyCalcJar.jar'
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Execute Against a jar File</em></p>

<p>We see in <em>Code Snippet 5</em> how we when we execute against a <code>.jar</code> need to:</p>

<ul>
<li>Set the path to the <code>.jar</code>, using the using the <code>CLASSPATH</code> parameter. This is required <strong>even</strong> if the <code>.jar</code> is in the actual <code>CLASSPATH</code>.</li>
<li>Include the name of the <code>.jar</code> file.</li>
</ul>

<p>We also need to ensure that the permissions mentioned above exist where ever the <code>.jar</code> is.</p>

<p>So the examples above re-enforce what we mentioned in the beginning, Java incurs some complexity which we do not have when executing R/Python code:</p>

<ul>
<li>Where to load the code from.</li>
<li>Permissions on said location.</li>
</ul>

<p>Apart from pointing out the complexities at the beginning of this post I also mentioned that new functionality in SQL Server 2019 CTP 2.3 helps to solve this. That functionality is the ability to create external libraries.</p>

<h2 id="external-libraries">External Libraries</h2>

<p>External libraries in SQL Server enables the ability to load artefacts needed for any new language runtimes and OS platforms supported by SQL Server from the database. For example, if you need an R package that is not part of the default install of the engine you can upload to the database the particular R package as an external library and use it from the database in question. An external library is similar to a CLR assembly in that the actual library exists in the database as a byte-stream <del>and SQL Server loads it from the database</del>.</p>

<blockquote>
<p><strong>EDIT (2019-04-10):</strong> *It so turns out that what I wrote about SQL Server loading from the database is not correct. It loads the pakage(s) from the external library path.  See <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> for more around this.</p>
</blockquote>

<p>You create an external library in a similar to how you create a CLR assembly; you use a DDL statement <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]  
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>In <em>Code Snippet 6</em> we see the signature for <code>CREATE EXTERNAL LIBRARY</code>. We see only the main parts:</p>

<ul>
<li><code>library_name</code> - the name we want the library to have. When we create an external library for Java code we can assign any name we want. However, when we create an external library for R, the name must be the same as what we refer to the package when we load it in the external script.</li>
<li><code>owner_name</code> - optional, and it specifies the name of the user or role that owns the external library.</li>
<li><code>file_spec</code> - this is the content of the package/code. For Java it has to be a <code>.jar</code> file, or a <code>.zip</code> file with relevant <code>.class</code> files in it. The <code>file_spec</code> can be either a path to the file, or a byte array. Part of the <code>file_spec</code> is also the platform on which SQL Server is running. For now, only Windows is supported.</li>
<li><code>language</code> - the language of the package/code.</li>
</ul>

<blockquote>
<p><strong>NOTE:</strong> I mentioned above that we see the main parts of <code>CREATE EXTERNAL LIBRARY</code>, and we have not drilled down in detail. If you are interested in the details look <a href="https://docs.microsoft.com/en-us/sql/t-sql/statements/create-external-library-transact-sql?view=sql-server-ver15">here</a>.</p>
</blockquote>

<p>To see this in practice, we need first to create a database: <code>CREATE DATABASE JavaTest</code>, (we can obviously use an existing db as well). Then, based on the code in <em>Code Snippet 4</em> and <em>Code Snippet 5</em>, the call to create an external library for our calculator looks like so:</p>

<pre><code class="language-sql">USE JavaTest;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Create External Library</em></p>

<p>What we see in <em>Code Snippet 7</em> is how we create an external library named <code>myCalc</code>, where the external library is based on a <code>.jar</code> file at <code>W:\javacodepath\MyCalcJar.jar</code>. The last thing we do is to indicate that the language is <code>Java</code>. As the only platform supported right now is Windows, we do not bother with the <code>PLATFORM</code> parameter.</p>

<p>To verify this works after we execute the code in <em>Code Snippet 7</em> we use exactly the same code as in <em>Code Snippet 2</em>:</p>

<pre><code class="language-sql">USE JavaTest;
GO

EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int',
@x = 21,
@y = 21;
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Execute Java Code Loaded from Database</em></p>

<p>In <em>Code Snippet 8</em> we see how we no longer define the <code>.jar</code> file as a parameter, (what we had to do in <em>Code Snippet 5</em>), but when we execute all works OK.</p>

<p>The question is now where the <code>.jar</code>,(or <code>.zip</code>), loads from. The answer to that is, (like with SQLCLR), that it loads from system tables in the database. When we create an SQLCLR assembly in a database, SQL Server stores the assembly in system tables, and we use catalog views to view the assemblies: <code>sys.assemblies</code>, <code>sys.assembly_files</code>, and so on. External libraries do not use the same underlying tables or catalog views, but to see the external libraries you use:</p>

<ul>
<li><code>sys.external_libraries</code> - contains a row for each external library that has been uploaded into the database.</li>
<li><code>sys.external_library_files</code> - lists a row for each file in the external library.</li>
<li><code>sys.external_libraries_installed</code> - shows what libraries have been loaded, e.g. used.</li>
</ul>

<p>An example of this:</p>

<pre><code class="language-sql">SELECT el.name, el.[language], ef.content
FROM sys.external_libraries el
JOIN sys.external_library_files ef
  ON el.external_library_id = ef.external_library_id
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>View External Libraries</em></p>

<p>When we run the code in <em>Code Snippet 9</em> we get:</p>

<p><img src="/images/posts/sql_2k19_java_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>External Libraries View</em></p>

<p>We see in <em>Figure 1</em> some information about the external library. The <code>content</code> column outlined in red is interesting in that it contains the binary representation of the external library.</p>

<h2 id="summary">Summary</h2>

<p>In this post, we saw how we can make the use of Java in SQL Server somewhat less complex (permissions, code paths, etc.), by using external libraries.</p>

<p>To be able to use external libraries for your Java code, the code need be packaged either in a <code>.jar</code> file, or your class files need to be archived into a <code>.zip</code> file.</p>

<p>We create the external library using the DDL statement <code>CREATE EXTERNAL LIBRARY</code> where we:</p>

<ul>
<li>Define a name for the library.</li>
<li>Indicate where the <code>.jar</code> or <code>.zip</code> file is.</li>
<li>Set the language to Java.</li>
</ul>

<p>When we execute against the code we no longer need to have the code copied to the <code>CLASSPATH</code> or define a <code>@CLASSPATH</code> parameter, and no special permissions are required. Well, you need permissions to execute <code>sp_execute_external_script</code> but apart from that nothing else.</p>

<p>When we call <code>sp_execute_external_script</code> SQL Server loads the code from a system table, and we can view what external libraries exist in the database by using the <code>sys.external_libraries</code> and <code>sys.external_library_files</code> catalog views.</p>

<p>As good as all this sounds, there is one minor, (well perhaps not so minor), detail to be aware of: the way we create external libraries in this post - from a file path - requires SQL Server to be able to read from that path. In a production environment that may not be possible, so in a future post we look at how to overcome that.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 9, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/03/interesting-stuff---week-9-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-03T10:54:21+02:00</updated>
    <id>http://nielsberglund.com/2019/03/03/interesting-stuff---week-9-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/architecting-transactional-system">Achieving High Throughput with Reliability in Transactional Systems</a>. This presentation from <a href="https://www.infoq.com/">InfoQ</a> discusses architecting and designing a high performance, throughput &amp; data processing transactional system and real-time access to large datasets via APIs.</li>
<li><a href="https://www.infoq.com/presentations/monolith-microservices-refactoring-analysis-tools">Getting from Monolith to Microservices</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation looks at strategies to break a monolith, from the front-end to the back, including database refactoring and analysis tools to see dependencies in legacy code.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/training-your-first-classifier-with-spark-and-scala-893d7c6f7d88">Training Your First Classifier with Spark and Scala</a>. This post is an excellent introduction to machine learning with Spark and Scala.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.ververica.com/blog/monitoring-apache-flink-applications-101">Monitoring Apache Flink Applications 101</a>. This blog post provides an introduction to Apache Flink’s built-in monitoring and metrics system, that allows developers to monitor their Flink jobs effectively.</li>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-3-affinity-between-events-streams-serverless">Journey to Event Driven – Part 3: The Affinity Between Events, Streams and Serverless</a>. This post is the third part in the <a href="https://www.confluent.io/blog/journey-to-event-driven-part-1-why-event-first-thinking-changes-everything">Journey to Eventdriven</a> series, and it looks at how event-driven streaming architectures fit with serverless.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/01/sql-server-2019-community-technology-preview-2-3-is-now-available/">SQL Server 2019 community technology preview 2.3 is now available</a>. What the title of the post says: CTP2.3 of SQL Server 2019 is now available for download. I have already downloaded and installed the Windows version, and right now I am in the process of installing the SQL Server 2019 Big Data Cluster on Azure Kubernetes Service. Happy Days!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 8, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/24/interesting-stuff---week-8-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-24T10:08:50+02:00</updated>
    <id>http://nielsberglund.com/2019/02/24/interesting-stuff---week-8-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<p>For some reason I did not find that much interesting to me this week, but here is what caught my eye.</p>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.ververica.com/blog/batch-as-a-special-case-of-streaming-and-alibabas-contribution-of-blink">Batch as a Special Case of Streaming and Alibaba&rsquo;s contribution of Blink</a>. This post discusses the in-house improvements to Flink batch processing Alibaba has done and contributed to open source. Oh, when you read the post, and you wonder what Ververica is, read <a href="https://www.ververica.com/blog/introducing-our-new-name">this post</a>.</li>
<li><a href="https://www.infoq.com/presentations/apache-flink-streaming-app">Patterns of Streaming Applications</a>. This presentation from <a href="https://www.infoq.com/">InfoQ</a> talks about a blueprint for streaming data architectures and a review of desirable features of a streaming engine. The presentation also discusses streaming application patterns and anti-patterns, and use cases and concrete examples using Apache Flink.</li>
<li><a href="https://www.infoq.com/presentations/wepay-database-streaming">The Whys and Hows of Database Streaming</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses how database streaming is becoming more and more essential and the many functions that database streaming serves. The presentation also covers challenges faced with streaming peer-to-peer distributed databases.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 7, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/17/interesting-stuff---week-7-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-17T08:20:06+02:00</updated>
    <id>http://nielsberglund.com/2019/02/17/interesting-stuff---week-7-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/chaos-engineering-gamedays">Chaos Engineering with Containers</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses the benefits of using Chaos Engineering to inject failures to make container infrastructure more reliable.</li>
<li><a href="https://www.infoq.com/presentations/10-kubernetes">The 10 Kubernetes Commandments</a>. The presenters in this <a href="https://www.infoq.com/">InfoQ</a> presentation explore topics from booting Kubernetes clusters to running complex workloads as a list of 10 items. They share ideas that teams can employ to make working Kubernetes less of a chore and more of a way of life.</li>
<li><a href="https://www.infoq.com/presentations/kubernetes-stateful-containers">The Highs and Lows of Stateful Containers</a>. So far, it has been a lot of containers and <a href="https://www.infoq.com/">InfoQ</a> presentations, and the third item this week is more of the same. In this <a href="https://www.infoq.com/">InfoQ</a> presentation the presenter walks through his experiences of how to reliably run a distributed database on Kubernetes, and optimize its performance. He looks at what kinds of stateful applications can most easily be run in containers, and some pitfalls he encountered along the way.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/02/13/the-february-release-of-azure-data-studio-is-now-available/">The February release of Azure Data Studio is now available</a>. I must say that Azure Data Studio (ADS) has grown on me, and now I use it almost exclusively (instead of SQL Server Management Studio). The post I link to here announces the latest release of ADS with quite a few new features. Go and grab it, and see what you think.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-connect-jdbc-source-connector-deep-dive">Kafka Connect JDBC Source Connector – Deep Dive</a>. An excellent blog post by <a href="https://twitter.com/rmoff">Robin Moffat</a>, where he drills deep into the inner workings of the Kafka Connect JDBC connector.</li>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-2-programming-models-event-driven-architecture">Journey to Event Driven – Part 2: Programming Models for the Event-Driven Architecture</a>. In <a href="/2019/02/03/interesting-stuff---week-5-2019/">Interesting Stuff - Week 5, 2019</a> I linked to <a href="https://www.confluent.io/blog/journey-to-event-driven-part-1-why-event-first-thinking-changes-everything">Journey to Event Driven – Part 1: Why Event-First Thinking Changes Everything</a>. This weeks blog post is part 2 of the series, and it looks at different styles of event-driven architectures and compares and contrasts scaling, persistence and runtime models.</li>
</ul>

<h2 id="azure-force-recon">Azure Force Recon</h2>

<p>I just want to remind you of the <a href="https://www.meetup.com/Azure-Transformation-Labs/events/258705868/">Azure Force Recon</a> boot camp held here in Durban February 23. I have the privilege to do a presentation: <a href="https://www.linkedin.com/feed/update/activity:6500043306041384960/">Live and Die with your Data</a>, where I talk about SQL Server 2019 Big Data Clusters. So, if you do not have anything else to do, sign up and come and hear about Azure!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 6, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/10/interesting-stuff---week-6-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-10T08:37:39+02:00</updated>
    <id>http://nielsberglund.com/2019/02/10/interesting-stuff---week-6-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/02/Oreilly-microservices-maturity">O’Reilly Publishes “The State of Microservices Maturity” Report</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article discussing a report by O&rsquo;Reilly about microservices. In the report, O&rsquo;Reilly concludes that microservices are evolving into a trend and that DevOps and microservices feed off each other.</li>
<li><a href="https://www.infoq.com/presentations/messaging-architecture-future">Point-to-Point Messaging Architecture - The Reactive Endgame</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation where the presenters explore the current state of messaging architecture and provide an R&amp;D perspective on the future of distributed systems.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/02/CSharp-Lambda-Attributes">C# Futures: Lambda Attributes</a>. In this article <a href="https://www.infoq.com/">InfoQ</a> looks at a proposal for adding attributes to lambdas and anonymous functions.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="https://blogs.microsoft.com/ai/azure-data-explorer-lake-storage/">Solving a common corporate conundrum: Making sense of all that data</a>. This post discusses the newly announced Azure Data Explorer and its capabilities of analyzing 1 billion records of streaming data per second, as well as data stored in Azure Data Lake Storage.</li>
<li><a href="https://databricks.com/blog/2019/02/07/high-performance-modern-data-warehousing-with-azure-databricks-and-azure-sql-dw.html">High-Performance Modern Data Warehousing with Azure Databricks and Azure SQL Data Warehouse</a>. This blog post discusses how we can use Azure Data Factory, Azure Data Lake Storage together with Azure Databricks to load data into Azure SQL Data Warehouse for analysis, etc.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://blogs.msdn.microsoft.com/dotnet/2019/02/07/announcing-ml-net-0-10-machine-learning-for-net/">Announcing ML.NET 0.10 – Machine Learning for .NET</a>. This post does what the title says; it announces the release of ML.NET 0.10. Read the post to see what new features are part of this release.</li>
<li><a href="https://www.confluent.io/blog/machine-learning-with-python-jupyter-ksql-tensorflow">Machine Learning with Python, Jupyter, KSQL and TensorFlow</a>. As it says in this post: &ldquo;This blog post focuses on how the Kafka ecosystem can help solve the impedance mismatch between data scientists, data engineers and production engineers.&rdquo;.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/processing-trillions-of-events-per-day-with-apache-kafka-on-azure/">Processing trillions of events per day with Apache Kafka on Azure</a>. This is cool; the post talks about the optimal setup to run one of the largest Kafka deployments in the world, and achieve a throughput of trillion events per day.</li>
<li><a href="https://www.confluent.io/blog/beginners-perspective-kafka-streams-building-real-time-walkthrough-detection">A Beginner’s Perspective on Kafka Streams: Building Real-Time Walkthrough Detection</a>. In retail, it is essential to detect when a customer walks in or out of a store. This blog post discusses how a company used Kafka and KSQL to be able to react quicker and with more accuracy.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://buckwoody.wordpress.com/2019/02/02/sql-server-big-data-clusters-workshop-at-sql-bits/">SQL Server Big Data Clusters Workshop at SQL Bits</a>. UK&rsquo;s leading SQL Server conference <a href="https://sqlbits.com/">SQLBits</a> takes place in Manchester at the end of February. If you are attending, don&rsquo;t miss <a href="https://twitter.com/BuckWoodyMSFT">Buck Woody&rsquo;s</a> one day SQL Server 2019 Big Data Cluster workshop. Buck knows what he talks about and he also has members of the SQL Server 2019 Big Data Cluster team on-site. I wish I could be there!</li>
</ul>

<h2 id="azure-force-recon">Azure Force Recon</h2>

<p>Speaking about conferences and SQL Server Big Data Clusters; February 23 the first of many <a href="https://www.meetup.com/Azure-Transformation-Labs/events/258705868/">Azure tactical bootcamps</a> is being held here in Durban, and I have the privilege to do a presentation: <a href="https://www.linkedin.com/feed/update/activity:6500043306041384960/">Live and Die with your Data</a>, where I talk about SQL Server 2019 Big Data Clusters. So, if you do not have anything else to do, sign up and learn about Azure!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 5, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/03/interesting-stuff---week-5-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-03T09:15:51+02:00</updated>
    <id>http://nielsberglund.com/2019/02/03/interesting-stuff---week-5-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/containers-infrastructure-virtualization">P to V to C: The Value of Bringing “Everything” to Containers</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation examining the benefits of containerization, the role of infrastructure virtualization, discussing containers, pods, controllers, policies and more.</li>
<li><a href="https://www.infoq.com/presentations/kubernetes-yaml">Dissecting Kubernetes (K8s) - An Intro to Main Components</a>. Another <a href="https://www.infoq.com/">InfoQ</a> presentation, and in this presentation we see how to deploy containers, building up a mini cluster one Kubernetes component at a time, and it also explains what happens to the YAML files involved. The presentation is an excellent introduction to the inner workings of Kubernetes.</li>
<li><a href="https://srcco.de/posts/kubernetes-failure-stories.html">KUBERNETES FAILURE STORIES</a>. Kubernetes is not only roses and plain sailing. This blog post looks at what can go wrong with Kubernetes.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/01/IAsyncDisposable-IAsyncEnume">Update on IAsyncDisposable and IAsyncEnumerator</a>. This <a href="https://www.infoq.com/">InfoQ</a> blog post looks at changes made recently to the .NET Core async streams proposal.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-1-why-event-first-thinking-changes-everything">Journey to Event Driven – Part 1: Why Event-First Thinking Changes Everything</a>. This article is the first in a series about event architecture. Event-driven architecture is a topic that I am extremely interested in, so I am really looking forward to next &ldquo;episode&rdquo; in the series.</li>
</ul>

<h2 id="microsoft-ignite-the-tour">Microsoft Ignite The Tour</h2>

<p>So, Microsoft Ignite The Tour did a stop in Johannesburg February 28 &amp; 29, and I had the privilege to present at the conference. I did three sessions:</p>

<ul>
<li><a href="http://bit.ly/2S3xtg8">What is That Cup of Coffee Doing in my Database</a>: This 15-minute talk takes a look at the new Java integration in SQL Server 2019.</li>
<li><a href="http://bit.ly/2MvQySO">SQL Server Machine Learning Services: An E2E platform for machine learning</a>: We talk about how SQL Server Machine Learning Services can function as an end-to-end platform for AI and Machine Learning.</li>
<li><a href="http://bit.ly/2sPvA8E">Deep dive on SQL Server and big data</a>: We look at how SQL Server 2019 Big Data Clusters work.</li>
</ul>

<p>If you attended the conference and would like to get the slide decks, please <a href="mailto:niels.it.berglund@gmail.com">ping</a> me as I cannot find where to upload them to.</p>

<p>I had a great time at the conference, kudos to the organizers!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 4, 2019]]></title>
    <link href="http://nielsberglund.com/2019/01/27/interesting-stuff---week-4-2019/" rel="alternate" type="text/html"/>
    <updated>2019-01-27T06:36:21+02:00</updated>
    <id>http://nielsberglund.com/2019/01/27/interesting-stuff---week-4-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="cloud">Cloud</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/microsoft-tfs-azure-devops">Journey to Cloud Architecture</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation discussing the architectural challenges faced turning TFS into Azure DevOps, the evolution of the architecture, and lessons learned along the way.</li>
</ul>

<h2 id="misc">Misc.</h2>

<ul>
<li><a href="https://www.infoq.com/articles/why-architectural-diagrams">Why Do We Need Architectural Diagrams?</a>. An <a href="https://www.infoq.com/">InfoQ</a> article about software architecture diagrams. Software architecture diagrams, when created well, and sparingly, can greatly improve communication within the development team and with external stakeholders. They require an understanding of the intended audience and thoughtful restraint on what to include. Resist the temptation to think that diagrams are unnecessary or unhelpful, simply because there have been plenty of cases of bad diagrams.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/hdinsight-tools-for-visual-studio-code-now-generally-available/">HDInsight Tools for Visual Studio Code now generally available</a>. A post announcing GA (general availability) of HDInsight Tools for <strong>VS Code</strong>. Seeing that I have started using <strong>VS CODE</strong> more and more, this is something I need to check out.</li>
<li><a href="https://azure.microsoft.com/en-us/blog/analyze-data-in-azure-data-explorer-using-kql-magic-for-jupyter-notebook/">Analyze data in Azure Data Explorer using KQL magic for Jupyter Notebook</a>. In this post, Microsoft announces the ability to, from inside a Jupyter Notebook, use <em>Keyword Query Language</em> (KQL) to query and analyze data in Azure Data Explorer. Very cool!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/confluent-raises-a-125m-series-d-funding-round">Confluent Raises a $125M Series D Funding Round</a>. This blog post is about how Confluent has raised &ldquo;some&rdquo; money from investors, good for them. What is interesting in the post for me is this: <em>We think there is a really fundamental missing ingredient in the software architecture of a company, namely the idea of &ldquo;events&rdquo;. These events are the orders, sales, and customer experiences, that constitute the operation of the business. Databases have long helped to store the current state of the world, but we think this is only half of the story. What is missing is the continually flowing stream of events that represents everything happening in a company, and that can act as the lifeblood of its operation.</em>. This is music to my ears!</li>
<li><a href="https://www.datasciencecentral.com/profiles/blogs/apache-kafka-ksql-tensorflow-for-data-scientists-via-python">Apache Kafka + KSQL + TensorFlow for Data Scientists via Python + Jupyter Notebook</a>. A very, very interesting post, discussing how to use Kafka and KSQL together with machine learning tools such as Jupyter notebooks, Python, and deep learning frameworks.</li>
</ul>

<h2 id="msignite-the-tour">MSIgnite | The Tour</h2>

<p>Later today, (Sunday, Jan 27), I am off to Johannesburg and The <strong>MSIgnite | The Tour</strong> conference, where I give some presentations on Monday and Tuesday (Jan 28 and 29):</p>

<ul>
<li><a href="http://bit.ly/2S3xtg8">What is That Cup of Coffee Doing in my Database</a>: This 15-minute talk takes a look at the new Java integration in SQL Server 2019.</li>
<li><a href="http://bit.ly/2MvQySO">SQL Server Machine Learning Services: An E2E platform for machine learning</a>: We talk about how SQL Server Machine Learning Services can function as an end-to-end platform for AI and Machine Learning.</li>
<li><a href="http://bit.ly/2sPvA8E">Deep dive on SQL Server and big data</a>: We look at how SQL Server 2019 Big Data Clusters work.</li>
</ul>

<p>If you are attending the conference, please come by and say Hi!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
</feed>

