<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Niels Berglund</title>
  <link href="http://nielsberglund.com/atom.xml" rel="self"/>
  <link href="http://nielsberglund.com"/>
  <updated>2019-04-10T06:36:16+02:00</updated>
  <id>http://nielsberglund.com/</id>
  <generator uri="http://gohugo.io/">Hugo</generator>

  
  <entry>
    <title type="html"><![CDATA[Installing R Packages in SQL Server Machine Learning Services - III]]></title>
    <link href="http://nielsberglund.com/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/" rel="alternate" type="text/html"/>
    <updated>2019-04-10T06:36:16+02:00</updated>
    <id>http://nielsberglund.com/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/</id>
    <content type="html"><![CDATA[<p>This post is the third in a series about installing R packages in <strong>SQL Server Machine Learning Services</strong> (SQL Server ML Services). To see all posts in the series go to <a href="/sql_server_ml_services_install_packages"><strong>Install R Packages in SQL Server ML Services Series</strong></a>.</p>

<p>Why this series came about is a colleague of mine <a href="https://www.linkedin.com/in/dane-bax/">Dane</a> pinged me and asked if I had any advice as he had issues installing an R package into one of their SQL Server instances. I tried to help him and then thought it would make a good topic for a blog post. Of course, at that time I didn&rsquo;t think it would be more posts than one, but here we are.</p>

<p>In this post, we look at how we can use T-SQL and DDL commands to install packages in a remote SQL Server.</p>

<p></p>

<p>Let us do a recap to see where we are.</p>

<h2 id="recap">Recap</h2>

<p>The first <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">post</a> in the series gave an overview of what ways we can install packages in the external R engine in SQL Server ML Services:</p>

<ul>
<li>R packet managers</li>
<li>T-SQL</li>
<li>RevoScaleR</li>
</ul>

<p>The <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">post</a> then went into details about using R packet managers, where an R packet manager is an R command line tool or GUI installed on the SQL Server Machine Learning Services machine. The packet manager should be run with elevated permissions and target the R engine for the instance on which you want to install the package. The easiest is to use either of the R tools that come as part of SQL Server&rsquo;s R service:</p>

<ul>
<li>The command line tool: <code>Rterm.exe</code>.</li>
<li>The GUI: <code>Rgui.exe</code>.</li>
</ul>

<p>These two packet managers live in the <code>\\&lt;path_to_SQL_Server_instance&gt;\R_SERVICES\bin\x64</code> directory. When you install packages via an R packet manager, they can only be installed to the default packet library for that instance. You find the library at: <code>\\&lt;path_to_SQL_Server_instance&gt;\R_SERVICES\library</code>.  The file system folder for this library has restricted access and you need elevated permissions to write to this folder. Typical code for installing packages from a packet manager can look like so:</p>

<pre><code class="language-r"># set the library path
libPath &lt;- C:\\path_to_SQL_Server_instance&gt;\\R_SERVICES\\library
install.packages(&quot;pkg_name&quot;, lib = libPath, 
                  repos = &quot;url_for_the_repo&quot;, 
                  dependencies = TRUE)
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Install Packages Command</em></p>

<p>In <em>Code Snippet 1</em> we use <code>install.packages</code> to install &ldquo;pkg_name&rdquo; to a hardcoded library path.</p>

<p>Using an R Package manager is the most straight forward way to install R packages, but the downside with it is that you need admin rights on the SQL Server box. Having admin rights on a SQL Server box in production can be an issue, and in <a href="/2018/06/30/installing-r-packages-in-sql-server-machine-learning-services---ii/">Installing R Packages in SQL Server Machine Learning Services - II</a> we looked at how we can install packages without having admin rights, by using RevoScaleR:</p>

<ul>
<li>To use RevoScaleR for package installation both the SQL Server instance as well as the database need to be enabled for package management. You enable package management via <code>RegisterRExt.exe</code> tool and the <code>/installpkgmgmt</code> option. There are additional flags for database enabling, authentication and so forth.</li>
<li>When enabling the database the process creates a table, stored procedures and roles.</li>
<li>For a user to be able to install packages he needs to have necessary permissions on <code>sp_execute_external_script</code> as well as the <code>EXECUTE ANY EXTERNAL SCRIPT</code> permission. He also needs to be in a role which allows him to install packages.</li>
<li>The roles that the enabling process creates are: <code>rpkgs-users</code>, <code>rpkgs-private</code> and <code>rpkgs-shared</code>.</li>
<li>The roles which allow the user to install packages are <code>rpkgs-private</code> and <code>rpkgs-shared</code> (and <code>db_owner</code>).</li>
<li>The roles define the scope of the installed packages: <code>private</code> and <code>shared</code>.</li>
<li>When a user installs a package with <code>private</code> scope, only he can see and use the package.</li>
<li>If the user installs a package with <code>shared</code> scope, all users in any of the roles, including <code>rpkgs-users</code> can use that package. The user needs to be in the <code>rpkgs-shared</code> (or <code>db_owner</code>) to install a <code>shared</code> package.</li>
<li>You use the function <code>rxInstallPackages</code> to install a package, and the function needs to run in an <em>SQLCC</em>.</li>
<li>When the user calls <code>rxInstallPackages</code> he needs to define which scope the package has through the <code>scope</code> argument. If the <code>scope</code> is not defined, it defaults to <code>private</code>.</li>
<li>To use a package, either in <code>private</code> or <code>shared</code> scope, the code needs to run in <em>SQLCC</em>.</li>
<li>For a package that does not know <em>SQLCC</em>, the functions in the package can be run via <code>rxExec</code>.</li>
</ul>

<h2 id="housekeeping">Housekeeping</h2>

<p>Before we &ldquo;dive&rdquo; into today&rsquo;s topics let us look at the code we use today. This section is here for those of you who want to follow along in what we are doing in the post.</p>

<pre><code class="language-sql">USE master;
GO

DROP DATABASE IF EXISTS DataScienceDB;
GO

DROP DATABASE IF EXISTS DataScienceDBRemote;
GO

CREATE DATABASE DataScienceDB;
GO

CREATE DATABASE DataScienceDBRemote;
GO
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create Databases</em></p>

<p>In <em>Code Snippet 2</em> we create two databases; <code>DataScienceDB</code> and <code>DataScienceDBRemote</code> where the latter is to emulate a database on a remote SQL Server instance. In previous posts, we have created logins and users, but in this post, we only log in as <code>sa</code>.</p>

<h2 id="installing-r-packages-using-t-sql">Installing R Packages Using T-SQL</h2>

<p>In the <em>Recap</em> above we said that in previous posts we have looked at installing R packages either by using R package managers on the SQL Server box, or doing it remotely via script using RevoScaleR. The third option we have is to do it via a T-SQL statement. More specifically through a statement introduced in SQL Server 2017: <code>CREATE EXTERNAL LIBRARY</code>.</p>

<blockquote>
<p><strong>NOTE:</strong> In SQL Server 2017 only R packages are supported whereas, in SQL Server 2019 R, Python and Java are supported. For both SQL Server 2017 and 2019 (up to and including CTP 2.3) only the Windows platform is supported. For SQL Server 2019, Linux may be added as a supported platform in later CTP releases.</p>
</blockquote>

<p>What <code>CREATE EXTERNAL LIBRARY</code> does is it uploads package files to a database from a file path or byte stream. The signature looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM (CONTENT = { &lt;file_spec&gt; }  
    [, PLATFORM = &lt;platform&gt; ]) 
WITH ( LANGUAGE = '&lt;language&gt;' )  
[ ; ] 
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Signature CREATE EXTERNAL LIBARY</em></p>

<p>The arguments we see in <em>Code Snippet 3</em> are:</p>

<ul>
<li><code>library_name</code>: A unique name for the package. When we create an external library for an R package, the name has to be the actual package name. While this may seem obvious, I mention it as when you create external libraries for Java code the name does not matter. We discussed this in the <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a> post. When I say the package name has to be unique, the unique:ness is based on the name and the principal id under which it is created. We talk more about that in a future post.</li>
<li><code>owner_name</code>: This optional parameter specifies the name of the user or role that owns the external library. More about this in a future post as well.</li>
<li><code>file_spec</code>: The <code>file_spec</code> specifies the content of the package for a specific platform, and it can either be in the form of a file location (local path/network path) or a hex literal. If we want to install an R package from a file location, the package needs to be in the form of a zipped archive file. If we install based on a hex-literal, the hex-literal need to derive from the package zip file.</li>
<li><code>platform</code>: The <code>PLATFORM</code> parameter, which defines the platform for the content of the library. The <code>PLATFORM</code> parameter defaults to the platform on which SQL Server runs on, and since <code>CREATE EXTERNAL LIBRARY</code> is only supported on Windows, for now, we do not set it.</li>
<li><code>language</code>: Specifies the language of the package. For this post we only deal with <code>R</code>, and - as I mentioned above - in SQL Server 2017, R is the only language supported.</li>
</ul>

<h2 id="using-create-external-library">Using CREATE EXTERNAL LIBRARY</h2>

<p>To see how to use <code>CREATE EXTERNAL LIBRARY</code> we want to install the <code>randomForest</code> package into our <code>DataScienceDB</code> database. We start with downloading the <code>randomForest</code> zip archive to a directory which is readable by SQL Server. I have it at <code>W:\randomForest_4.6-14.zip</code>. We log in to the server and database as <code>dbo</code> (<code>sa</code> login), and we are ready to execute the <code>CREATE EXTERNAL LIBRARY</code> DDL:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = 'W:\randomForest_4.6-14.zip') 
WITH (LANGUAGE = 'R'); 
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create External Library</em></p>

<p>As we see in <em>Code Snippet 4</em> I name the external library <code>randomForest</code>, as that is the name of the R package, and I set the location of where the package <code>zip</code> file is. Before we execute the code in <em>Code Snippet 4</em>, let us look at what R packages we have installed already:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'
                    OutputDataSet &lt;- data.frame(
                    installed.packages()[,c(&quot;Package&quot;, &quot;LibPath&quot;)]);'
WITH RESULT SETS ((Package nvarchar(255), LibPath nvarchar(2000)));
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>View R Packages</em></p>

<p>When we execute the code in <em>Code Snippet 5</em> we see something like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_inst_pkgs.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>View Installed R Packages - I</em></p>

<p>In <em>Figure 1</em> we see some of the installed R packages and notice that we do not see randomForest. Also, notice the <code>LibPath</code> column outlined in red. Remember how I mentioned in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a> how, when using SQL Server ML Services, we install packages to a specific library which SQL Server then loads the packages from. That location is the <code>LibPath</code> in <em>Figure 1</em>.</p>

<blockquote>
<p><strong>NOTE:</strong> As we see later in this post, what I said above about only one location is not entirely true.</p>
</blockquote>

<p>The last thing to do before we execute the code in <em>Code Snippet 4</em> is to browse around in <em>File Explorer</em> and look at a directory under <code>C:\&lt;path_to_SQL_instance&gt;\MSSQL</code>. When we look around we see a directory named <code>ExternalLibraries</code>, and when we &ldquo;drill&rdquo; into it we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib1.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>ExternalLibraries Directory</em></p>

<p>Hmm, what is so interesting with this directory we see in <em>Figure 2</em>, it has a subdirectory named <code>R</code>, but otherwise, it is empty? Well, the name is interesting: <code>ExternalLibraries</code>. I wonder if it has anything to do with creating external libraries? So to find out we execute the code in <em>Code Snippet 4</em>.</p>

<p>Strange, after we execute the code in <em>Code Snippet 4</em> nothing changes in the directories we look at. Are we wrong in our assumptions about the directories, or did the code fail? In either case, how can we find out?</p>

<p>Creating an external library is very similar to creating an SQLCLR assembly, and if you have ever created an SQLCLR assembly you are probably aware of a couple of catalog views that gives us information about the assemblies:</p>

<ul>
<li><code>sys.assemblies</code>: base catalog view for assemblies with one row per assembly created in the database.</li>
<li><code>sys.assembly_files</code>: contains the binary representation of the assembly files.</li>
</ul>

<p>For external libraries we have similar catalog views:</p>

<ul>
<li><code>sys.external_libraries</code>: base catalog view for external libraries with one row per external library created in the database.</li>
<li><code>sys.external_library_files</code>: contains the binary representation of the external library files.</li>
</ul>

<p>So, if we successfully created the external library we <em>should</em> see something in <code>sys.external_libraries</code>:</p>

<pre><code class="language-sql">SELECT * 
FROM sys.external_libraries;
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>View External Libraries</em></p>

<p>When we execute the code in <em>Code Snippet 6</em> we see:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Installed External Library</em></p>

<p>Yes, when we look at <em>Figure 3</em> we see that we have created an external library. The columns we see represents:</p>

<ul>
<li><code>external_library_id</code>: the id of the external library as assigned by the database.</li>
<li><code>name</code>: name given to it during creation.</li>
<li><code>principal_id</code>: id of the owner, (principal), of the library.</li>
<li><code>language</code>: name of the language of the library. As mentioned before; in SQL Server 2017, only R, in SQL Server 2019; R, Python, and/or Java.</li>
<li><code>scope</code>: defines who can access the library, 0 for <code>PUBLIC</code>, 1 for <code>PRIVATE</code>. More about that in a.</li>
<li><code>scope_desc</code>: literal description of the scope.</li>
</ul>

<p>Let us see if we can use it the external library:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script 
                    @language = N'R', 
                    @script = N'library(&quot;randomForest&quot;)'
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Load R Package</em></p>

<p>Admittedly the code in <em>Code Snippet 6</em> does not accomplish much, but when we execute it we can tell whether we have succeeded in creating the external library:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib2.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Execute randomForest</em></p>

<p>From what is outlined in red in <em>Figure 4</em> we see that we have successfully executed against the <code>randomForest</code> package. We also see how external libraries only get loaded and &ldquo;properly&rdquo; installed at first use (blue outline). Cool, so that worked. What about the <code>ExternalLibraries</code> directory:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib3.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>ExternalLibraries after First Execution</em></p>

<p>So, our assumption above regarding <code>ExternalLibraries</code> were correct; the directory contains the actual packages for the external libraries we create. We see in <em>Figure 5</em> how there are new directories, and how we have a <code>randomForest</code> directory which contains the <code>randomForest</code> package.</p>

<blockquote>
<p><strong>NOTE:</strong> The number 5 in <em>Figure 5</em> refers to the database id, and the number 1 beneath the 5 is the id of the external library (<code>external_library_id</code>). So the databases have their own top-level directory, named after the database id. Underneath the database id directory is the individual external library directories identified by the external library id.</p>
</blockquote>

<p>When we execute the code in <em>Code Snippet 5</em> we get:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib4.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>View Installed R Packages - II</em></p>

<p>We now see in <em>Figure 6</em> how the <code>randomForest</code> package comes up as an installed packet (outlined in red), and we see the installation path (highlighted in yellow), and this is where it loads from. So what I said in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a> about SQL only loads packages from one directory is not entirely true, SQL Server can load packages from different locations.</p>

<p>What we have seen so far looks quite good, but the problem is similar to what we discussed in <a href="/2018/06/23/installing-r-packages-in-sql-server-machine-learning-services---i/">Installing R Packages in SQL Server Machine Learning Services - I</a>:</p>

<ul>
<li>In the post we said we needed elevated access to the box where the SQL Server instance is.</li>
<li>Here we need access to a directory to which we can copy the package(s) we want to create the external library(s) from, and SQL Server needs read access to that directory. This directory is most likely on the SQL Server server, so we still have the same problem as before.</li>
</ul>

<p>Fortunately, there is a way to solve this. Remember how we said above that the <code>file_spec</code> parameter which, up until now, has been a file path, also can be a hex-literal.</p>

<h2 id="hex-literal-create-external-library">Hex Literal &amp; CREATE EXTERNAL LIBRARY</h2>

<p>The question is then how do I get the hex-literal for a package?</p>

<blockquote>
<p><strong>NOTE:</strong> What follows related to hex literal is more or less a copy from my post <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a>.</p>
</blockquote>

<p>The hex-literal is the actual binary representation of the package, so let us look at a couple of ways we can get hold of the binary package representation:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-database">Local Database</h4>

<p>We know (from above) that the catalog view <code>sys.external_library_files</code> contains the binary representation of the package, and we see that using a query like so:</p>

<pre><code class="language-sql">SELECT l.external_library_id, l.name, lf.content
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest'
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>View External Library</em></p>

<p>In <em>Code Snippet 7</em> we <code>SELECT</code> out the library id, name from the <code>sys.external_libraries</code> view, and <code>content</code> from <code>sys.external_library_files</code>. When we run the code the result looks like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib_content1.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>Binary Representation</em></p>

<p>What we see highlighted in <em>Figure 7</em> is the <code>content</code> column, and we see it contains the hex-literal for the <code>randomForest</code> package.</p>

<p>So if we want to create an external library on a remote SQL Server on which we do not have access to the file system, but we have access to a local SQL Server, we can do this:</p>

<ul>
<li>Create an external library in a database on the local machine, like in <em>Code Snippet 4</em>.</li>
<li>Get the hex-literal from the <code>content</code> column and save it.</li>
</ul>

<p>The naive way, (what I did initially), to get the hex-literal is to use code like this:</p>

<pre><code class="language-sql">DECLARE @hexLit varbinary(max);

SELECT @hexLit = lf.content
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest' 

PRINT @hexLit;
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Get the Hex Literal</em></p>

<p>To get the hex-literal, we see in <em>Code Snippet 8</em> how we:</p>

<ul>
<li>Declare a <code>varbinary(max)</code> variable into which we <code>SELECT</code> the <code>content</code> column.</li>
<li>Print that variable so we can use it.</li>
</ul>

<p>When we execute the code, it looks like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_ext_lib_hexlit.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Selecting out Hex Literal</em></p>

<p>In <em>Figure 8</em> we see part of the hex literal. However, I mentioned above that what we see in <em>Code Snippet 8</em> is a naive way to do it, and - in most cases - it does not work. Sure you get something that looks like your hex-literal, but if you compare the size of the printed output of the variable, with the size of the value in the column, you see how the size in the column is much bigger. This is because when you do a <code>PRINT</code> either in SSMS or Azure Data Studio the output is limited to a max size of 8000.</p>

<blockquote>
<p><strong>NOTE:</strong> In the <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a> post I used the method above, and it worked. The reason was that the <code>.jar</code> file I wanted to create an external library from, had a size of ~1.5k.</p>
</blockquote>

<p>So what do we do if we want to capture the value of the variable? Well, by using some xml &ldquo;magic&rdquo; we can achieve what we want:</p>

<pre><code class="language-sql">SELECT CONVERT(varchar(max), lf.content, 1)
FROM sys.external_libraries l
JOIN sys.external_library_files lf
  ON l.external_library_id = lf.external_library_id
WHERE l.name = 'randomForest'
FOR XML PATH('');
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Output as XML</em></p>

<p>We see that the code in <em>Code Snippet 9</em> is not that much different from <em>Code Snippet 8</em>. Instead of selecting the <code>content</code> column value into a variable which we <code>PRINT</code>, we <code>CONVERT</code> the binary value to <code>varchar(max)</code> and then indicate we want it exposed as xml (<code>FOR XML PATH('')</code>). When we execute the result is like so:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_hexlit_xml.png" alt="" /></p>

<p><strong>Figure 9:</strong> <em>Hex Literal XML</em></p>

<p>When you see <em>Figure 9</em> you may ask what the difference is from what we have seen before? When we copy out the content of the column, will we not get just a part of the full value? The answer to that is yes, however, as the column data type is xml, and if we click on it we see something different:</p>

<p><img src="/images/posts/sql_ml_install_r_pckgs3_hexlit_aml_output.png" alt="" /></p>

<p><strong>Figure 10:</strong> <em>XML Output</em></p>

<p>When we clicked on the column a new file opens, and in that file, we get the full hex-literal value, as we see in <em>Figure 10</em>. We can now use the full hex literal to create the <code>randomForest</code> external library on another SQL Server instance.</p>

<p>In this post I do not have access to a remote SQL Server, so what we do instead is that we emulate doing it; we do it against the second database we created in <em>Code Snippet 2</em>; <code>DataScienceDBRemote</code>. After we ensure we have the full hex literal saved off somewhere we:</p>

<ul>
<li>Switch over to <code>DataScienceDBRemote</code> (as <code>sa</code>).</li>
<li>Open a new query window.</li>
</ul>

<p>In the new query window we declare a new variable, let us call it <code>@hexLit</code>, as a <code>varbinary(max)</code>, and we assign the hex literal from <code>DataScienceDB</code> to the variable:</p>

<pre><code class="language-sql">USE DataScienceDBRemote;
GO

DECLARE @hexLit varbinary(max) = 0x504B03040A00000000009982964...
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Assign Hex Literal Value to Variable</em></p>

<p>When we have declared the variable and assigned the hex-literal value to it, we can use it in <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-sql">USE DataScienceDBRemote;
GO

DECLARE @hexLit varbinary(max) = 
0x504B03040A00000000009982964C0000000000000000000000000D00000072...
...

CREATE EXTERNAL LIBRARY randomForest
FROM (CONTENT = @hexLit)
WITH (LANGUAGE = 'R');
GO

SELECT * FROM sys.external_libraries;
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Create External Library from Hex Literal Variable</em></p>

<p>Finally, we execute the code in <em>Code Snippet 11</em> and the <code>SELECT</code> shows us that we now have an external library named <code>randomForest</code> in the &ldquo;remote&rdquo; database.</p>

<p>So this is one way we can get a binary for a package. It may, however, be somewhat convoluted, so let us look at the second way.</p>

<h4 id="generate-binary-from-code">Generate Binary from Code</h4>

<p>Compared to the above, to get the binary representation based on code is probably somewhat easier, and I decided to use Python to create a script which writes the package binary to a file:</p>

<pre><code class="language-python">import binascii

packageFile = input(&quot;Provide full path to the R package \ 
                    file you want to use - \
                    Example: 'W:\\randomForest_4.6-14.zip': &quot;)
fileName = input(&quot;Provide name of the file \
                  you want to create to write the binary to: &quot;)

with open(packageFile, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

f = open(fileName, &quot;w+&quot;)
f.write(hex_bytes)
f.close()
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Python Script to Generate File with Hex Literal</em></p>

<p>We see in <em>Code Snippet 12</em> how the script:</p>

<ul>
<li>Asks for what package zip file to use.</li>
<li>What name to give the output file.</li>
<li>Generates the binary.</li>
<li>Saves it into a file.</li>
</ul>

<p>We now take the code in <em>Code Snippet 12</em> and copy it into a Python script file, for example <code>createBinary.py</code>. When we have the Python file we execute from the command prompt like so:</p>

<pre><code class="language-bash">$ python .\createBinary.py
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Run Python Script</em></p>

<p>After we run the script as per <em>Code Snippet 13</em> we open the created file and grab the hex-literal. We now follow the same procedure as we did in <em>Code Snippet 10</em> and <em>Code Snippet 11</em>, without having the package installed as an external library on the local machine.</p>

<p>However, why do copy and paste when we can connect directly from Python to the remote database and execute <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-python">import pyodbc
import binascii

extLibName = input(&quot;Provide a unique name for \
                   the external library you want to create: &quot;)
packageFile = input(&quot;Provide full path to the zip \
                  file you want to use - \
                  Example: 'W:\\randomForest_4.6-14.zip': &quot;)
dbServer = input(&quot;Provide name/ip address of your \
                  database server. If instance also instance name \ 
                  - Example: 'mydbServer\myInstance: &quot;)
dataBase = input(&quot;Provide name of the database where you \
                  want to create the external library: &quot;)
userName = input(&quot;Provide the user name with which you \
                   want to connect to the server: &quot;)
password = input(&quot;Provide password with which to \
                  connect to the database: &quot;)

with open(packageFile, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

drvr = '{ODBC Driver 17 for SQL Server}'
connStr = f'DRIVER={drvr};SERVER={dbServer};DATABASE={dataBase};UID={userName};PWD={password}'
conn = pyodbc.connect(connStr)
cursor = conn.cursor()

execStmt = f'CREATE EXTERNAL LIBRARY {extLibName}\n'
execStmt = execStmt + f'FROM (CONTENT = {hex_bytes})\n'
execStmt = execStmt + f&quot;WITH (LANGUAGE = 'R');\n&quot;

cursor.execute(execStmt)
conn.commit()    
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>Execute Directly Against the Remote Database</em></p>

<p>So, what do we do in <em>Code Snippet 14</em>? Well, we use the same code as in <em>Code Snippet 12</em> to generate the binary representation. However, instead of writing it to a file we connect to the database using the <code>pyodbc</code> module, and the latest SQL Server ODBC driver. The <code>hex_bytes</code> variable is now a parameter in the <code>CREATE EXTERNAL LIBRARY</code> statement. The name of the external library is passed in as a parameter together with database connection details. It is worth noting that the way the script captures the password variable is not particularly secure. Instead of <code>input</code>, we should use <code>getpass</code> or something similar.</p>

<blockquote>
<p><strong>NOTE:</strong> Unless the user with which you connect is part of the <code>db_owner</code> role, the user needs explicit permissions to execute <code>CREATE EXTERNAL LIBRARY</code>. A future post covers permissions for <code>CREATE EXTERNAL LIBRARY</code>.</p>
</blockquote>

<p>To run this, we do as we did in <em>Code Snippet 12</em>; we copy the code into a Python file and run it from the command line. The code should run OK, and we have created an external library in a database in a remote SQL Server (well, in my case an emulated remote SQL Server).</p>

<h2 id="summary">Summary</h2>

<p>In this post, we set out to solve the issue of how to deploy an R package without having access to the filesystem of the SQL Server where we want to deploy the package to.</p>

<p>We have seen two ways of doing it:</p>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create an external library from the R package based on the file path in a local SQL Server where we have access to the filesystem (like <code>localhost</code>).</li>
<li>Get the binary representation from the <code>content</code> column in <code>sys.external_library_files</code> via some XML &ldquo;magic&rdquo;.</li>
<li>Assign the retrieved value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 3 above (local database).</li>
</ol>

<p>Alternatively, you can connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 14, 2019]]></title>
    <link href="http://nielsberglund.com/2019/04/07/interesting-stuff---week-14-2019/" rel="alternate" type="text/html"/>
    <updated>2019-04-07T19:33:23+02:00</updated>
    <id>http://nielsberglund.com/2019/04/07/interesting-stuff---week-14-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/starling-bank">Building a Reliable Cloud-Based Bank in Java</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation discussing the experience of Starling Bank, a mobile-only, cloud-based bank that launched in the UK in 2017. The presenter looks at the system architecture of the bank, the design principles that give them the ability to release quickly and reliably, and why they decided to build the back end using Java.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><p><a href="https://www.confluent.io/blog/introducing-confluent-platform-5-2">Introducing Confluent Platform 5.2</a>. During the week Confluent announced the release of Confluent Platform 5., and with it some exciting new features:</p>

<ul>
<li>Confluent Platform is free for single node clusters, it is like a developer edition!</li>
<li>The <code>librdkafka</code> library is now in version 1.0. That is interesting as it brings this library closer to parity with the Java client for Kafka.</li>
<li>New and enhanced query expressions in KSQL.</li>
</ul></li>

<li><p><a href="https://www.confluent.io/blog/putting-events-in-their-place-with-dynamic-routing">Putting Events in Their Place with Dynamic Routing</a>. This is a blog post about how Kafka Streams are a powerful way to enrich data streaming through event-driven architectures. We can dynamically route events to topics, even pulling in the output topic information from another end data system.</p></li>

<li><p><a href="https://www.infoq.com/presentations/starling-bank">KSQL: What’s New in 5.2</a>. As I mentioned above, there are new features in KSQL 5.2, and in this blog post <a href="https://twitter.com/rmoff">Robin</a> discusses some of them!</p></li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 13, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/31/interesting-stuff---week-13-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-31T08:43:04+02:00</updated>
    <id>http://nielsberglund.com/2019/03/31/interesting-stuff---week-13-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://blog.acolyer.org/2019/03/29/calvin-fast-distributed-transactions-for-partitioned-database-systems/">Calvin: fast distributed transactions for partitioned database systems</a>. In this white-paper dissection by <a href="https://twitter.com/adriancolyer">Adrian</a>, he looks at <a href="https://github.com/yaledb/calvin">Calvin</a> which is a transaction scheduling and data replication layer that uses a deterministic ordering guarantee to reduce the high contention costs associated with distributed transactions significantly.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/27/sql-server-2019-community-technology-preview-2-4-is-now-available/">SQL Server 2019 community technology preview 2.4 is now available</a>. What the title says. I downloaded the CTP a couple of days ago, and when I am done with this post, I will install it. Oh, word of warning - if you want to install the <strong>SQL Server 2019 Big Data Cluster</strong>, please remember to uninstall and reinstall <code>mssqlctl</code>, so you get the latest version.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/importance-of-distributed-tracing-for-apache-kafka-based-applications">The Importance of Distributed Tracing for Apache-Kafka-Based Applications</a>. This blog post looks at how to instrument Kafka-based applications with distributed tracing capabilities to make dataflows between event-based components more visible. Very interesting!</li>
<li><a href="https://www.confluent.io/blog/consuming-messages-out-of-apache-kafka-in-a-browser/2">Consuming Messages Out of Apache Kafka in a Browser</a>. The post covers what the title says; how to consume Kafka messages in a browser.</li>
<li><a href="https://rmoff.net/2019/03/28/exploring-ksql-stream-stream-joins/">Exploring KSQL Stream-Stream Joins</a>. This is an excellent post by <a href="https://twitter.com/rmoff">Robin</a> where he covers KSQL and stream to stream joins! I need to go off and <del>play with</del> research this now!</li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (<em>What Is Niels Doing</em>)</h2>

<p>I am still working on the post about <code>CREATE EXTERNAL LIBRARY</code> in the <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series. Expect it towards the end of this coming week.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 12, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/24/interesting-stuff---week-12-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-24T08:37:01+02:00</updated>
    <id>http://nielsberglund.com/2019/03/24/interesting-stuff---week-12-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/csharp-testing-strategy-tools">Unit Testing Strategies &amp; Patterns in C#</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses design principles and ways to make C# code testable, as well as using testing tools such as Moq, Autofixture, &amp; MsTest.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://medium.com/google-cloud/istio-routing-basics-14feab3c040e">Istio Routing Basics</a>. So, <a href="https://cloud.google.com/istio/">Istio</a> is an open source service mesh, and this blog post covers the basics of Istio and shows what it takes to build an Istio enabled &ldquo;Hello World&rdquo; application.</li>
<li><a href="https://medium.com/@masroor.hasan/tracing-infrastructure-with-jaeger-on-kubernetes-6800132a677">Distributed Tracing Infrastructure with Jaeger on Kubernetes</a>. The blog post I link to here looks at distributed tracing on Kubernetes using Jaeger.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/18/the-march-release-of-azure-data-studio-is-now-available/">The March release of Azure Data Studio is now available</a>. What the title says! There are quite a few new features in the March release of Azure Data Studio, among them: support for SQL Notebooks, PowerShell extension, and PostgresSQL support. Go and get it!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-streams-take-on-watermarks-and-triggers">Kafka Streams’ Take on Watermarks and Triggers</a>. This blog post discusses a new Kafka Streams operator: <code>Suppress</code>. It gives you the ability to control when to forward KTable updates. The <code>Suppress</code> operator comes in very handy in various CEP scenarios: &ldquo;tell me when someone has done &ldquo;a&rdquo; more than &ldquo;x&rdquo; times within &ldquo;y&rdquo; time period&rdquo;. What normally happens is that if someone achieves the &ldquo;a&rdquo;, &ldquo;x&rdquo; times within the &ldquo;y&rdquo; time period every following &ldquo;a&rdquo; would trigger as well. With <code>Suppress</code> you - wait for it - suppress the extra &ldquo;a&rdquo;, until the end of the time period.<br /></li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (<em>What Is Niels Doing</em>)</h2>

<p>Since I did the two posts about <code>CREATE EXTERNAL LIBRARY</code> for Java code (<a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">here</a> and <a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">here</a>), I thought it would be a good idea to finish off my <a href="/sql_server_ml_services_install_packages">Install R Packages in SQL Server ML Services</a> series. So, I am at the moment working on a post discussing <code>CREATE EXTERNAL LIBRARY</code> in the R world. The post is somewhat like the ones covering Java, but it also covers permissions etc.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 11, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/17/interesting-stuff---week-11-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-17T21:16:22+02:00</updated>
    <id>http://nielsberglund.com/2019/03/17/interesting-stuff---week-11-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/net-core-container-images-now-published-to-microsoft-container-registry/">.NET Core Container Images now Published to Microsoft Container Registry</a>. A post discussing how Microsoft are now publishing .NET Core container images to Microsoft Container Registry (MCR).</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/istio-microservices">Reducing Microservices Architecture Complexity with Istio and Kubernetes</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation which introduces Istio, and explains how the service mesh works, the technology behind it, and how to use it with microservices.</li>
<li><a href="https://www.infoq.com/news/2019/03/microservices-recommendations">Recommendations When Starting with Microservices: Ben Sigelman at QCon London</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article about the mistakes Google made in he beginning when adopting a microservices architecture, and recommendations to avoid making these mistakes when starting with microservices.</li>
</ul>

<h2 id="data-science-machine-learning">Data Science / Machine Learning</h2>

<ul>
<li><a href="https://towardsdatascience.com/machine-learning-with-big-data-86bcb39f2f0b">Machine Learning with Big Data</a>. Data is on overdrive. It’s being generated at break-neck pace. How do we analyze all this data? This article discusses how to easily create a scalable and parallelized machine learning platform on the cloud to process large-scale data.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://eng.uber.com/dbevents-ingestion-framework/">DBEvents: A Standardized Framework for Efficiently Ingesting Data into Uber’s Apache Hadoop Data Lake</a>. This blog post looks at Uber&rsquo;s  DBEvents, a change data capture system designed for high data quality and freshness. It facilitates bootstrapping, ingesting a snapshot of an existing table, and incremental, streaming updates.</li>
<li><a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues">Kafka Connect Deep Dive – Error Handling and Dead Letter Queues</a>. In this blog post <a href="https://twitter.com/rmoff">Robin Moffat</a> looks at several common patterns for handling Kafka Connect problems and examines how the patterns can be implemented.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="/2019/03/17/sql-server-2019-java--external-libraries---ii/">SQL Server 2019, Java &amp; External Libraries - II</a>. This post by yours truly looks at how to use <code>CREATE EXTERNAL LIBRARY</code> to deploy Java code without having access to SQL Server&rsquo;s filesystem.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019, Java &amp; External Libraries - II]]></title>
    <link href="http://nielsberglund.com/2019/03/17/sql-server-2019-java--external-libraries---ii/" rel="alternate" type="text/html"/>
    <updated>2019-03-17T17:13:45+02:00</updated>
    <id>http://nielsberglund.com/2019/03/17/sql-server-2019-java--external-libraries---ii/</id>
    <content type="html"><![CDATA[<p>This post is part of the <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a> series of posts, and it is the second post discussing SQL Server 2019, Java and the creation and use of external libraries.</p>

<p>In the previous post about external libraries, we said that they were beneficial as they reduced complexities when deploying code, but there were still some caveats. So, in this post, we look at how to overcome those caveats</p>

<p></p>

<h2 id="recap">Recap</h2>

<p>Let us start with a recap of what we covered in the previous post.</p>

<p>In the last post we saw how we can make the use of Java in SQL Server somewhat less complex (permissions, code paths, etc.), by using external libraries.</p>

<p>We create the external library using the DDL statement <code>CREATE EXTERNAL LIBRARY</code>, and we saw in the post that the signature, somewhat simplified, looks like so:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>To be able to use external libraries for your Java code, the code need be packaged either in a <code>.jar</code> file or your class files need to be archived into a <code>.zip</code> file. We give the external library a name, in the <code>file_spec</code> we point to where the file resides, and finally, we set the <code>LANGUAGE</code> parameter to <code>Java</code>:</p>

<pre><code class="language-sql">USE JavaTest;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Create External Library</em></p>

<p>The code we see in <em>Code Snippet 2</em> is fairly self-explanatory, where we name the external library <code>myCalc</code> and the code is at <code>W:\javacodepath\MyCalcJar.jar</code>. What is interesting when creating external libraries for Java is that the name does not matter (apart from that it has to be unique).</p>

<p>To see that it has worked we use catalog views to investigate:</p>

<pre><code class="language-sql">SELECT el.name, el.[language], ef.content
FROM sys.external_libraries el
JOIN sys.external_library_files ef
  ON el.external_library_id = ef.external_library_id
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>View External Libraries</em></p>

<p>In <em>Code Snippet 3</em> we do a <code>SELECT</code> against <code>sys.external_libraries</code> and <code>sys.external_library_files</code>, and when we execute the result looks like so:</p>

<p><img src="/images/posts/sql_2k19_java_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>External Libraries View</em></p>

<p>We see in <em>Figure 1</em> some information about the external library. The <code>content</code> column outlined in red is interesting in that it contains the binary representation of the external library. This is like assemblies in SQLCLR. They are persisted to system tables and, when needed, loaded from the tables based on the binary representation. External libraries are the same, persisted to system tables, and when needed they are loaded from those tables.</p>

<p>So by loading the code from the database, we no longer need to worry about permissions and where to load the code from. An additional benefit is that the external libraries are database bound. If you backup and restore the database to another machine, the external libraries are there, as opposed to if you load them from a file location.</p>

<p>As good as this is, there is a problem or rather a caveat. What we have done so far requires the code for the external library to be in a location SQL Server can read. I as a developer may not have access to the file system of the SQL box. So in the rest of this post, we look at some options how we can create an external library on a remote SQL Server, where we do not have access to the file system, but we can access the SQL Server instance via SSMS or in my case, <a href="https://github.com/Microsoft/azuredatastudio">Azure Data Studio</a>.</p>

<h2 id="demo-code">Demo Code</h2>

<p>Before diving into what we want to do, let us look at the code we use today (it looks very similar to the code in the previous post):</p>

<pre><code class="language-sql">USE master
GO

DROP DATABASE IF EXISTS JavaTest;
GO

DROP DATABASE IF EXISTS JavaTestLocal;
GO

DROP DATABASE IF EXISTS JavaTestRemote;
GO

CREATE DATABASE JavaTestLocal;
GO

CREATE DATABASE JavaTestRemote;
GO
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create Databases</em></p>

<p>We see in <em>Code Snippet 4</em> how we create a couple of databases. Since I do not have access to a remote SQL Server right now, I emulate the remote SQL by the <code>JavaTestRemote</code> database. Oh, and the first database I drop, that is the one we used in the previous post. We also need some Java code. We assume the code below is in a source file named <code>Calculator.java</code>:</p>

<pre><code class="language-java">public class Calculator {
    public static short numberOfOutputCols;
    public static int x;
    public static int y;

    static public int[] outputDataCol1;
    static public boolean[][] outputNullMap;

    public static void adder() {
        numberOfOutputCols = 1;
        outputDataCol1 = new int[1];
        outputDataCol1[0] = x + y;
        outputNullMap = new boolean[1][1];
    }
}
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Java Calculator</em></p>

<p>The code in <em>Code Snippet 5</em> is the same we used in <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>. As I mentioned in the <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">last post</a> that if you wonder about the variables in the code, the other posts in the Java <a href="/s2k19_ext_framework_java">series</a> discuss them in detail.</p>

<p>The last thing to do before we can talk about how to solve the issue with having to have access to the file system of the box SQL Server is on is to compile the code in <em>Code Snippet 5</em> and create a <code>.jar</code> for it:</p>

<pre><code class="language-java">$ javac .\Calculator.java
$ jar -cf MyCalcJar.jar .\Calculator.class
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Compile and Create a jar File</em></p>

<p>After running the code in <em>Code Snippet 6</em> we have a <code>.jar</code> file which we use to create the external library.</p>

<h2 id="external-library">External Library</h2>

<p>The question is now how to create the external library on a remote SQL Server instance if we do not have access to the file system on that server? Let us look at <code>CREATE EXTERNAL LIBRARY</code>&rsquo;s signature again (we saw it in the previous <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">post</a>):</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]  
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>Remember how we said in <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>, that <code>file_spec</code> points to the content of the package/code, and we saw in <em>Code Snippet 2</em> how we set <code>file_spec</code> to the path of the file.</p>

<p>However, we also said in the last <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">post</a> that <code>file_spec</code> can be a hex literal, similar to what we do when we create assemblies in SQLCLR. The hex literal is the actual binary representation of the package, and if we can get hold of the binary somehow we are &ldquo;golden&rdquo;. So, let us look at a couple of ways we can get hold of the binary package representation:</p>

<ul>
<li>From a local database.</li>
<li>Generate binary from code.</li>
</ul>

<h4 id="local-database">Local Database</h4>

<p>Let us start with a way to get the binary from a local database.</p>

<blockquote>
<p><strong>NOTE:</strong> This is similar to what we do at <a href="/derivco">Derivco</a> when we generate SQL statements to deploy SQLCLR assemblies.</p>
</blockquote>

<p>We see in <em>Figure 1</em> the <code>content</code> column, which we said before contains the binary representation of the package. What we do is to log on to the local database <code>JavaTestLocal</code>, and create the external library from the <code>.jar</code> file we created in <em>Code Snippet 6</em>:</p>

<pre><code class="language-sql">USE JavaTestLocal;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Create Local External Library</em></p>

<p>As SQL Server is installed on my local dev-machine, and SQL Server has access to the <code>W:\javacodepath</code> path, the code in <em>Code Snippet 8</em> executes ok.</p>

<p>We know from <a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a> and from the summary above how the binary representation of the package is stored in the <code>content</code> column of the <code>sys.external_library_files</code> catalog view. Let us grab the content of the <code>content</code> column:</p>

<pre><code class="language-sql">USE JavaTestLocal;
GO

DECLARE @binrep varbinary(max);

SELECT @binrep = lf.content
FROM sys.external_library_files lf
JOIN sys.external_libraries l
  ON lf.external_library_id = l.external_library_id
WHERE l.name = 'myCalc';

PRINT @binrep;
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Retrieve the Binary Representation</em></p>

<p>We see in <em>Code Snippet 9</em> how we <code>DECLARE</code> a variable <code>@binrep</code> which is a <code>varbinary</code>, and then we <code>SELECT</code> the value of the <code>content</code> column into the variable. We finally <code>PRINT</code> the content of the variable and we get something like so when we execute:</p>

<blockquote>
<p><strong>EDIT (2019-04-10):</strong> The above method works only with packages with a size less than 8k. See <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> for an explanation, and a way around it.</p>
</blockquote>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_binrep.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Binary Representation</em></p>

<p>In <em>Figure 2</em> we see part of the binary value of the package. We copy that into a new query window connected to the remote server and database, and we do a new <code>CREATE EXTERNAL LIBRARY</code>, but instead of a file-path for the <code>CONTENT</code> parameter we paste in the binary representation:</p>

<pre><code class="language-sql">USE JavaTestRemote;
GO

CREATE EXTERNAL LIBRARY myCalcRemote
FROM (CONTENT = 0x504B03041400080808007B34684E...)
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Use Binary as CONTENT</em></p>

<p>We see how the <code>CONTENT</code> parameter in <em>Code Snippet 10</em> now contains the binary value of the external library. After we execute the code in <em>Code Snippet 10</em> we test to see that it has worked by executing on the remote SQL Server:</p>

<pre><code class="language-sql">USE JavaTestRemote;
GO

EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int',
@x = 21,
@y = 21;
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Execute Against Calculator.adder</em></p>

<p>The result of running the code in <em>Code Snippet 11</em> is:</p>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_queryres1.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Result</em></p>

<p>From what we see in <em>Figure 3</em>, everything has worked.</p>

<p>We used the binary representation of an external library on our local SQL Server instance to create an external library on a remote instance. We do this without having access to the remote file system.</p>

<p>That is all well and good, but what if we do not have access to a local SQL Server?</p>

<h4 id="generate-binary-from-code">Generate Binary from Code</h4>

<p>The second way we can get the binary representation is to generate it from code. When I started looking into this post and how to generate the binary representation I first started with C# as I am a .NET guy. However, boy, that was a lot of code (slight exaggeration), and wouldn&rsquo;t it be &ldquo;cool&rdquo; if I could just run a script, and send in a file-path to the package? Everyone told me that Python is what all the &ldquo;cool kids&rdquo; use, so I decided to go with Python, and this is the code I started with:</p>

<pre><code class="language-python">import binascii

filePath = &quot;W:\\javacodepath\\MyCalcJar.jar&quot;

with open(filePath, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify( \
                       bytearray(myArr)).decode('utf-8')

print(hex_bytes)
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Generate Binary from Python</em></p>

<p>When we look at the code in <em>Code Snippet 12</em> we see how:</p>

<ul>
<li>I <code>import</code> the <code>binascii</code> module which contains a number of methods to convert between binary and various ASCII-encoded binary representations.</li>
<li>I hardcode (for now) the file-path to where the <code>.jar</code> file is.</li>
<li>I open the file in binary mode. The <code>&quot;rb&quot;</code> in the <code>open(filePath, &quot;rb&quot;)</code> indicates I want the file as binary.</li>
<li>I read the file into a byte array (<code>myArr</code>).</li>
<li>I turn the byte-array into hex representation, and then I print the hex representation.</li>
</ul>

<p>The code is in a source file named <code>outputBinary.py</code>, and when I execute it from a command prompt I see the following:</p>

<p><img src="/images/posts/sql_2k19_java_ext_lib2_python1.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Python Output</em></p>

<p>The (cropped) binary output in <em>Figure 4</em> is the same as we used in <em>Code Snippet 10</em>. We can now copy the output as we see in <em>Figure 4</em> and do exactly what we did before.</p>

<p>However, why do copy and paste when we can connect directly from Python to the remote database and execute <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-python">import pyodbc
import binascii

filePath = &quot;W:\\javacodepath\\MyCalcJar.jar&quot;
extLibName = 'myCalcRemote'

with open(filePath, &quot;rb&quot;) as binaryfile :
    myArr = binaryfile.read()
    hex_bytes = '0x' + binascii.hexlify(bytearray(myArr)).decode('utf-8')

# connect to db

dbServer = 'localhost\s2k19_ctp23_1'
dataBase = 'JavaTestRemote'
userName = '&lt;some_user_name'
password = '&lt;some_pwd&gt;'

drvr = '{ODBC Driver 17 for SQL Server}'
connStr = f'DRIVER={drvr};SERVER={dbServer};DATABASE={dataBase};UID={userName};PWD={password}'
conn = pyodbc.connect(connStr)
cursor = conn.cursor()

execStmt = f'CREATE EXTERNAL LIBRARY {extLibName}\n'
execStmt = execStmt + f'FROM (CONTENT = {hex_bytes})\n'
execStmt = execStmt + f&quot;WITH (LANGUAGE = 'Java');\n&quot;

cursor.execute(execStmt)
conn.commit()
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Create External Library from Python Code</em></p>

<p>Before we look at the code in <em>Code Snippet 13</em> let us drop the external library we just created in the remote SQL Server instance: <code>DROP EXTERNAL LIBRARY myCalcRemote</code>. This to ensure we are back in a state with no external libraries installed.</p>

<p>So, what do we do in <em>Code Snippet 13</em>? Well, we use the same code as in <em>Code Snippet 12</em> to generate the binary representation, but we do not do a <code>PRINT</code> of it. Instead, we connect to the database using the <code>pyodbc</code> module, and the latest SQL Server ODBC driver. The <code>hex_bytes</code> variable is now a parameter in the <code>CREATE EXTERNAL LIBRARY</code> statement, and we have a hardcoded variable for the name of the external library.</p>

<p>As the code is just sample code, the connection details for the database is also hardcoded. In a real-world scenario, the script should prompt for the various details; file path, name, connection details etc., and assign the inputs to the variables:</p>

<pre><code class="language-python">extLibName = input(&quot;Provide a unique name for \
                   the external library you want to create: &quot;)
filePath = input(&quot;Provide full path to the JAR \
                  file you want to use - \
                  Example: 'W:\\javacodepath\\myJarFile.jar': &quot;)
dbServer = input(&quot;Provide name/ip address of your \
                  database server. If instance also instance name \ 
                  - Example: 'mydbServer\myInstance: &quot;)
dataBase = input(&quot;Provide name of the database where you \
                  want to create the external library: &quot;)
userName = input(&quot;Provide the user name with which you \
                   want to connect to the server: &quot;)
password = input(&quot;Provide password with which to \
                  connect to the database: &quot;)
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>Input Variables</em></p>

<p>It is worth noting that the way the script captures the password variable is not particularly secure. Instead of <code>input</code>, we should use <code>getpass</code> or something similar.</p>

<blockquote>
<p><strong>NOTE:</strong> Unless the user with which you connect is part of <code>db_owner</code>, the user needs explicit permissions to execute <code>CREATE EXTERNAL LIBRARY</code>.</p>
</blockquote>

<p>To test this, you replace the variables in <em>Code Snippet 13</em> with relevant values for your environment and run the code. The code should run OK, and you have now created an external library in a database in a remote SQL Server (well, in my case an emulated remote SQL Server).</p>

<h2 id="summary">Summary</h2>

<p>In this post, we set out to solve the issue of how to create an external library of some Java code without having access to the filesystem of the SQL Server where we want to create the external library.</p>

<p>We have seen two ways of doing it:</p>

<h4 id="local-datbase">Local Datbase</h4>

<ol>
<li>Create the external assembly from a file-path in a local SQL Server where we have access to the filesystem (like <code>localhost</code>).</li>
<li>Copy the binary representation from the <code>content</code> column in <code>sys.external_library_files</code>.</li>
<li>Assign the copied value to the <code>CONTENT</code> parameter in <code>CREATE EXTERNAL LIBRARY</code>.</li>
<li>Execute <code>CREATE EXTERNAL LIBRARY</code>.</li>
</ol>

<h4 id="generate-from-code">Generate from Code</h4>

<ol>
<li>Write script code which generates the binary representation.</li>
<li>Follow from step 2 above (local database).</li>
</ol>

<p>Alternatively, you in addition to generate the binary in the script, connect to the database from inside the script and call <code>CREATE EXTERNAL LIBRARY</code> from the script.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 10, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/10/interesting-stuff---week-10-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-10T13:14:44+02:00</updated>
    <id>http://nielsberglund.com/2019/03/10/interesting-stuff---week-10-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://blog.acolyer.org/2019/03/08/a-generalised-solution-to-distributed-consensus/">A generalised solution to distributed consensus</a>. Distributed consensus is hard! In this blog post <a href="https://twitter.com/adriancolyer">Adrian</a> dissects a white-paper which re-examines the foundations of distributed consensus.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/microsoft-opens-first-datacenters-in-africa-with-general-availability-of-microsoft-azure/">Microsoft opens first datacenters in Africa with general availability of Microsoft Azure</a>. I guess the title says it all! On March 6, Microsoft opened two data centers in South Africa: South Africa North (Johannesburg) and South Africa West (Cape Town). At the moment the offerings are somewhat sparse, but I have no doubt we&rsquo;ll soon see quite a lot of services.</li>
<li><a href="https://azure.microsoft.com/en-us/blog/service-fabric-processor-in-public-preview/">Service Fabric Processor in public preview</a>. Azure Event Hub is an elegant way to ingest data into the Azure ecosystem, and Service Fabric is awesome for hosting and running microservices. Quite often some of the services need to consume from Azure Event Hubs, and until now you have had to write your own consumer, most likely based on <em>Event Processor Host</em>. That changes now with the preview of <em>Service Fabric Processor</em>, which is a new library for consuming events from an Event Hub that is directly integrated with Service Fabric. Awesome!</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://devblogs.microsoft.com/dotnet/announcing-net-core-3-preview-3/">Announcing .NET Core 3 Preview 3</a>. What the title says; .NET Core 3 Preview 3 is available for download. Go and get it!</li>
<li><a href="https://devblogs.microsoft.com/dotnet/collecting-net-core-linux-container-cpu-traces-from-a-sidecar-container/">Collecting .NET Core Linux Container CPU Traces from a Sidecar Container</a>. This blog post gives a step-by-step guide of using a sidecar container to collect CPU trace of an ASP.NET application running in a Linux container.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://101.datascience.community/2019/03/07/microsoft-launches-data-science-certifications/">MICROSOFT LAUNCHES DATA SCIENCE CERTIFICATIONS</a>. In this blog post <a href="https://twitter.com/ryanswanstrom">Ryan</a> discusses 3 new certifications Microsoft recently announced aimed at Data Scientists/Engineers. I have always been skeptic to certifications by vendors, brain dumps anyone, but I will definitely have a look at this.<br /></li>
<li><a href="https://eng.uber.com/machine-learning-capacity-safety/">Using Machine Learning to Ensure the Capacity Safety of Individual Microservices</a>. This is a very interesting post by Uber&rsquo;s engineering team, discussing how they apply Machine Learning to forecast micro-services issues!</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="/2019/03/10/sql-server-2019-java--external-libraries---i/">SQL Server 2019, Java &amp; External Libraries - I</a>. Earlier today I published this post, in which I talk about how to deploy Java code to a database, so it can be loaded from there.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019, Java &amp; External Libraries - I]]></title>
    <link href="http://nielsberglund.com/2019/03/10/sql-server-2019-java--external-libraries---i/" rel="alternate" type="text/html"/>
    <updated>2019-03-10T10:22:51+02:00</updated>
    <id>http://nielsberglund.com/2019/03/10/sql-server-2019-java--external-libraries---i/</id>
    <content type="html"><![CDATA[<p>A couple of months ago I wrote a series of posts about one of the new features in SQL Server 2019; the ability to call out to Java code from inside SQL Server.</p>

<p>To see the posts, go to <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a>.</p>

<p>In the posts, we discussed how the Java extension differs from R and Python in that R and Python are an integrated part of the SQL Server install (when enabling in-database analytics), but Java is not. In other words, the use of the Java extension requires Java to be installed beforehand, and this then has implications on permissions. We also discussed how Java is a compiled language, and we execute against a method in a class, whereas with R and Python we send a script to the external engine. The consequence of this is that when we execute Java code, we need to indicate where the compiled code resides, and those locations need specific permissions.</p>

<p>All this creates a level of complexity, and it would potentially be easier if we load the Java code from a well-known place, where we do not need to worry about permissions and so forth.</p>

<p>This post is the first of a couple where we see how new functionality in SQL Server 2019 CTP 2.3 can help.</p>

<p></p>

<h2 id="code-background">Code &amp; Background</h2>

<p>Let us start with looking at the code we use today, and also remind ourselves of some of the complexities when calling Java from SQL server.</p>

<p>So, the code:</p>

<pre><code class="language-java">public class Calculator {
    public static short numberOfOutputCols;
    public static int x;
    public static int y;

    static public int[] outputDataCol1;
    static public boolean[][] outputNullMap;

    public static void adder() {
        numberOfOutputCols = 1;
        outputDataCol1 = new int[1];
        outputDataCol1[0] = x + y;
        outputNullMap = new boolean[1][1];
    }

}
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Java Calculator</em></p>

<p>As we see in *Code Snippet 1`, the code is very simple, and we have seen variants of it in my other <a href="/s2k19_ext_framework_java">Java posts</a>. If you wonder about some of the variables in the code, the previous <a href="/s2k19_ext_framework_java">posts</a> discuss them in detail.</p>

<p>To use the code from SQL Server, we compile the source file <code>Calculator.java</code>: <code>$ javac Calculator.java</code>, into a <code>.class</code> file: <code>Calculator.class</code>.
After compilation, we can now place the <code>Calculator.class</code> in any of the locations a pre-defined <code>CLASSPATH</code> environment variable points to. To call the <code>adder</code> method from inside SQL Server we execute like so:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
    @language = N'Java',
    @script = N'Calulator.adder',
    @params = N'@x int, @y int',
    @x = 21,
    @y = 21;
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Execute from SQL Server</em></p>

<p>By the fact that the <code>.class</code> file is in a <code>CLASSPATH</code> location, the code in <em>Code Snippet 2</em> succeeds, <strong>IF</strong> the right permissions exist on the location.</p>

<blockquote>
<p><strong>NOTE:</strong> The required permission is <code>READ</code> for the <code>ALL APPLICATION PACKAGES</code> group.</p>
</blockquote>

<p>Having the code in a <code>CLASSPATH</code> location is one way to load and execute the code. Another way is to have the code in an arbitrary location and explicitly set a parameter in the SQL call to point to that location:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
    @language = N'Java',
    @script = N'Calculator.adder',
    @params = N'@x int, @y int, @CLASSPATH nvarchar(512)',
    @x = 21,
    @y = 21,
    @CLASSPATH = N'W:\javacodepath';
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Using @CLASSPATH Parameter</em></p>

<p>In <em>Code Snippet 3</em> we see how we set a parameter <code>CLASSPATH</code> to point to where the code is. The permission requirements for this scenario are the same as for when we have a defined <code>CLASSPATH</code>: the location need <code>READ</code> permission for the <code>ALL APPLICATION PACKAGES</code> group.</p>

<blockquote>
<p><strong>NOTE:</strong> You may wonder where the <code>CLASSPATH</code> parameter in <em>Code Snippet 3</em> comes from, as it is not part of the signature of <code>sp_execute_external_script</code>? This parameter is a well-known parameter for the SQL Server Java language extension, and if this parameter exists the extension sets the <code>--classpath</code> option in the <code>java</code> command.</p>
</blockquote>

<p>In the code snippets above we execute against <code>.class</code> files. In the &ldquo;real world&rdquo; however you are unlikely to do that, but instead, you use <code>.jar</code> files. So let us see how we do that from SQL Server. First, we compile the <code>.java</code> source, followed by creating the <code>.jar</code>:</p>

<pre><code class="language-java">$ javac .\Calculator.java
$ jar -cf MyCalcJar.jar .\Calculator.class
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Create a jar File</em></p>

<p>After we have created the <code>MyCalcJar.jar</code> as in <em>Code Snippet 4</em>, we copy the <code>.jar</code> to either the <code>CLASSPATH</code> location or an arbitrary location. To execute we call it like so:</p>

<pre><code class="language-sql">EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int, @CLASSPATH nvarchar(max)',
@x = 21,
@y = 21,
@CLASSPATH = N'W:\javacodepath\MyCalcJar.jar'
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Execute Against a jar File</em></p>

<p>We see in <em>Code Snippet 5</em> how we when we execute against a <code>.jar</code> need to:</p>

<ul>
<li>Set the path to the <code>.jar</code>, using the using the <code>CLASSPATH</code> parameter. This is required <strong>even</strong> if the <code>.jar</code> is in the actual <code>CLASSPATH</code>.</li>
<li>Include the name of the <code>.jar</code> file.</li>
</ul>

<p>We also need to ensure that the permissions mentioned above exist where ever the <code>.jar</code> is.</p>

<p>So the examples above re-enforce what we mentioned in the beginning, Java incurs some complexity which we do not have when executing R/Python code:</p>

<ul>
<li>Where to load the code from.</li>
<li>Permissions on said location.</li>
</ul>

<p>Apart from pointing out the complexities at the beginning of this post I also mentioned that new functionality in SQL Server 2019 CTP 2.3 helps to solve this. That functionality is the ability to create external libraries.</p>

<h2 id="external-libraries">External Libraries</h2>

<p>External libraries in SQL Server enables the ability to load artefacts needed for any new language runtimes and OS platforms supported by SQL Server from the database. For example, if you need an R package that is not part of the default install of the engine you can upload to the database the particular R package as an external library and use it from the database in question. An external library is similar to a CLR assembly in that the actual library exists in the database as a byte-stream <del>and SQL Server loads it from the database</del>.</p>

<blockquote>
<p><strong>EDIT (2019-04-10):</strong> *It so turns out that what I wrote about SQL Server loading from the database is not correct. It loads the pakage(s) from the external library path.  See <a href="/2019/04/10/installing-r-packages-in-sql-server-machine-learning-services---iii/">Installing R Packages in SQL Server Machine Learning Services - III</a> for more around this.</p>
</blockquote>

<p>You create an external library in a similar to how you create a CLR assembly; you use a DDL statement <code>CREATE EXTERNAL LIBRARY</code>:</p>

<pre><code class="language-sql">CREATE EXTERNAL LIBRARY library_name  
[ AUTHORIZATION owner_name ]  
FROM &lt;file_spec&gt; [ ,...2 ]  
WITH ( LANGUAGE = &lt;language&gt; )  
[ ; ]  
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Signature CREATE EXTERNAL LIBRARY</em></p>

<p>In <em>Code Snippet 6</em> we see the signature for <code>CREATE EXTERNAL LIBRARY</code>. We see only the main parts:</p>

<ul>
<li><code>library_name</code> - the name we want the library to have. When we create an external library for Java code we can assign any name we want. However, when we create an external library for R, the name must be the same as what we refer to the package when we load it in the external script.</li>
<li><code>owner_name</code> - optional, and it specifies the name of the user or role that owns the external library.</li>
<li><code>file_spec</code> - this is the content of the package/code. For Java it has to be a <code>.jar</code> file, or a <code>.zip</code> file with relevant <code>.class</code> files in it. The <code>file_spec</code> can be either a path to the file, or a byte array. Part of the <code>file_spec</code> is also the platform on which SQL Server is running. For now, only Windows is supported.</li>
<li><code>language</code> - the language of the package/code.</li>
</ul>

<blockquote>
<p><strong>NOTE:</strong> I mentioned above that we see the main parts of <code>CREATE EXTERNAL LIBRARY</code>, and we have not drilled down in detail. If you are interested in the details look <a href="https://docs.microsoft.com/en-us/sql/t-sql/statements/create-external-library-transact-sql?view=sql-server-ver15">here</a>.</p>
</blockquote>

<p>To see this in practice, we need first to create a database: <code>CREATE DATABASE JavaTest</code>, (we can obviously use an existing db as well). Then, based on the code in <em>Code Snippet 4</em> and <em>Code Snippet 5</em>, the call to create an external library for our calculator looks like so:</p>

<pre><code class="language-sql">USE JavaTest;
GO

CREATE EXTERNAL LIBRARY myCalc
FROM (CONTENT = 'W:\javacodepath\MyCalcJar.jar')
WITH (LANGUAGE = 'Java');
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Create External Library</em></p>

<p>What we see in <em>Code Snippet 7</em> is how we create an external library named <code>myCalc</code>, where the external library is based on a <code>.jar</code> file at <code>W:\javacodepath\MyCalcJar.jar</code>. The last thing we do is to indicate that the language is <code>Java</code>. As the only platform supported right now is Windows, we do not bother with the <code>PLATFORM</code> parameter.</p>

<p>To verify this works after we execute the code in <em>Code Snippet 7</em> we use exactly the same code as in <em>Code Snippet 2</em>:</p>

<pre><code class="language-sql">USE JavaTest;
GO

EXECUTE sp_execute_external_script
@language = N'Java',
@script = N'Calculator.adder',
@params = N'@x int, @y int',
@x = 21,
@y = 21;
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Execute Java Code Loaded from Database</em></p>

<p>In <em>Code Snippet 8</em> we see how we no longer define the <code>.jar</code> file as a parameter, (what we had to do in <em>Code Snippet 5</em>), but when we execute all works OK.</p>

<p>The question is now where the <code>.jar</code>,(or <code>.zip</code>), loads from. The answer to that is, (like with SQLCLR), that it loads from system tables in the database. When we create an SQLCLR assembly in a database, SQL Server stores the assembly in system tables, and we use catalog views to view the assemblies: <code>sys.assemblies</code>, <code>sys.assembly_files</code>, and so on. External libraries do not use the same underlying tables or catalog views, but to see the external libraries you use:</p>

<ul>
<li><code>sys.external_libraries</code> - contains a row for each external library that has been uploaded into the database.</li>
<li><code>sys.external_library_files</code> - lists a row for each file in the external library.</li>
<li><code>sys.external_libraries_installed</code> - shows what libraries have been loaded, e.g. used.</li>
</ul>

<p>An example of this:</p>

<pre><code class="language-sql">SELECT el.name, el.[language], ef.content
FROM sys.external_libraries el
JOIN sys.external_library_files ef
  ON el.external_library_id = ef.external_library_id
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>View External Libraries</em></p>

<p>When we run the code in <em>Code Snippet 9</em> we get:</p>

<p><img src="/images/posts/sql_2k19_java_view_ext_lib.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>External Libraries View</em></p>

<p>We see in <em>Figure 1</em> some information about the external library. The <code>content</code> column outlined in red is interesting in that it contains the binary representation of the external library.</p>

<h2 id="summary">Summary</h2>

<p>In this post, we saw how we can make the use of Java in SQL Server somewhat less complex (permissions, code paths, etc.), by using external libraries.</p>

<p>To be able to use external libraries for your Java code, the code need be packaged either in a <code>.jar</code> file, or your class files need to be archived into a <code>.zip</code> file.</p>

<p>We create the external library using the DDL statement <code>CREATE EXTERNAL LIBRARY</code> where we:</p>

<ul>
<li>Define a name for the library.</li>
<li>Indicate where the <code>.jar</code> or <code>.zip</code> file is.</li>
<li>Set the language to Java.</li>
</ul>

<p>When we execute against the code we no longer need to have the code copied to the <code>CLASSPATH</code> or define a <code>@CLASSPATH</code> parameter, and no special permissions are required. Well, you need permissions to execute <code>sp_execute_external_script</code> but apart from that nothing else.</p>

<p>When we call <code>sp_execute_external_script</code> SQL Server loads the code from a system table, and we can view what external libraries exist in the database by using the <code>sys.external_libraries</code> and <code>sys.external_library_files</code> catalog views.</p>

<p>As good as all this sounds, there is one minor, (well perhaps not so minor), detail to be aware of: the way we create external libraries in this post - from a file path - requires SQL Server to be able to read from that path. In a production environment that may not be possible, so in a future post we look at how to overcome that.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 9, 2019]]></title>
    <link href="http://nielsberglund.com/2019/03/03/interesting-stuff---week-9-2019/" rel="alternate" type="text/html"/>
    <updated>2019-03-03T10:54:21+02:00</updated>
    <id>http://nielsberglund.com/2019/03/03/interesting-stuff---week-9-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/architecting-transactional-system">Achieving High Throughput with Reliability in Transactional Systems</a>. This presentation from <a href="https://www.infoq.com/">InfoQ</a> discusses architecting and designing a high performance, throughput &amp; data processing transactional system and real-time access to large datasets via APIs.</li>
<li><a href="https://www.infoq.com/presentations/monolith-microservices-refactoring-analysis-tools">Getting from Monolith to Microservices</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation looks at strategies to break a monolith, from the front-end to the back, including database refactoring and analysis tools to see dependencies in legacy code.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://towardsdatascience.com/training-your-first-classifier-with-spark-and-scala-893d7c6f7d88">Training Your First Classifier with Spark and Scala</a>. This post is an excellent introduction to machine learning with Spark and Scala.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.ververica.com/blog/monitoring-apache-flink-applications-101">Monitoring Apache Flink Applications 101</a>. This blog post provides an introduction to Apache Flink’s built-in monitoring and metrics system, that allows developers to monitor their Flink jobs effectively.</li>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-3-affinity-between-events-streams-serverless">Journey to Event Driven – Part 3: The Affinity Between Events, Streams and Serverless</a>. This post is the third part in the <a href="https://www.confluent.io/blog/journey-to-event-driven-part-1-why-event-first-thinking-changes-everything">Journey to Eventdriven</a> series, and it looks at how event-driven streaming architectures fit with serverless.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/03/01/sql-server-2019-community-technology-preview-2-3-is-now-available/">SQL Server 2019 community technology preview 2.3 is now available</a>. What the title of the post says: CTP2.3 of SQL Server 2019 is now available for download. I have already downloaded and installed the Windows version, and right now I am in the process of installing the SQL Server 2019 Big Data Cluster on Azure Kubernetes Service. Happy Days!</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 8, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/24/interesting-stuff---week-8-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-24T10:08:50+02:00</updated>
    <id>http://nielsberglund.com/2019/02/24/interesting-stuff---week-8-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<p>For some reason I did not find that much interesting to me this week, but here is what caught my eye.</p>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.ververica.com/blog/batch-as-a-special-case-of-streaming-and-alibabas-contribution-of-blink">Batch as a Special Case of Streaming and Alibaba&rsquo;s contribution of Blink</a>. This post discusses the in-house improvements to Flink batch processing Alibaba has done and contributed to open source. Oh, when you read the post, and you wonder what Ververica is, read <a href="https://www.ververica.com/blog/introducing-our-new-name">this post</a>.</li>
<li><a href="https://www.infoq.com/presentations/apache-flink-streaming-app">Patterns of Streaming Applications</a>. This presentation from <a href="https://www.infoq.com/">InfoQ</a> talks about a blueprint for streaming data architectures and a review of desirable features of a streaming engine. The presentation also discusses streaming application patterns and anti-patterns, and use cases and concrete examples using Apache Flink.</li>
<li><a href="https://www.infoq.com/presentations/wepay-database-streaming">The Whys and Hows of Database Streaming</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses how database streaming is becoming more and more essential and the many functions that database streaming serves. The presentation also covers challenges faced with streaming peer-to-peer distributed databases.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 7, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/17/interesting-stuff---week-7-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-17T08:20:06+02:00</updated>
    <id>http://nielsberglund.com/2019/02/17/interesting-stuff---week-7-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/chaos-engineering-gamedays">Chaos Engineering with Containers</a>. This <a href="https://www.infoq.com/">InfoQ</a> presentation discusses the benefits of using Chaos Engineering to inject failures to make container infrastructure more reliable.</li>
<li><a href="https://www.infoq.com/presentations/10-kubernetes">The 10 Kubernetes Commandments</a>. The presenters in this <a href="https://www.infoq.com/">InfoQ</a> presentation explore topics from booting Kubernetes clusters to running complex workloads as a list of 10 items. They share ideas that teams can employ to make working Kubernetes less of a chore and more of a way of life.</li>
<li><a href="https://www.infoq.com/presentations/kubernetes-stateful-containers">The Highs and Lows of Stateful Containers</a>. So far, it has been a lot of containers and <a href="https://www.infoq.com/">InfoQ</a> presentations, and the third item this week is more of the same. In this <a href="https://www.infoq.com/">InfoQ</a> presentation the presenter walks through his experiences of how to reliably run a distributed database on Kubernetes, and optimize its performance. He looks at what kinds of stateful applications can most easily be run in containers, and some pitfalls he encountered along the way.</li>
</ul>

<h2 id="sql-server">SQL Server</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/02/13/the-february-release-of-azure-data-studio-is-now-available/">The February release of Azure Data Studio is now available</a>. I must say that Azure Data Studio (ADS) has grown on me, and now I use it almost exclusively (instead of SQL Server Management Studio). The post I link to here announces the latest release of ADS with quite a few new features. Go and grab it, and see what you think.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/kafka-connect-jdbc-source-connector-deep-dive">Kafka Connect JDBC Source Connector – Deep Dive</a>. An excellent blog post by <a href="https://twitter.com/rmoff">Robin Moffat</a>, where he drills deep into the inner workings of the Kafka Connect JDBC connector.</li>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-2-programming-models-event-driven-architecture">Journey to Event Driven – Part 2: Programming Models for the Event-Driven Architecture</a>. In <a href="/2019/02/03/interesting-stuff---week-5-2019/">Interesting Stuff - Week 5, 2019</a> I linked to <a href="https://www.confluent.io/blog/journey-to-event-driven-part-1-why-event-first-thinking-changes-everything">Journey to Event Driven – Part 1: Why Event-First Thinking Changes Everything</a>. This weeks blog post is part 2 of the series, and it looks at different styles of event-driven architectures and compares and contrasts scaling, persistence and runtime models.</li>
</ul>

<h2 id="azure-force-recon">Azure Force Recon</h2>

<p>I just want to remind you of the <a href="https://www.meetup.com/Azure-Transformation-Labs/events/258705868/">Azure Force Recon</a> boot camp held here in Durban February 23. I have the privilege to do a presentation: <a href="https://www.linkedin.com/feed/update/activity:6500043306041384960/">Live and Die with your Data</a>, where I talk about SQL Server 2019 Big Data Clusters. So, if you do not have anything else to do, sign up and come and hear about Azure!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 6, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/10/interesting-stuff---week-6-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-10T08:37:39+02:00</updated>
    <id>http://nielsberglund.com/2019/02/10/interesting-stuff---week-6-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/02/Oreilly-microservices-maturity">O’Reilly Publishes “The State of Microservices Maturity” Report</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article discussing a report by O&rsquo;Reilly about microservices. In the report, O&rsquo;Reilly concludes that microservices are evolving into a trend and that DevOps and microservices feed off each other.</li>
<li><a href="https://www.infoq.com/presentations/messaging-architecture-future">Point-to-Point Messaging Architecture - The Reactive Endgame</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> presentation where the presenters explore the current state of messaging architecture and provide an R&amp;D perspective on the future of distributed systems.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/02/CSharp-Lambda-Attributes">C# Futures: Lambda Attributes</a>. In this article <a href="https://www.infoq.com/">InfoQ</a> looks at a proposal for adding attributes to lambdas and anonymous functions.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="https://blogs.microsoft.com/ai/azure-data-explorer-lake-storage/">Solving a common corporate conundrum: Making sense of all that data</a>. This post discusses the newly announced Azure Data Explorer and its capabilities of analyzing 1 billion records of streaming data per second, as well as data stored in Azure Data Lake Storage.</li>
<li><a href="https://databricks.com/blog/2019/02/07/high-performance-modern-data-warehousing-with-azure-databricks-and-azure-sql-dw.html">High-Performance Modern Data Warehousing with Azure Databricks and Azure SQL Data Warehouse</a>. This blog post discusses how we can use Azure Data Factory, Azure Data Lake Storage together with Azure Databricks to load data into Azure SQL Data Warehouse for analysis, etc.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://blogs.msdn.microsoft.com/dotnet/2019/02/07/announcing-ml-net-0-10-machine-learning-for-net/">Announcing ML.NET 0.10 – Machine Learning for .NET</a>. This post does what the title says; it announces the release of ML.NET 0.10. Read the post to see what new features are part of this release.</li>
<li><a href="https://www.confluent.io/blog/machine-learning-with-python-jupyter-ksql-tensorflow">Machine Learning with Python, Jupyter, KSQL and TensorFlow</a>. As it says in this post: &ldquo;This blog post focuses on how the Kafka ecosystem can help solve the impedance mismatch between data scientists, data engineers and production engineers.&rdquo;.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/processing-trillions-of-events-per-day-with-apache-kafka-on-azure/">Processing trillions of events per day with Apache Kafka on Azure</a>. This is cool; the post talks about the optimal setup to run one of the largest Kafka deployments in the world, and achieve a throughput of trillion events per day.</li>
<li><a href="https://www.confluent.io/blog/beginners-perspective-kafka-streams-building-real-time-walkthrough-detection">A Beginner’s Perspective on Kafka Streams: Building Real-Time Walkthrough Detection</a>. In retail, it is essential to detect when a customer walks in or out of a store. This blog post discusses how a company used Kafka and KSQL to be able to react quicker and with more accuracy.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://buckwoody.wordpress.com/2019/02/02/sql-server-big-data-clusters-workshop-at-sql-bits/">SQL Server Big Data Clusters Workshop at SQL Bits</a>. UK&rsquo;s leading SQL Server conference <a href="https://sqlbits.com/">SQLBits</a> takes place in Manchester at the end of February. If you are attending, don&rsquo;t miss <a href="https://twitter.com/BuckWoodyMSFT">Buck Woody&rsquo;s</a> one day SQL Server 2019 Big Data Cluster workshop. Buck knows what he talks about and he also has members of the SQL Server 2019 Big Data Cluster team on-site. I wish I could be there!</li>
</ul>

<h2 id="azure-force-recon">Azure Force Recon</h2>

<p>Speaking about conferences and SQL Server Big Data Clusters; February 23 the first of many <a href="https://www.meetup.com/Azure-Transformation-Labs/events/258705868/">Azure tactical bootcamps</a> is being held here in Durban, and I have the privilege to do a presentation: <a href="https://www.linkedin.com/feed/update/activity:6500043306041384960/">Live and Die with your Data</a>, where I talk about SQL Server 2019 Big Data Clusters. So, if you do not have anything else to do, sign up and learn about Azure!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 5, 2019]]></title>
    <link href="http://nielsberglund.com/2019/02/03/interesting-stuff---week-5-2019/" rel="alternate" type="text/html"/>
    <updated>2019-02-03T09:15:51+02:00</updated>
    <id>http://nielsberglund.com/2019/02/03/interesting-stuff---week-5-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/containers-infrastructure-virtualization">P to V to C: The Value of Bringing “Everything” to Containers</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation examining the benefits of containerization, the role of infrastructure virtualization, discussing containers, pods, controllers, policies and more.</li>
<li><a href="https://www.infoq.com/presentations/kubernetes-yaml">Dissecting Kubernetes (K8s) - An Intro to Main Components</a>. Another <a href="https://www.infoq.com/">InfoQ</a> presentation, and in this presentation we see how to deploy containers, building up a mini cluster one Kubernetes component at a time, and it also explains what happens to the YAML files involved. The presentation is an excellent introduction to the inner workings of Kubernetes.</li>
<li><a href="https://srcco.de/posts/kubernetes-failure-stories.html">KUBERNETES FAILURE STORIES</a>. Kubernetes is not only roses and plain sailing. This blog post looks at what can go wrong with Kubernetes.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/01/IAsyncDisposable-IAsyncEnume">Update on IAsyncDisposable and IAsyncEnumerator</a>. This <a href="https://www.infoq.com/">InfoQ</a> blog post looks at changes made recently to the .NET Core async streams proposal.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/journey-to-event-driven-part-1-why-event-first-thinking-changes-everything">Journey to Event Driven – Part 1: Why Event-First Thinking Changes Everything</a>. This article is the first in a series about event architecture. Event-driven architecture is a topic that I am extremely interested in, so I am really looking forward to next &ldquo;episode&rdquo; in the series.</li>
</ul>

<h2 id="microsoft-ignite-the-tour">Microsoft Ignite The Tour</h2>

<p>So, Microsoft Ignite The Tour did a stop in Johannesburg February 28 &amp; 29, and I had the privilege to present at the conference. I did three sessions:</p>

<ul>
<li><a href="http://bit.ly/2S3xtg8">What is That Cup of Coffee Doing in my Database</a>: This 15-minute talk takes a look at the new Java integration in SQL Server 2019.</li>
<li><a href="http://bit.ly/2MvQySO">SQL Server Machine Learning Services: An E2E platform for machine learning</a>: We talk about how SQL Server Machine Learning Services can function as an end-to-end platform for AI and Machine Learning.</li>
<li><a href="http://bit.ly/2sPvA8E">Deep dive on SQL Server and big data</a>: We look at how SQL Server 2019 Big Data Clusters work.</li>
</ul>

<p>If you attended the conference and would like to get the slide decks, please <a href="mailto:niels.it.berglund@gmail.com">ping</a> me as I cannot find where to upload them to.</p>

<p>I had a great time at the conference, kudos to the organizers!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 4, 2019]]></title>
    <link href="http://nielsberglund.com/2019/01/27/interesting-stuff---week-4-2019/" rel="alternate" type="text/html"/>
    <updated>2019-01-27T06:36:21+02:00</updated>
    <id>http://nielsberglund.com/2019/01/27/interesting-stuff---week-4-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="cloud">Cloud</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/microsoft-tfs-azure-devops">Journey to Cloud Architecture</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation discussing the architectural challenges faced turning TFS into Azure DevOps, the evolution of the architecture, and lessons learned along the way.</li>
</ul>

<h2 id="misc">Misc.</h2>

<ul>
<li><a href="https://www.infoq.com/articles/why-architectural-diagrams">Why Do We Need Architectural Diagrams?</a>. An <a href="https://www.infoq.com/">InfoQ</a> article about software architecture diagrams. Software architecture diagrams, when created well, and sparingly, can greatly improve communication within the development team and with external stakeholders. They require an understanding of the intended audience and thoughtful restraint on what to include. Resist the temptation to think that diagrams are unnecessary or unhelpful, simply because there have been plenty of cases of bad diagrams.</li>
</ul>

<h2 id="azure">Azure</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/hdinsight-tools-for-visual-studio-code-now-generally-available/">HDInsight Tools for Visual Studio Code now generally available</a>. A post announcing GA (general availability) of HDInsight Tools for <strong>VS Code</strong>. Seeing that I have started using <strong>VS CODE</strong> more and more, this is something I need to check out.</li>
<li><a href="https://azure.microsoft.com/en-us/blog/analyze-data-in-azure-data-explorer-using-kql-magic-for-jupyter-notebook/">Analyze data in Azure Data Explorer using KQL magic for Jupyter Notebook</a>. In this post, Microsoft announces the ability to, from inside a Jupyter Notebook, use <em>Keyword Query Language</em> (KQL) to query and analyze data in Azure Data Explorer. Very cool!</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/confluent-raises-a-125m-series-d-funding-round">Confluent Raises a $125M Series D Funding Round</a>. This blog post is about how Confluent has raised &ldquo;some&rdquo; money from investors, good for them. What is interesting in the post for me is this: <em>We think there is a really fundamental missing ingredient in the software architecture of a company, namely the idea of &ldquo;events&rdquo;. These events are the orders, sales, and customer experiences, that constitute the operation of the business. Databases have long helped to store the current state of the world, but we think this is only half of the story. What is missing is the continually flowing stream of events that represents everything happening in a company, and that can act as the lifeblood of its operation.</em>. This is music to my ears!</li>
<li><a href="https://www.datasciencecentral.com/profiles/blogs/apache-kafka-ksql-tensorflow-for-data-scientists-via-python">Apache Kafka + KSQL + TensorFlow for Data Scientists via Python + Jupyter Notebook</a>. A very, very interesting post, discussing how to use Kafka and KSQL together with machine learning tools such as Jupyter notebooks, Python, and deep learning frameworks.</li>
</ul>

<h2 id="msignite-the-tour">MSIgnite | The Tour</h2>

<p>Later today, (Sunday, Jan 27), I am off to Johannesburg and The <strong>MSIgnite | The Tour</strong> conference, where I give some presentations on Monday and Tuesday (Jan 28 and 29):</p>

<ul>
<li><a href="http://bit.ly/2S3xtg8">What is That Cup of Coffee Doing in my Database</a>: This 15-minute talk takes a look at the new Java integration in SQL Server 2019.</li>
<li><a href="http://bit.ly/2MvQySO">SQL Server Machine Learning Services: An E2E platform for machine learning</a>: We talk about how SQL Server Machine Learning Services can function as an end-to-end platform for AI and Machine Learning.</li>
<li><a href="http://bit.ly/2sPvA8E">Deep dive on SQL Server and big data</a>: We look at how SQL Server 2019 Big Data Clusters work.</li>
</ul>

<p>If you are attending the conference, please come by and say Hi!</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 3, 2019]]></title>
    <link href="http://nielsberglund.com/2019/01/20/interesting-stuff---week-3-2019/" rel="alternate" type="text/html"/>
    <updated>2019-01-20T18:00:59+02:00</updated>
    <id>http://nielsberglund.com/2019/01/20/interesting-stuff---week-3-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="misc">Misc.</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/01/rearchitecture-system-success">An Incremental Architecture Approach to Building Systems</a>. An <a href="https://www.infoq.com/">InfoQ</a> article about building systems and how, to avoid over-engineering, we should start with a simple architecture and evolve it as needs arise.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/news/2019/01/Net-Core-3-System-Data">System.Data in .NET Core 3.0</a>. The first of two <a href="https://www.infoq.com/">InfoQ</a> articles about <code>System.Data</code> in .NET Core 3.0. The article looks at what changes there are in .NET Core 3.0 for <code>System.Data</code>.</li>
<li><a href="https://www.infoq.com/news/2019/01/Net-Core-3-System-Data-SqlClient">SQL Server and .NET Core 3.0</a>. The second <a href="https://www.infoq.com/">InfoQ</a> article about <code>System.Data</code> in .NET Core 3.0. This time the attention is at <code>System.Data.SqlClient</code>, which is the SQL Server driver.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/stream-processing-part-2-testing-your-streaming-application">Getting Your Feet Wet with Stream Processing – Part 2: Testing Your Streaming Application</a>. The second and last part of a two-part blog series about developing and validating real-time streaming applications. This post looks at how we test streaming applications.</li>
<li><a href="https://www.infoq.com/articles/distributed-stream-processor-container">Scaling a Distributed Stream Processor in a Containerized Environment</a>. This <a href="https://www.infoq.com/">InfoQ</a> article presents ideas and experiences around scaling a distributed stream processor in Kubernetes. The article discusses how the stream processor should identify the level of resource requirement and scale accordingly.<br /></li>
</ul>

<h2 id="wind-what-is-niels-doing">WIND (What is Niels Doing)</h2>

<ul>
<li><a href="/2019/01/17/sql-server-2019--java-with-visual-studio-code/">SQL Server 2019 &amp; Java with Visual Studio Code</a>. A blog-post looking at how we can write SQL Server Java code using <strong>Visual Studio Code</strong>, the <em>VS Code</em>&rsquo;s Java extension, and Maven.</li>
</ul>

<p>If you are at <a href="https://www.microsoft.com/en-za/ignite-the-tour/Johannesburg"><strong>Microsoft Ignite | The Tour</strong></a> in Johannesburg at the end of the month, please come by and say Hi! I deliver three sessions:</p>

<ul>
<li><strong>What is That Cup of Coffee Doing in my Database?</strong> - A 15 minutes whirl-wind tour about the new Java language extension in SQL Server 2019.</li>
<li><strong>SQL Server Machine Learning Services: An E2E platform for machine learning</strong> - A 60-minute break-out session where we look at how SQL Server Machine Learning Services serves as an end-to-end ML platform for customers.</li>
<li><strong>Deep dive on SQL Server and big data</strong> - A 60-minute break-out session where we do a deep dive behind the technology for big data integration with SQL Server including Kubernetes, Polybase futures, and scalable performance.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019 &amp; Java with Visual Studio Code]]></title>
    <link href="http://nielsberglund.com/2019/01/17/sql-server-2019--java-with-visual-studio-code/" rel="alternate" type="text/html"/>
    <updated>2019-01-17T06:16:42+02:00</updated>
    <id>http://nielsberglund.com/2019/01/17/sql-server-2019--java-with-visual-studio-code/</id>
    <content type="html"><![CDATA[<p>As you know, SQL Server 2019 introduces the Java language extensions as part of the <strong>SQL Server Extensibility Framework</strong>. The Java language extensions make it possible to execute Java code from inside SQL Server, the same way we can run R/Python code. Seeing that I am &ldquo;somewhat&rdquo; interested in the <strong>SQL Server Extensibility Framework</strong> I wrote some posts about the Java language extensions: <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a>.</p>

<p>The code in the posts is very, very simplistic where I was just trying to get the ideas across how and what to do. Another reason the code is simplistic is that I am not a Java &ldquo;person&rdquo;; in fact, the only Java code I have ever written is what is in those posts. Me not being a Java &ldquo;person&rdquo; I do not have a Java IDE, (for the code I wrote I did not need one either), so I used my regular text editor <a href="https://www.sublimetext.com/">Sublime Text 3</a>, and I compiled the code from command line (<code>$ javac ...</code>).</p>

<p>I then started on a new Java post (which I have not finished yet), and it became clear I needed an IDE, (intelli-sense, debug, etc.), but which IDE?</p>

<p></p>

<p>As you, my readers, probably know by now, I am a Microsoft and Windows guy at heart, so for me, the natural choice for an IDE has always been Visual Studio. However, even though it might be possible, writing Java code in Visual Studio is not straightforward. So, I thought; &ldquo;I have heard a lot of <a href="https://code.visualstudio.com/"><strong>Visual Studio Code</strong></a>, why not see what that can do&rdquo;. I know that <em>VS Code</em> does support Java, so why not &ldquo;kill two birds with one stone&rdquo;:</p>

<ol>
<li>Get to know <em>VS Code</em>.</li>
<li>Write some Java code.</li>
</ol>

<p>So, in the rest of this post, we see what I did to be able to write, debug, and compile Java code in <em>VS Code</em> for use in SQL Server 2019.</p>

<blockquote>
<p><strong>NOTE:</strong> Even though the title says SQL 2019 and I mention SQL 2019 above, there is very little in the post that is SQL Server 2019 specific. So, this post should be useful as well for you who are only interested in using <em>VS Code</em> for writing and debugging Java applications, no SQL Server at all.</p>
</blockquote>

<h2 id="pre-reqs-enable-java-in-vs-code">Pre-reqs &amp; Enable Java in VS Code</h2>

<p>Let us start with looking at what we need to have installed for Java in <em>VS Code</em> to work:</p>

<h4 id="visual-studio-code">Visual Studio Code</h4>

<p>Well <em>duh</em> - this is kind of obvious, and you can download it from <a href="https://code.visualstudio.com/">here</a>. Below we discuss some more about what we need to do to enable <em>VS Code</em> for Java.</p>

<h4 id="java">Java</h4>

<p>As obvious as <em>VS Code</em> from above. When installing Java, there are a couple of things to think about:</p>

<ul>
<li>Version - personally I use Java 1.8.x, as that works across platforms, and works with SQL Server on both Windows as well as Linux.</li>
<li>Paths  - ensure that the directory where <code>java</code> and <code>javac</code> exists is on the <code>PATH</code>.</li>
<li><code>JAVA_HOME</code> - you need an environment variable - <code>JAVA_HOME</code> - pointing to where the JDK directory is.</li>
</ul>

<h4 id="maven">Maven</h4>

<p><a href="https://maven.apache.org/index.html">Maven</a> is a build automation tool for primarily Java projects. Maven manages a project&rsquo;s build, dependencies, reporting and documentation from a central piece of information, the project object model (<strong>POM</strong>) file. Maven is not absolutely required, but since it is, today, the de-facto standard for Java-based projects, it is a good idea to use it.</p>

<p>You download Maven from <a href="https://maven.apache.org/download.cgi">here</a> and install instructions are <a href="https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-pack">here</a>. After installation, make sure that the directory where the <code>mvn</code> command is, exists on the <code>PATH</code>.</p>

<h2 id="vs-code-extensions">VS Code Extensions</h2>

<p><em>VS Code</em> is a lightweight cross-platform (Windows, Mac, Linux) source code editor, and it comes with built-in support for JavaScript, TypeScript and Node.js. Hmm, this is a Microsoft product, and it has its roots in Visual Studio, and no support for .NET? It is not as bad as it may sound, to add other languages you do it by installing extensions.</p>

<h4 id="installation">Installation</h4>

<p>So, in our case, we should add some Java extensions. Open <em>VS Code</em>, and you see something like this:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_open1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>VS Code Start</em></p>

<p>What you see may not exactly match <em>Figure 1</em> as it opens up in the same state it was in when you last closed it. The important part is what is outlined in red on the <em>Activity</em> bar at the left and towards the bottom of the picture: the context menu for extensions. When you click on that, the result is something like so:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_extensions1.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Enabled VS Code Extensions</em></p>

<p>In <em>Figure 2</em> we see that I have, (on my development box), enabled extensions for C#, Docker, Python and R, and we also see expandable labels for <code>RECOMMENDED</code> and <code>DISABLED</code> extensions, as well as a search box. To find Java extension we enter Java in the search box and hit enter:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_java_extensions.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>VS Code Java Extensions</em></p>

<p>We see quite a few extensions for Java in <em>Figure 3</em>, and I do not know which is best, but I have used the one outlined in red before: <em>Java Extension Pack</em>, so I click on the green <em>Install</em> button:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_java_extension_install.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>VS Code Install Java Extension</em></p>

<p>What we see in <em>Figure 4</em> is that not only the <em>Java Extension Pack</em> gets installed but a few other extensions as well. What is interesting is that among the extensions installed is an extension for Maven. Restart <em>VS Code</em> after the installation of the extensions, and we are ready to go.</p>

<blockquote>
<p><strong>NOTE:</strong> You can read more about the <em>Java Extension Pack</em> <a href="https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-pack">here</a>.</p>
</blockquote>

<h4 id="un-install-remove">Un-install &amp; Remove</h4>

<p>If you do not need an extension any more, you can uninstall it by right-clicking on it and choose <code>Uninstall</code>. In the case of an extension containing other extensions (like the <em>Java Extension Pack</em>), those will be uninstalled as well.</p>

<p>Notice that uninstalling an extension does not remove it, so you still see it among your installed extensions. To completely remove an extension you delete it from the filesystem. You find the extensions at:</p>

<ul>
<li>Windows: <code>%USERPROFILE%\.vscode\extensions</code>.</li>
<li>Mac: <code>~/.vscode/extensions</code>.</li>
<li>Linux: <code>~/.vscode/extensions</code>.</li>
</ul>

<h2 id="java-in-vs-code">Java in VS Code</h2>

<p>We are now ready to write some Java code, so let us open <em>VS Code</em> (if it is not open yet). If you are used to <em>Visual Studio</em>, you would now probably go <strong>File | New Project</strong>, however that is not how you do it in <em>VS Code</em>: create a directory which will be the root of your &ldquo;project&rdquo;, and in <em>VS Code</em> open the directory: <strong>File | Open Folder</strong>:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_open_folder.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>VS Code Open Folder</em></p>

<p>In <em>Figure 5</em> we see how the directory I created, (<code>javatest</code> - outlined in red), is open in the <em>VS Code</em> Explorer. We now go ahead and add a source file to the directory by clicking on the <em>New File</em> icon outlined in blue:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_add_file.png" alt="" /></p>

<p><strong>Figure 6:</strong> <em>VS Code New File in Folder</em></p>

<p>After I click on the <em>New File</em> icon we see in <em>Figure 6</em> how a text box opens under the folder name, and how I name the file: <code>Calculator.java</code>. When I do that the file opens in the <em>VS Code</em> Editor area and I can start editing the file:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_source_file.png" alt="" /></p>

<p><strong>Figure 7:</strong> <em>VS Code Source File</em></p>

<p>The, in red, outlined area in <em>Figure 7</em> is the source file in <em>VS Code</em>&rsquo;s Editor.</p>

<p>The code we want to write is a variant of some code we wrote in <a href="/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/">SQL Server 2019 Extensibility Framework &amp; Java - Misc. &ldquo;Stuff&rdquo;</a>:</p>

<pre><code class="language-java">public class Calculator {
  public static short numberOfOutputCols;
  public static int x;
  public static int y;

  static public int[] outputDataCol1;
  static public boolean[][] outputNullMap;

  public static void main(String[] args) {
      x = 21;
      y = 21;
      adder();
  }

  public static void adder() {
    numberOfOutputCols = 1;
    outputDataCol1 = new int[1];
    int res = x + y;
    outputDataCol1[0] = res;
    System.out.printf(&quot;The result of adding %d and %d = %d&quot;, x, y, res); 
    outputNullMap = new boolean[1][1];
  }
}
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Calculator</em></p>

<p>There are two differences between the code in <em>Code Snippet 1</em>, and the code in <a href="/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/">SQL Server 2019 Extensibility Framework &amp; Java - Misc. &ldquo;Stuff&rdquo;</a>:</p>

<ul>
<li>In <em>Code Snippet 1</em> we have a <code>main</code> method.</li>
<li>The <code>adder</code> method in <em>Code Snippet 1</em> is doing a <code>System.out.printf</code>.</li>
</ul>

<p>The <code>main</code> method in <em>Code Snippet 1</em> is there so we can run the code as an application in <em>VS Code</em> and debug the code. The <code>System.out.printf</code> is there just to get an output during debugging:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_debug.png" alt="" /></p>

<p><strong>Figure 8:</strong> <em>Debugging Java in VS Code</em></p>

<p>So, we see in <em>Figure 8</em> how I have set three breakpoints in my <code>Calculator.java</code> code: at line 8, 16 and 21. I have then hit <strong>F5</strong> to run the code in debug mode, and I eventually hit the breakpoint at line 21. We see, outlined in red, the output of the <code>adder</code> method. Cool, it looks like our code is working, but how do we compile the code into a <code>.class</code> file?</p>

<p>Well, that is the thing, there is no built-in way to compile as we have not (or been able to) treat the code as a project, we just opened a directory and added a file to that directory. If we now want to compile we need to do it from command-line:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_compile.png" alt="" /></p>

<p><strong>Figure 9:</strong> <em>Compile Java in VS Code</em></p>

<p>We open the terminal in <em>VS Code</em> by <strong>View | Terminal</strong>, and in <em>Figure 9</em> we see how we:</p>

<ul>
<li>are in the terminal (the terminal tab, outlined in red).</li>
<li>compile the <code>Calculator.java</code> source file by calling: <code>javac .\Calculator.java</code> (outlined in blue).</li>
<li>see the compiled <code>Calculator.class</code> file (outlined in yellow).</li>
</ul>

<p>When we have the compiled <code>.class</code> file we copy that to the <code>CLASSPATH</code> location and execute against it from SQL Server like so:</p>

<pre><code class="language-sql">DECLARE @p1 int = 21;
DECLARE @p2 int = 21;
EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'Calculator.adder'
, @params = N'@x int, @y int'
, @x = @p1
, @y = @p2 
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Execute from SQL Server</em></p>

<p>What we see in <em>Code Snippet 2</em> is nothing different from what we have done in the posts in the <a href="/s2k19_ext_framework_java">SQL Server 2019 Extensibility Framework &amp; Java</a> series.</p>

<p>We have now seen how we use <em>VS Code</em> to write and debug Java code. However, the code we wrote and debugged was very simple. The question is, how do we handle more complex scenarios - dependencies on external JAR files, compile without having to do it from the command prompt, etc.? That is where Maven enters the picture.</p>

<h2 id="maven-projects">Maven Projects</h2>

<p>I mentioned above how Maven is a build automation tool for primarily Java projects. There are other build tools as well, but in this post, I use Maven as it is - which I mentioned above -  the de-facto standard for Java-based projects.</p>

<p>Above we saw how we installed Maven as well as the <em>VS Code</em> Maven extension, however before we start to use it let us talk a little about Maven archetypes and naming conventions.</p>

<h4 id="maven-archetypes">Maven Archetypes</h4>

<p>A Maven archetype is like a template for a project. Templates can be:</p>

<ul>
<li>Internal: part of the Maven install.</li>
<li>Local: you create archetypes and install them locally.</li>
<li>Remote: archetypes are uploaded to, and exists in repositories.</li>
</ul>

<p>To see what internal archetypes you have installed you run following Maven command: <code>$ mvn archetype:generate -DarchetypeCatalog=internal</code>:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_archetypes_internal.png" alt="" /></p>

<p><strong>Figure 10:</strong> <em>Maven Internal Archetypes</em></p>

<p>In <em>Figure 10</em> we see the internal archetypes and we see (outlined in red) a default archetype, the <code>maven-archetype-quickstart</code>. Oh, the command <code>mvn archetype:generate</code> creates a new Maven project. The command allows you to define what archetype to use, plus properties of the project.</p>

<h4 id="naming-conventions">Naming Conventions</h4>

<p>As mentioned above, when we create a Maven project based on an archetype, we need to define some properties of the project:</p>

<ul>
<li><code>groupId</code>: uniquely identifies a project across all projects. Typically it follows Java&rsquo;s package name rules, (<code>org.apache.maven</code> for example), but it is not required to follow those rules.</li>
<li><code>artifactId</code>: this is like a .NET project name.</li>
<li><code>version</code>: version number (<code>1.0</code>, <code>1.1</code>, etc.).</li>
<li><code>packageName</code>: this is optional. If you do not define a package name, the <code>groupId</code> is used as package name.</li>
</ul>

<p>Now, let us see how we use Maven together with <em>VS Code</em>.</p>

<h2 id="vs-code-maven">VS Code &amp; Maven</h2>

<p>When you click in the Activity pane to view the Explorer (or <strong>View</strong> | <strong>Explorer</strong>), you should see a new tab for <code>MAVEN PROJECTS</code>:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_project1.png" alt="" /></p>

<p><strong>Figure 11:</strong> <em>Maven Projects - I</em></p>

<p>We see, outlined in red, the Maven Projects tab in <em>Figure 11</em>. To create a new Maven project we use the plus icon, outlined in yellow, also in <em>Figure 11</em>, and when we click on the icon we get:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_project2.png" alt="" /></p>

<p><strong>Figure 12:</strong> <em>Select Archetype</em></p>

<p>We see in <em>Figure 12</em> an archetype search box, together with some internally installed archetypes, and we see how we can look for more archetypes in remote repositories. For now, we use the archetype outlined in red: <code>maven-archetype-quickstart</code>. When we choose the <code>quickstart</code> archetype, a file dialog pops up for us to choose a directory for the project. After we have chosen a directory Maven starts to download jar files etc.:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_project3.png" alt="" /></p>

<p><strong>Figure 13:</strong> <em>Maven Downloads</em></p>

<p>When the download finishes (it can take a while), we are asked for some information about the project:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_project4.png" alt="" /></p>

<p><strong>Figure 14:</strong> <em>Project Properties</em></p>

<p>We see in <em>Figure 14</em> how we define the Maven properties:</p>

<ul>
<li><code>groupId</code>: <code>com.nielsberglund.calculator</code>.</li>
<li><code>artifactId</code>: <code>myCalculator</code>.</li>
<li><code>version</code>: <code>1.0</code>.</li>
<li><code>package</code>: <code>javasqlcalc</code>.</li>
</ul>

<p>In <em>Figure 14</em> we see how the package name defaulted to the value of the <code>groupId</code>, but I decided to override and set a shorter package name, as it is preferred not to have multiple levels of package names in the SQL Server Java extension. After we confirmed the properties Maven created the project:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_project5.png" alt="" /></p>

<p><strong>Figure 15:</strong> <em>Project Properties</em></p>

<p>Maven created the project in, (as we see outlined in red in <em>Figure 15</em>),  <code>D:\maventest1\myCalculator</code>. When navigating to <code>D:\maventest1</code> in File Explorer we see the directory hierarchy:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_project6.png" alt="" /></p>

<p><strong>Figure 16:</strong> <em>Project Directory Hierarchy</em></p>

<p>The projects directory/file hierarchy, as we see in <em>Figure 16</em>, is your typical Java project hierarchy with the package name as a directory. If the package name had been something like: <code>com.nielsberglund.calculator</code>, we would see three directories: <code>com</code>, <code>nielsberglund</code>, and <code>calculator</code>.</p>

<p>Ok, so now what - we have a Maven project, but when we look in <em>VS Code</em>, we do not see anything different from when we created the project. We need to, from the <em>File</em> menu open the folder Maven created, in our case the <code>myCalculator</code> folder:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_project7.png" alt="" /></p>

<p><strong>Figure 17:</strong> <em>Open Project Folder in VS Code</em></p>

<p>We opened the <code>myCalculator</code> folder in <em>VS Code</em> as we see in <em>Figure 17</em>, and what is somewhat strange is that we see more folders and files in <em>Figure 17</em>, (outlined in red), than what we do in <em>Figure 16</em>. Those directories/files get created by one of the installed Java extensions when we open the folder. We also see in <em>Figure 17</em> the <code>pom.xml</code> file which defines project dependencies etc.</p>

<p>When we drill down in the directory structure we arrive at a source file:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_source_maven_file.png" alt="" /></p>

<p><strong>Figure 18:</strong> <em>Source File</em></p>

<p>When Maven created the project, it also added the file we see in <em>Figure 18</em>, and this is now our &ldquo;starter&rdquo; file for the project. In this project, we will have multiple source files and to start with we rename the <code>App.java</code> to <code>MyCalculator.java</code>, and also change the class name to <code>MyCalculator</code>. We then add a second source file in the <code>javasqlcalc</code> folder, as we did in <em>Figure 6</em>, we name the file <code>Calculator.java</code>, and in that file create a class named `Calculator. Let us not forget to add the definition at the top of the file.</p>

<p>We want the <code>Calculator</code> class to have an <code>adder</code> instance method, taking two parameters as input, and returning the result of the addition of those two parameters:</p>

<pre><code class="language-java">package javasqlcalc;

public class Calculator {

    public int adder(int x, int y) {
        return x + y;
    }
}
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Calculator Class</em></p>

<p>Nothing strange with the <code>Calculator</code> class as we see in <em>Code Snippet 3</em>.</p>

<p>The <code>MyCalculator</code> class should have a static method looking something like the method in <em>Code Snippet 1</em>, but instead of doing the addition in the method, it creates a new instance of the <code>Calculator</code> class and calls the <code>adder</code> method in that class:</p>

<pre><code class="language-java">public static void adder() {
    numberOfOutputCols = 1;
    outputDataCol1 = new int[1];

    Calculator calc = new Calculator();

    int res = calc.adder(x, y);
    outputDataCol1[0] = res;
    System.out.printf(&quot;The result of adding %d and %d = %d&quot;, x, y, res); 
    outputNullMap = new boolean[1][1];
}
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>The adder method in MyCalculator Class</em></p>

<p>In <em>Code Snippet 4</em> we see the changed, (from what we see in <em>Code Snippet 1</em>), <code>adder</code> method. Copy the code in the <code>main</code> method as we see in <em>Code Snippet 1</em> into the <code>MyCalculator</code> class, and we are now ready to test the code. Set a couple of breakpoints in the code, similar to what we did in <em>Figure 8</em>, and then hit <strong>F5</strong> to debug. The code should now run without any issues.</p>

<h4 id="maven-compile">Maven Compile</h4>

<p>We are now at the same stage we were after <em>Figure 8</em> above when we compiled the code from the command line as in <em>Figure 9</em>. The question is how do we compile when we use Maven? That&rsquo;s easy:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_compile.png" alt="" /></p>

<p><strong>Figure 19:</strong> <em>Maven Compile Menu</em></p>

<p>To compile using Maven we:</p>

<ul>
<li>Right-click on our project under the Maven tab as in <em>Figure 19</em> (outlined in red).</li>
<li>That brings up a menu.</li>
</ul>

<p>We click on the <code>compile</code> menu entry, outlined in yellow in <em>Figure 19</em>, which calls <code>mvn compile ...</code> from <em>VS Code</em>&rsquo;s built-in terminal:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_compile2.png" alt="" /></p>

<p><strong>Figure 20:</strong> <em>Maven Compile</em></p>

<p>We see in <em>Figure 20</em> the <code>compile</code> command, (outlined in red), and how Maven compiles it into the <code>target\classes</code> directory (outlined in yellow). When we, in File Explorer, navigate to <code>target\classes</code>, we see something like so:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_compile_output.png" alt="" /></p>

<p><strong>Figure 21:</strong> <em>Output After Compile</em></p>

<p>As we see in <em>Figure 21</em> the compilation created a directory with the same name as the package, (outlined in red), and put the two <code>.class</code> files in that directory, (the class files are outlined in yellow). To use this from SQL we now copy the <code>javasqlcalc</code> directory to the <code>CLASSPATH</code> location, and we call it like so:</p>

<pre><code class="language-sql">DECLARE @p1 int = 21;
DECLARE @p2 int = 21;
EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'javasqlcalc.MyCalculator.adder'
, @params = N'@x int, @y int'
, @x = @p1
, @y = @p2 
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Execute from SQL Server</em></p>

<p>In <em>Code Snippet 5</em>, in the <code>@script</code> parameter, we see what we discussed in <a href="/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/">SQL Server 2019 Extensibility Framework &amp; Java - Misc. &ldquo;Stuff&rdquo;</a>; how to call into a method inside a Java package. Once again, do not forget to copy the directory together with the <code>.class</code> files to the location of <code>CLASSPATH</code>.</p>

<h4 id="maven-jar-files">Maven &amp; JAR Files</h4>

<p>We have now seen how we compile Java projects with Maven, and how that generates <code>.class</code> files. In <a href="/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/">SQL Server 2019 Extensibility Framework &amp; Java - Misc. &ldquo;Stuff&rdquo;</a>, we said, however, that in a production environment you do not usually call into <code>.class</code> files directly, but you use JAR files. So, the question is then whether we can compile and create JAR files in <em>VS Code</em> using Maven?</p>

<p>Of course we can, and we do it in almost the same way we compiled in <em>Figure 19</em>:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_jar.png" alt="" /></p>

<p><strong>Figure 22:</strong> <em>Package Java Application</em></p>

<p>To create a JAR file using the <em>VS Code</em> Maven extension we, as we see in <em>Figure 22</em>, right click on our project, (outlined in red), and then in the menu, we click on the <code>package</code> menu item which is outlined in yellow. The result of this is like so:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_jar_compile.png" alt="" /></p>

<p><strong>Figure 23:</strong> <em>Create JAR - I</em></p>

<p>What happens, as we see in <em>Figure 23</em>, is that - in <em>VS Code</em>&rsquo;s built-in terminal the command <code>mvn package ...</code> executes, (outlined in red). Part of the <code>package</code> command is a recompilation, which we see outlined in yellow. The recompilation only happens if necessary, e.g. if there has been code changes between last compilation/packaging and now. After potential recompilation Maven builds the JAR file:</p>

<p><img src="/images/posts/sql_2k19_java_vscode_maven_jar_build.png" alt="" /></p>

<p><strong>Figure 24:</strong> <em>Create JAR - II</em></p>

<p>Finally, Maven builds the JAR file as we see in <em>Figure 24</em> and places it in the <code>target</code> directory. We see how Maven names the JAR file: <code>artifactId</code>-<code>version</code> by default. To use it from SQL Server we copy the JAR file to the <code>CLASSPATH</code> location, as discussed in <a href="/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/">SQL Server 2019 Extensibility Framework &amp; Java - Misc. &ldquo;Stuff&rdquo;</a>, and we call it like so:</p>

<pre><code class="language-sql">DECLARE @p1 int = 21;
DECLARE @p2 int = 21;
EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'javasqlcalc.MyCalculator.adder'
, @params = N'@CLASSPATH nvarchar(256), @x int, @y int'
, @CLASSPATH = N'C:/javacodepath/myCalculator-1.0.jar'
, @x = @p1
, @y = @p2 
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>SQL Call to JAR</em></p>

<p>As we call into a method packaged in a JAR file, we need to set the <code>@CLASSPATH</code> parameter - as we do in <em>Code Snippet 6</em> - and include the JAR file name. The location to where the <code>@CLASSPATH</code> parameter points to, does not need to be the location of the <code>CLASSPATH</code> environment variable, but it is important that the <code>ALL APPLICATION PACKAGES</code> group has <code>READ</code> permissions on the location. See <a href="/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/">SQL Server 2019 Extensibility Framework &amp; Java - Misc. &ldquo;Stuff&rdquo;</a> for more about this.</p>

<h2 id="summary">Summary</h2>

<p>As I mentioned i the beginning, this post came about because I needed an IDE to help when writing Java code.</p>

<p>In this post we covered <em>VS Code</em> and its Java extensions, and we also saw how to use Maven to compile Java code and/or package it into JAR files.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Week 2, 2019]]></title>
    <link href="http://nielsberglund.com/2019/01/13/interesting-stuff---week-2-2019/" rel="alternate" type="text/html"/>
    <updated>2019-01-13T19:43:46+02:00</updated>
    <id>http://nielsberglund.com/2019/01/13/interesting-stuff---week-2-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This blog-post is the &ldquo;roundup&rdquo; of the things that have been most interesting to me, for the week just ending.</p>

<p></p>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/articles/dotnet-core-article-second-series">Article Series - .NET Core - 2nd Series</a>. An <a href="https://www.infoq.com/">InfoQ</a> series, exploring some of the benefits of .NET Core and how it can help traditional .NET developers and all technologists that need to bring robust, performant and economical solutions to market.</li>
<li><a href="https://adamsitnik.com/ConcurrencyVisualizer-Profiler/">Profiling Concurrent .NET Code with BenchmarkDotNet and visualizing it with Concurrency Visualizer</a>. A blog post by <a href="https://twitter.com/SitnikAdam">Adam Sitnik</a> who is .NET Mr Performance. In the post, he talks about how to profile multithreaded .NET code using <a href="https://benchmarkdotnet.org/">BenchmarkDotNet</a> and <a href="https://marketplace.visualstudio.com/items?itemName=Diagnostics.ConcurrencyVisualizer2017">Concurrency Visualizer</a>. If you are a .NET developer, do yourself a favor and follow <a href="https://twitter.com/SitnikAdam">Adam</a>.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://www.confluent.io/blog/stream-processing-part-1-tutorial-developing-streaming-applications">Getting Your Feet Wet with Stream Processing – Part 1: Tutorial for Developing Streaming Applications</a>. The first part of a two-part blog series about developing and validating real-time streaming applications. This part is an introduction to streaming application development.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://databricks.com/blog/2019/01/07/introducing-databricks-runtime-5-1-for-machine-learning.html">Introducing Databricks Runtime 5.1 for Machine Learning</a>. A blog post which introduces the latest beta release of Databricks runtime for Machine Learning (version 5.1). The release includes some of the best frameworks for deep learning.</li>
</ul>

<h2 id="sql-server-2019">SQL Server 2019</h2>

<ul>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/01/09/how-to-automate-machine-learning-on-sql-server-2019-big-data-clusters/">How to automate machine learning on SQL Server 2019 big data clusters</a>. This post explores how to use automated machine learning (AutoML) to create new machine learning models over data in SQL Server 2019 big data clusters.</li>
<li><a href="https://cloudblogs.microsoft.com/sqlserver/2019/01/09/the-january-release-of-azure-data-studio-is-now-available/">The January release of Azure Data Studio</a>. A post announcing the latest release of <a href="https://github.com/microsoft/azuredatastudio">Azure Data Studio</a>. Go and download it from <a href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download?view=sql-server-ver15">here</a>.</li>
</ul>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Interesting Stuff - Christmas, New Year, Week 1, 2019]]></title>
    <link href="http://nielsberglund.com/2019/01/06/interesting-stuff---christmas-new-year-week-1-2019/" rel="alternate" type="text/html"/>
    <updated>2019-01-06T17:13:57+02:00</updated>
    <id>http://nielsberglund.com/2019/01/06/interesting-stuff---christmas-new-year-week-1-2019/</id>
    <content type="html"><![CDATA[<p>Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:</p>

<ul>
<li>data science</li>
<li>data in general</li>
<li>distributed computing</li>
<li>SQL Server</li>
<li>transactions (both db as well as non db)</li>
<li>and other &ldquo;stuff&rdquo;</li>
</ul>

<p>This is the &ldquo;roundup&rdquo; of the posts that has been most interesting to me over the Christmas and New Year period.</p>

<p></p>

<h2 id="misc">Misc.</h2>

<ul>
<li><a href="https://blog.acolyer.org/2018/12/19/identifying-impactful-service-system-problems-via-log-analysis/">Identifying impactful service system problems via log analysis</a>. This is the dissection by <a href="https://twitter.com/adriancolyer">Adrian</a> of a white-paper about <a href="https://github.com/logpai/Log3C">Log3C</a>, which is a general framework that identifies service system problems from system logs. Go off and read <a href="https://twitter.com/adriancolyer">Adrian</a>&rsquo;s take on it, and then go and download <a href="https://github.com/logpai/Log3C">Log3C</a>!</li>
<li><a href="https://blog.acolyer.org/2018/12/21/towards-a-theory-of-software-development-expertise/">Towards a theory of software development expertise</a>. The last paper <a href="https://twitter.com/adriancolyer">Adrian</a> looked at in 2018. The paper is about what is a good software developer, and how do you get better?</li>
</ul>

<h2 id="databases">Databases</h2>

<ul>
<li><a href="https://www.infoq.com/presentations/devops-database">DevOps for the Database</a>. An <a href="https://www.infoq.com/">InfoQ</a> presentation trying to find the answer to why it is difficult to apply principles of DevOps to databases.</li>
</ul>

<h2 id="distributed-computing">Distributed Computing</h2>

<ul>
<li><a href="https://muratbuffalo.blogspot.com/2018/12/2-phase-commit-and-beyond.html">Two-phase commit and beyond</a>. An excellent post by <a href="https://twitter.com/muratdemirbas">Murat</a> discussing the two-phase commit protocol. It is an excellent read, and if you have any interest in distributed computing, you should read the post.</li>
</ul>

<h2 id="data-science">Data Science</h2>

<ul>
<li><a href="https://www.kdnuggets.com/2018/08/github-python-data-science-spotlight.html">GitHub Python Data Science Spotlight: AutoML, NLP, Visualization, ML Workflows</a>. A blog post which spotlights a select group of open source Python data science projects with GitHub repos. I am particularly interested in <a href="http://autokeras.com">Auto-Keras</a>, and <a href="https://mlflow.org/docs/latest/index.html">MLFlow</a>.</li>
</ul>

<h2 id="net">.NET</h2>

<ul>
<li><a href="https://www.infoq.com/articles/testing-aspnet-core-web-api">How to Test ASP.NET Core Web API</a>. This is an <a href="https://www.infoq.com/">InfoQ</a> article investigating testing ASP.NET Core 2.0 Web API solutions. The article looks at internal testing with Unit Testing and externally testing with a new testing framework in ASP.NET Core called <em>Integration Testing</em>.</li>
<li><a href="https://www.infoq.com/articles/netcore-cli">A Quick Tour of the .NET CLI</a>. Another <a href="https://www.infoq.com/">InfoQ</a> article, this time it covers how several .Net OSS tools take advantage of the dotnet cli and how we can use the new cli tooling in our daily development.</li>
</ul>

<h2 id="streaming">Streaming</h2>

<ul>
<li><a href="https://azure.microsoft.com/en-us/blog/microsoft-open-sources-trill-to-deliver-insights-on-a-trillion-events-a-day/">Microsoft open sources Trill to deliver insights on a trillion events a day</a>. A blog post introducing <a href="https://github.com/Microsoft/trill">Trill</a>; a high-performance streaming analytics engine. This is something I want to keep my eyes on!</li>
<li><a href="https://www.confluent.io/blog/easy-ways-generate-test-data-kafka">Easy Ways to Generate Test Data in Kafka</a>. As the title says, a post discussing how to generate data for testing in Kafka.</li>
</ul>

<h2 id="what-did-niels-do-during-the-holidays">What Did Niels Do During the Holidays</h2>

<p>I was a, (somewhat), busy bee during the holidays and managed to publish three blog posts:</p>

<ul>
<li><a href="/2018/12/19/sql-server-2019-extensibility-framework--java---null-values/">SQL Server 2019 Extensibility Framework &amp; Java - Null Values</a>. A post where I look at how to handle null values when calling Java code from SQL Server 2019.</li>
<li><a href="/2018/12/24/sql-server-ml-services---multiple-input-data-sets/">SQL Server ML Services - Multiple Input Data Sets</a>. We look at how to push in multiple datasets to external scripts.</li>
<li><a href="/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/">SQL Server 2019 Extensibility Framework &amp; Java - Misc. &ldquo;Stuff&rdquo;</a>. We look at SQL Server 2019 Java Extensions, and Java packages, the CLASSPATH and JAR files.</li>
</ul>

<p>Right now I am working on two more posts related to the <strong>SQL Server 2019 Extensibility Framework</strong>. I hope to publish at least one this coming week.</p>

<h2 id="finally">~ Finally</h2>

<p>That&rsquo;s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server 2019 Extensibility Framework &amp; Java - Misc. &#39;Stuff&#39;]]></title>
    <link href="http://nielsberglund.com/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/" rel="alternate" type="text/html"/>
    <updated>2018-12-30T12:24:53+02:00</updated>
    <id>http://nielsberglund.com/2018/12/30/sql-server-2019-extensibility-framework--java---misc.-stuff/</id>
    <content type="html"><![CDATA[<p>This post is the fourth post in a series where I look at the Java extension in SQL Server, i.e. the ability to execute Java code from inside SQL Server.</p>

<p>To see what other posts there are in the series, go to <a href="/s2k19_ext_framework_java"><strong>SQL Server 2019 Extensibility Framework &amp; Java</strong></a>.</p>

<p>This fourth post acts as a &ldquo;roundup&rdquo; of miscellaneous &ldquo;stuff&rdquo; I did not cover in the three previous posts, and some of the things we look at are:</p>

<ul>
<li>Java packages.</li>
<li>The <code>CLASSPATH</code> environment variable.</li>
<li>JAR files.</li>
</ul>

<p>Ok, let us get into it.</p>

<p></p>

<blockquote>
<p><strong>DISCLAIMER:</strong> *This post contains Java code. I am not a Java guy, in fact, the only Java I have ever written is the code in this post and the previous <strong>SQL Server 2019 Java</strong> posts. So, the code is not elegant in any shape or form, and I am absolutely certain it can be done in a much better way. However, this is not about Java as such, but how you call Java code from SQL Server, and what you need to implement on the Java side.*</p>
</blockquote>

<h2 id="java-packages">Java Packages</h2>

<p>We use packages in Java to prevent naming conflicts, to control access, to make searching/locating and usage of classes, interfaces, enumerations and annotations easier, etc. A Java package is somewhat similar to a .NET namespace in that it can be used to group &ldquo;like-minded&rdquo; classes etc. together.</p>

<p>In <a href="/2018/12/02/sql-server-2019-extensibility-framework--java---hello-world/">SQL Server 2019 Extensibility Framework &amp; Java - Hello World</a> we saw some code looking like so:</p>

<pre><code class="language-java">public class JavaTest1 {
  public static short numberOfOutputCols;
  public static int x;
  public static int y;

  public static void adder() {
    System.out.printf(&quot;The result of adding %d and %d = %d&quot;, x, y, x + y);   
  }

  public static void helloWorld() {
    System.out.print(&quot;Hello World from SQL Java&quot;);
  }
}
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Sample Code</em></p>

<p>As we see in <em>Code Snippet 1</em>, we have one class: <code>JavaTest1</code> with two methods:</p>

<ul>
<li>The method <code>adder</code> which adds two integers together.</li>
<li>The <code>helloWorld</code> method which says hello.</li>
</ul>

<p>Let us break out the <code>adder</code> method, and put it into a class of its own - <code>Calculator</code>:</p>

<pre><code class="language-java">public class Calculator {
  public static short numberOfOutputCols;
  public static int x;
  public static int y;

  public static void adder() {
    System.out.printf(&quot;The result of adding %d and %d = %d&quot;, 
                        x, y, x + y);
  }
}
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Calculator - I</em></p>

<p>We assume the code in <em>Code Snippet 2</em> is in a source file: <code>Calculator.java</code>. We then compile the code into a <code>.class</code> file: <code>javac Calculator.java</code>, and after the compile, we move the <code>Calculator.class</code> to the <code>CLASSPATH</code> location.</p>

<blockquote>
<p><strong>NOTE:</strong> If you wonder why the <code>adder</code> method has no parameters, why we have two class members, <code>x</code> and <code>y</code>, and what is this <code>CLASSPATH</code> thing about, go back to <a href="/2018/12/02/sql-server-2019-extensibility-framework--java---hello-world/">SQL Server 2019 Extensibility Framework &amp; Java - Hello World</a> where it is all explained.</p>
</blockquote>

<p>To execute the code in <em>Code Snippet 2</em> we use more or less the same code as in <a href="/2018/12/02/sql-server-2019-extensibility-framework--java---hello-world/">Hello World</a>:</p>

<pre><code class="language-sql">DECLARE @p1 int = 21;
DECLARE @p2 int = 21;
EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'Calculator.adder'
, @params = N'@x int, @y int'
, @x = @p1
, @y = @p2 
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Execute adder Method</em></p>

<p>In <em>Code Snippet 3</em> we see how we send in two parameters to the java code, and how we call the <code>Calculator.adder</code> method. All works ok, and we get back a result. This application is now deployed, but after a while someone creates a new and better calculator:</p>

<pre><code class="language-java">public class Calculator {
  public static short numberOfOutputCols;
  public static int x;
  public static int y;

  static public int[] outputDataCol1;
  static public boolean[][] outputNullMap;

  static public short numberOfOutputCols;

  public static void adder() {

    numberOfOutputCols = 1;

    outputDataCol1 = new int[1];
    outputDataCol1[0] = x + y;

    outputNullMap = new boolean[1][1];

  }
}
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Calculator - II</em></p>

<p>The new and better calculator, as we see in <em>Code Snippet 4</em>, still takes two class members, but now returns the result as a one column resultset. As we did with the code in <em>Code Snippet 2</em> we put it into a source file, <code>Calculator.java</code> and compile it into <code>Calculator.class</code>. Ok, so far so good. However, what if we try and copy the <code>.class</code> file to the <code>CLASSPATH</code> location, then we overwrite the existing <code>Calculator.class</code>. Not good!</p>

<p>This issue can potentially be resolved by having multiple <code>CLASSPATH</code> locations and copy the <code>.class</code> file to another location, but doing it that way would not guarantee which version of the application we call. That&rsquo;s where Java packages come to the rescue. Change the code in <em>Code Snippet 4</em> slightly:</p>

<pre><code class="language-java">package mycalculator
public class Calculator {
  
  ...

  public static void adder() {
    '''
  }
}
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Calculator &amp; Package</em></p>

<p>In <em>Code Snippet 5</em> we added at the top of the source file: <code>package mycalculator</code>. Ok, so what does this do? Let us experiment:</p>

<ul>
<li>Compile <code>Calculator.java</code> as usual (the edited one).</li>
<li>Rename the <code>Calculator.class</code> file in the <code>CLASSPATH</code> location to something different, (like <code>Calcuator.xxx</code>).</li>
</ul>

<p>After copying the newly compiled <code>Calculator.class</code> to the <code>CLASSPATH</code> location, execute the code in <em>Code Snippet 3</em> again and see if it works:</p>

<p><img src="/images/posts/sql_2k19_java_misc_error1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Cannot Find Class</em></p>

<p>So that didn&rsquo;t work! We see in <em>Figure 1</em> how we get an exception, saying something about not finding class <code>Calculator</code>. Seeing that the code now includes a package name, and reading-up some more about packages, maybe I should include the package name as well in the <code>@script</code> parameter: <code>@script = N'mycalculator.Calculator.adder</code>.</p>

<p>When we try that it still does not work, but I get a somewhat different error message: <code>... Failed to find class mycalculator/Calculator</code>. That error message almost seems like a path. Let us create a directory in the <code>CLASSPATH</code> location named as our package, <code>mycalculator</code>, and move the <code>.class</code> file to there, and see what happens when we execute (still with <code>@script = N'mycalculator.Calculator.adder</code>):</p>

<p><img src="/images/posts/sql_2k19_java_misc_pkg_success.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>Package Success</em></p>

<p>As we see in <em>Figure 2</em>, it works! So, if you compile into packages you need to:</p>

<ul>
<li>Place the code in a directory named as the package in the <code>CLASSPATH</code> location.</li>
<li>Execute the code with the package name in the <code>@script</code> variable: <code>@script=N'packagename.ClassName.methodName</code>.</li>
</ul>

<blockquote>
<p><strong>NOTE:</strong> The Java compiler can automatically create the directory for the package by using the <code>-d</code> option. If you are new to Java (like me), I can recommend <a href="https://www.guru99.com/java-packages.html">this site</a> to read more about packages.</p>
</blockquote>

<h2 id="classpath">CLASSPATH</h2>

<p>In <a href="/2018/12/02/sql-server-2019-extensibility-framework--java---hello-world/">SQL Server 2019 Extensibility Framework &amp; Java - Hello World</a> we discussed the <code>CLASSPATH</code> environment variable briefly. We said that the <code>CLASSPATH</code> variable is there so that the Java Compiler and Java Runtime can find Java classes referenced in your program. It maintains a list of directories (containing many Java class files) and JAR file (a single-file archive of Java classes), and in all of the SQL 2019 Java posts we have copied our <code>.class</code> files to the location of the <code>CLASSPATH</code> variable.</p>

<p>However, when you execute a Java application from the command line you do not have to rely on the <code>CLASSPATH</code> variable, but you can define where to find the application by the <code>-cp</code> option:</p>

<pre><code class="language-bash">W:\&gt;java -cp .\nielsb-work\GitHub-Repos\nielsberglund.com \
               \_code\sql_2k19_java_misc\java Calculator`.
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Usage of -cp Option</em></p>

<p>In <em>Code Snippet 6</em> we see how we, from the root of <code>W:\</code>, call the <code>Calculator</code> application by setting the <code>-cp</code> option to where the application is.</p>

<blockquote>
<p><strong>NOTE:</strong> When calling the application as in <em>Code Snippet 6</em>, the application has to have a <code>main</code> method: <code>public static void main(String[] args)</code>.</p>
</blockquote>

<p>When executing <code>sp_execute_external_script</code> we have the same functionality. We do this by defining, in <code>sp_execute_external_script</code>&rsquo;s <code>@params</code> parameter list, a parameter <code>@CLASSPATH</code>, something like so:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'some_method'
, @params = N'@CLASSPATH nvarchar(256)'
, @CLASSPATH = N'my_path_to_app`

</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Execute with Classpath</em></p>

<p>So, we see, in <em>Code Snippet 7</em>, how we define the <code>@CLASSPATH</code> parameter, and set it to a value. The parameter is a well-known parameter to the Java extension components, and they know how to handle it. The <code>@CLASSPATH</code> parameter is similar to <code>@r_rowsPerRead</code>, for the R/Python components. In <a href="/2018/03/21/microsoft-sql-server-r-services---sp_execute_external_script---iii/">Microsoft SQL Server R Services: sp_execute_external_script - III</a> you can read more about <code>@r_rowsPerRead</code>.</p>

<blockquote>
<p><strong>NOTE:</strong> The <code>@r_rowsPerRead</code> parameter is not supported in the Java extensions.</p>
</blockquote>

<p>To see how to use the <code>@CLASSPATH</code> parameter, (and some &ldquo;gotchas&rdquo;), we create two almost identical applications:</p>

<pre><code class="language-java">// this is the first app
public class Hello {
  
  public static short numberOfOutputCols;
  public static void world() {
    System.out.print(&quot;Hello World 1 from SQL Java&quot;);
  }
}

// this is the second app
public class Hello {
  
  public static short numberOfOutputCols;
  public static void world() {
    System.out.print(&quot;Hello World 2 from SQL Java&quot;);
  }
}
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Java Apps</em></p>

<p>In <em>Code Snippet 8</em> we see both applications (I put them in one code snippet to save space). The only difference between them is what we print out to the &ldquo;console&rdquo;. Copy the two classes into two separate source files (<code>Hello.java</code>), compile and copy the first <code>Hello.class</code> to the location which the <code>@CLASSPATH</code> environment variable points to. Create a new directory, (<code>testpath</code> or something like so), and copy the second <code>Hello.class</code> to that directory.</p>

<p>To be sure that we start afresh, restart the <em>Launchpad</em> service, and then execute:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'Hello.world'
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>Execute against CLASSPATH Environment Variable</em></p>

<p>The code in <em>Code Snippet 9</em> succeeds and returns <code>Hello World 1 from SQL Java</code>, cool. When we executed, the Java runtime found the code in the <code>CLASSPATH</code> location.</p>

<p>Rename the <code>Hello.class</code> file in the <code>CLASSPATH</code> location to something like <code>Hello2.xxx</code>, and now we use code like so:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'Hello.world'
, @params = N'@CLASSPATH nvarchar(256)
, @CLASSPATH = N'C:/testpath'
</code></pre>

<p><strong>Code Snippet 10:</strong> *Execute with <em>CLASSPATH</em> Parameter*</p>

<p>In <em>Code Snippet 10</em> we see how we have defined the <code>@CLASSPATH</code> parameter and set it to the directory where our second Java app is. When we execute the code in <em>Code Snippet 10</em>, we get a surprise:</p>

<p><img src="/images/posts/sql_2k19_java_misc_classpath_error.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Exception</em></p>

<p>Hmm, we get an exception, and the exception says something about not being able to find the class (outlined in red). What is that all about, we know that the <code>.class</code> file contains the class and the method? The issue we see here is related to something we discussed in <a href="/2018/12/02/sql-server-2019-extensibility-framework--java---hello-world/">SQL Server 2019 Extensibility Framework &amp; Java - Hello World</a>, more specifically permissions. Remember how we said that we need to give the <code>ALL APPLICATION PACKAGES</code> group <code>READ</code> permissions on the <code>CLASSPATH</code> directory. The same is true for the directory(is) you define in the <code>@CLASSPATH</code> parameter. So what we need to do is assign <code>READ</code> permissions to the <code>ALL APPLICATION PACKAGES</code> group, and that should then fix it.</p>

<p>Before we do that, however, go to the <code>CLASSPATH</code> location where you have the renamed <code>Hello.class</code> application, and rename it back to its original name. Then execute the code in <em>Code Snippet 10</em> as it stands. Notice how the execution succeeds, and you get <code>Hello World 1 from SQL Java</code> as output. This indicates that when we execute, we first try and find the application in the <code>@CLASSPATH</code> parameter location, and if that does not succeed we try in the <code>CLASSPATH</code> environment variable location. With this in mind the exception we received in <em>Figure 3</em> makes somewhat more sense:</p>

<ul>
<li>We first tried to execute against the code in the <code>@CLASSPATH</code> parameter location.</li>
<li>An exception was thrown before we could execute the actual code.</li>
<li>We fell back to the <code>CLASSPATH</code> environment variable location.</li>
<li>We didn&rsquo;t find the class (as we renamed it).</li>
<li>We throw the exception we see in <em>Figure 3</em>.</li>
</ul>

<p>Ok, so now we can go ahead and assign the <code>ALL APPLICATION PACKAGES</code> group <code>READ</code> permissions on the location of the <code>@CLASSPATH</code> parameter, and then execute the code in <em>Code Snippet 10</em> again:</p>

<p><img src="/images/posts/sql_2k19_java_misc_classpath_success.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Success</em></p>

<p>We see in <em>Figure 4</em> how we get the expected output back when we execute. Assigning the right permissions fixes it as we expected.</p>

<blockquote>
<p><strong>NOTE:</strong> In future SQL Server 2019 CTP releases (and RTM) we most likely will not need to bother with either <code>CLASSPATH</code> or <code>@CLASSPATH</code> as there will be a way to upload JAR files (see below) to the database, and the code gets loaded from there. This is somewhat similar to what we do with SQLCLR today, as well as external libraries for R (<code>CREATE EXTERNAL LIBRARY...</code>).</p>
</blockquote>

<h2 id="jar-files">JAR Files</h2>

<p>So far, in this post as well as previous posts about <strong>SQL Server 2019 Java</strong> extensions, we have dealt with individual <code>.class</code> files, and since the code has just been simple snippets of test code it&rsquo;s okay. In a production environment, outside of SQL Server you would most likely use <strong>JAR</strong> files, as it is common practice and it makes the overall experience more manageable.</p>

<p>JAR stands for <strong>J</strong>ava <strong>AR</strong>chive and is a package file format typically used to aggregate many Java class files and associated metadata and resources (text, images, etc.) into one file for distribution.</p>

<p>To see how this works in SQL Server we start with the <code>Calculator</code> class we see in <em>Code Snippet 2</em>. Compile it into a class file: <code>javac Calculator.java</code>. After compilation, we have a <code>Calculator.class</code>, and we want to create a JAR file containing that <code>Calculator.class</code> file:</p>

<pre><code class="language-bash">jar cvf testjar1.jar Calculator.class
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Create JAR File</em></p>

<p>To create a JAR file, we use something called the <em>Java Archive Tool</em> which is part of the Java Development Kit (JDK). To invoke the <em>Java Archive Tool</em>, we use the <code>jar</code> command as we see in <em>Code Snippet 11</em>. The options and arguments following the <code>jar</code> command in <em>Code Snippet 11</em> are (the following is taken from the <a href="https://docs.oracle.com/javase/tutorial/deployment/jar/build.html">Oracle Java Documentation</a>):</p>

<ul>
<li>The <code>c</code> option indicates that you want to create a JAR file.</li>
<li>The <code>v</code> option produces verbose output while the JAR file builds.</li>
<li>The <code>f</code> option indicates that you want the output to go to a file.</li>
<li>Following <code>cvf</code> is the name of the JAR file you want created.</li>
<li>The last argument is a space-separated list of one or more files that you want to include in your JAR file. This can contain the <code>*</code> wildcard symbol as well as name of directories.</li>
</ul>

<p>When I run the code in <em>Code Snippet 11</em> I see:</p>

<pre><code class="language-bash">W:\path_to_my_source_code&gt;jar cvf testjar1.jar Calculator.class
added manifest
adding: Calculator.class(in = 656) (out= 426)(deflated 35%)
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Output Create JAR File</em></p>

<p>In <em>Code Snippet 12</em> we see how a manifest file is added, together with the <code>.class</code> file. We also see how the <code>.class</code> file is compressed. The manifest file is not required as such, and you can use the <code>M</code> option to indicate you do not want a manifest file. So now we have a JAR file, what do we do with it?</p>

<p>To begin with, delete everything you have in the <code>CLASSPATH</code> location, and also in where <code>@CLASSPATH</code> (<em>Code Snippet 10</em>) points to. Then copy the <code>.jar</code> file created in <em>Code Snippet 12</em> to the <code>CLASSPATH</code> location. The JAR file contains the <code>Calculator</code> class from <em>Code Snippet 2</em>, and we may expect to be able to call it as in <em>Code Snippet 3</em>. However, when we execute the code we get the same error as in <em>Figure 1</em>: <code>... Failed to find class ...</code>. So apparently we cannot call a method in a JAR file the same way as in a <code>.class</code> file. That makes sense when we see how to call an application in a JAR file from the command line:</p>

<pre><code class="language-bash">java -jar &lt;jar_file&gt;
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Calling a JAR File Application</em></p>

<p>In <em>Code Snippet 13</em> we see how we tell the Java launcher, (<code>java</code>), that the application is packaged in a <code>.jar</code> file by using the <code>-jar</code> flag, and we also point to the actual file. To do this in SQL Server, we need to give the full path to the JAR file in the <code>@CLASSPATH</code> variable:</p>

<pre><code class="language-sql">DECLARE @p1 int = 21;
DECLARE @p2 int = 21;
EXEC sp_execute_external_script
  @language = N'Java'
, @script = N'Calculator.adder'
, @params = N'@CLASSPATH nvarchar(256), @x int, @y int'
, @CLASSPATH = N'C:/javacodepath/testjar1.jar'
, @x = @p1
, @y = @p2 
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>Calling a Method in a JAR File</em></p>

<p>We see in <em>Code Snippet 14</em> how we use the <code>@CLASSPATH</code> parameter to indicate what JAR file our method is in,  and when we run the code, we get the expected result back.</p>

<p>So what about the scenario when we have a couple of <code>.class</code> files and one (or more) is part of a package, like what we discussed related to <em>Code Snippet 5</em>? We have:</p>

<ul>
<li>The <code>Calculator</code> class as in <em>Code Snippet 2</em>, compiled to <code>Calculator.class</code>.</li>
<li>The <code>Calculator</code> class in a package <code>mycalculator</code>, compiled to a separate <code>Calculator.class</code>.</li>
</ul>

<p>Remember what we said above how packages need their own directories, and the <code>.class</code> file(s) being inside that directory. I have a directory layout like so:</p>

<p><img src="/images/posts/sql_2k19_java_misc_jar_directories.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Project Directory Layout</em></p>

<p>We see in <em>Figure 5</em> how I have a &ldquo;top&rdquo; level directory <code>calcproj</code>, and in that directory, I have the <code>.class</code> file for the <code>Calculator</code> class we see in <em>Code Snippet 2</em>. Under the <code>calcproj</code> directory I have a directory named as the package in <em>Code Snippet 5</em>, and inside that directory is the <code>.class</code> file for the <em>Code Snippet 5</em> <code>Calculator</code> class. To create the <code>.jar</code> file I run some code like so:</p>

<pre><code class="language-bash">W:\&lt;path&gt;\calcproj&gt;jar cvfM testjar1.jar *
adding: Calculator.class(in = 656) (out= 426)(deflated 35%)
adding: mycalculator/(in = 0) (out= 0)(stored 0%)
adding: mycalculator/Calculator.class(in = 475) (out= 334) (deflated 29%)
</code></pre>

<p><strong>Code Snippet 15:</strong> <em>Create JAR File</em></p>

<p>There are a couple of things to look at in <em>Code Snippet 15</em>:</p>

<ul>
<li>I use a wildcard in the <code>jar</code> command, and this recursively adds <code>.class</code> files and directories to the <code>.jar</code> file.</li>
<li>In the output we see how the <code>mycalculator</code> directory gets added together with the <code>Calculator.class</code> file.</li>
</ul>

<p>To check that what we see in <em>Code Snippet 15</em> is correct we can inspect a <code>.jar</code> file by executing: <code>jar tf testjar1.jar</code>:</p>

<pre><code class="language-bash">W:\&lt;path&gt;\calcproj&gt;jar tf testjar1.jar
Calculator.class
mycalculator/
mycalculator/Calculator.class
</code></pre>

<p><strong>Code Snippet 16:</strong> <em>Inspecting JAR File</em></p>

<p>What we see in <em>Code Snippet 16</em> verifies the output in <em>Code Snippet 15</em>.</p>

<p>After copying the <code>.jar</code> file to the location in <em>Code Snippet 14</em> (and overwriting the file there) we can execute as usual (including the path to the <code>.jar</code> file), and see how it all works:</p>

<ul>
<li><code>@script=N'Calculator.adder</code></li>
<li><code>@script=N'mycalculator.Calculator.adder</code></li>
</ul>

<p>Before I summarize this post, a couple of points about JAR files:</p>

<ul>
<li>The location of the JAR file can be wherever Java can get to it.</li>
<li>The directory where the JAR file needs the usual permissions: <code>READ</code> for the <code>ALL APPLICATION PACKAGES</code> group.</li>
<li>The JAR file does not need to be named <code>.jar</code>, it can have any extension or even no extension at all.</li>
<li>If the JAR file is not found where <code>@CLASSPATH</code> parameter says it is, Java fallbacks to the <code>CLASSPATH</code> and tries to find the class and method as per the <code>@script</code> parameter. It does NOT try and find the JAR file.</li>
</ul>

<h2 id="summary">Summary</h2>

<p>In this blog post we discussed:</p>

<ul>
<li>Java packages</li>
<li>Classpaths</li>
<li>JAR files</li>
</ul>

<h4 id="java-packages-1">Java Packages</h4>

<p>We use Java packages to avoid naming conflicts and to keep &ldquo;like-minded&rdquo; things together. The compiled <code>.class</code> file needs to be in a subdirectory with the same name as the package, and we call it from SQL Server as so: <code>@script = N'packagename.classname.methodname</code>. If the package is like <code>p1.p2</code>, then we need two directories <code>p1/p2</code> and call it like: <code>@script = N'p1.p2.classname.methodname'</code>.</p>

<h4 id="classpaths">Classpaths</h4>

<p>In <a href="/2018/12/02/sql-server-2019-extensibility-framework--java---hello-world/">SQL Server 2019 Extensibility Framework &amp; Java - Hello World</a> we discussed the <code>CLASSPATH</code> environment variable and said it indicated to Java where our applications are located. In this post, we saw how we could have our applications at other locations and indicate where they are by using the <code>@CLASSPATH</code> parameter. When using the <code>@CLASSPATH</code> parameter, we need to ensure that the path has the right permissions: <code>READ</code> for the <code>ALL APPLICATION PACKAGES</code> group.</p>

<p>If we cannot find the method (<code>ClassName.method</code>) in the location indicated by the <code>@CLASSPATH</code> parameter, we fall back to the location of the <code>CLASSPATH</code> environment variable.</p>

<h4 id="jar-files-1">JAR Files</h4>

<p>We use JAR files to typically aggregate many Java class files and associated metadata and resources into one file for distribution. When we use JAR files from SQL Server, we need to explicitly set the path to the JAR file (including the filename) via the <code>@CLASSPATH</code> parameter.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL Server ML Services - Multiple Input Data Sets]]></title>
    <link href="http://nielsberglund.com/2018/12/24/sql-server-ml-services---multiple-input-data-sets/" rel="alternate" type="text/html"/>
    <updated>2018-12-24T06:51:12+02:00</updated>
    <id>http://nielsberglund.com/2018/12/24/sql-server-ml-services---multiple-input-data-sets/</id>
    <content type="html"><![CDATA[<p>This post came about due to a question on the <a href="https://social.msdn.microsoft.com/Forums/en-US/home?forum=MicrosoftR">Microsoft Machine Learning Server</a> forum. The <a href="https://social.msdn.microsoft.com/Forums/en-US/70e3577c-58f1-40af-9f0b-546c8b181cfa/sql-server-r-services-are-more-input-datasets-planned-or-under-development?forum=MicrosoftR">question</a> was if there are any plans by Microsoft to support more the one input dataset (<code>@input_data_1</code>) in <code>sp_execute_external_script</code>. My immediate reaction was that if you want more than one dataset, you can always connect from the script back into the database, and retrieve data.</p>

<p>However, the poster was well aware of that, but due to certain reasons he did not want to do it that way - he wanted to push in the data, fair enough. When I read this, I seemed to remember something from a while ago, where, instead of retrieving data from inside the script, they pushed in the data, serialized it as an output parameter and then used the binary representation as in input parameter (yeah - this sounds confusing, but bear with me). I did some research (read Googling), and found <a href="https://stackoverflow.com/questions/42918990/how-to-pass-two-sql-tables-as-input-parameter-for-r-codes-in-sql-server">this</a> StackOverflow question, and answer. So for future questions, and for me to remember, I decided to write a blog post about it.</p>

<p></p>

<blockquote>
<p><strong>DISCLAIMER:</strong> <em>I want to make it perfectly clear that the method outlined in this post is NOT my idea, but - as mentioned above - comes from the StackOverflow <a href="https://stackoverflow.com/questions/42918990/how-to-pass-two-sql-tables-as-input-parameter-for-r-codes-in-sql-server">answer</a> by <a href="https://twitter.com/@brandonmoretz">Brandon Moretz</a>.</em></p>
</blockquote>

<h2 id="recap">Recap</h2>

<p>We start with a recap about how we pass/retrieve data for external scripts. In <a href="/2018/03/07/microsoft-sql-server-r-services---sp_execute_external_script---i/">Microsoft SQL Server R Services - sp_execute_external_script - I</a> we discussed, among other things, the <code>sp_execute_external_script</code>&rsquo;s <code>@input_data_1</code> parameter and how it specifies the input data used by the external script in the form of a Transact-SQL query:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
            @language = N'R',
            @script = N'
                iris_dataset &lt;- InputDataSet
                setosa &lt;- iris_dataset[iris_dataset$Species == &quot;setosa&quot;,]
                meanSepWidth &lt;- mean(setosa$SepalWidth)
                cat(paste(&quot;Seposa sepal mean width: &quot;, meanSepWidth))',
            @input_data_1 = N'SELECT * FROM dbo.tb_irisdata_full'
</code></pre>

<p><strong>Code Snippet 1:</strong> <em>Using @input_data_1 with straight SELECT</em></p>

<p>In <em>Code Snippet 1</em> we see how the <code>@input_data_1</code> parameter contains a <code>SELECT</code> statement against a table, and the statement executes during the <code>sp_execute_external_script</code> execution. The dataset generated by the query is referred to in the script as <code>InputDataSet</code>. The query has to be based on a <code>SELECT</code>, but it does not have to be against a table, it can be against a view or a user-defined function as well.</p>

<blockquote>
<p><strong>NOTE:</strong> The code in <em>Code Snippet 1</em> above, and <em>Code Snippet 2</em> below, uses tables and data from the <a href="/2018/03/07/microsoft-sql-server-r-services---sp_execute_external_script---i/">Microsoft SQL Server R Services - sp_execute_external_script - I</a> post.</p>
</blockquote>

<p>That is all well and good, but what if you want to push in multiple datasets? Seeing that the parameter we use to define the data ends with a <code>1</code>, it would be logical to think there are <code>@input_data_2</code>, <code>3</code>, and so on - but no, that is not the case. To process more than one dataset in the external script, we have to pull the dataset(s) from inside the script. To do this, we can use <code>ODBC</code> (in R it is the <code>RODBC</code> package, in Python <code>pyodbc</code>) or the highly optimized Microsoft <a href="https://docs.microsoft.com/en-us/machine-learning-server/r-reference/revoscaler/revoscaler"><strong><code>RevoScaleR</code></strong></a> package (in Python <strong><code>revoscalepy</code></strong>). In the following example I use <code>RevoScaleR</code>:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
        @language = N'R',
        @script = N'
          # set up connection string       
          sqlConnString &lt;- &quot;Driver=SQL Server;server=win10-dev;
                            database=IrisTestDb;uid=&lt;some_uid&gt;;pwd=&lt;some_pwd&gt;&quot;
          
          # define the data
          mydata &lt;- RxSqlServerData(table = NULL, 
                                    sqlQuery = &quot;SELECT * 
                                    FROM dbo.tb_irisdata_uneven&quot;, 
                                    connectionString = sqlConnString)

          # open the dataset
          rxOpen(mydata)

          # read the data
          iris_uneven &lt;- rxReadNext(mydata)
          versicolor &lt;- iris_uneven[iris_uneven$Species == &quot;versicolor&quot;,]
          meanSepWidthVersi &lt;- mean(versicolor$SepalWidth)
          
          # get the data from the input data set
          iris_dataset &lt;- InputDataSet
          setosa &lt;- iris_dataset[iris_dataset$Species == &quot;setosa&quot;,]
          meanSepWidth &lt;- mean(setosa$SepalWidth)

          # output the data
          cat(paste(&quot;Seposa sepal mean width:&quot;, meanSepWidth, &quot;.&quot;, 
                     &quot;Versicolor sepal mean width:&quot;, meanSepWidthVersi))',
        @input_data_1 = N'SELECT * FROM dbo.tb_irisdata_even';
</code></pre>

<p><strong>Code Snippet 2:</strong> <em>Multiple Data Sets using RevoScaleR</em></p>

<p>The code in <em>Code Snippet 2</em> shows how we read in data within the script by the use of <code>RevoScaleR</code> functionality together with the data from the <code>@input_data_1</code> parameter, and how we subsequently calculate <code>mean</code> on the two datasets.</p>

<p>So above we see how we can use multiple datasets, but what if we for some or another do not want to / cannot connect from the script to the database, as per the <a href="https://social.msdn.microsoft.com/Forums/en-US/70e3577c-58f1-40af-9f0b-546c8b181cfa/sql-server-r-services-are-more-input-datasets-planned-or-under-development?forum=MicrosoftR">question</a> above? Well, that is what we cover in this post.</p>

<h2 id="multiple-datasets">Multiple Datasets</h2>

<p>What we want to do is to push data from three completely different tables into the external script, and then in the script do something. We use <code>@input_data_1</code> to push one of the datasets, and we look at two different ways to push in the data from the other two tables. The tables we read data from are three system tables, this way we do not need to create separate tables and load data etc.:</p>

<ul>
<li><code>sys.tables</code>.</li>
<li><code>sys.databases</code>.</li>
<li><code>sys.columns</code>.</li>
</ul>

<p>What we want to do in the script is to use R/Python functionality to print out the number of rows that we push in from the separate tables, so we start with some code like this:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
@language = N'R'
, @script = N'
 df &lt;- InputDataSet
 nmbrRows &lt;- nrow(df)
 cat(paste(&quot;Number rows @input_data_1: &quot;, nmbrRows))'
, @input_data_1 = N'SELECT * FROM sys.columns' 
</code></pre>

<p><strong>Code Snippet 3:</strong> <em>Pushing Data via @input_data_1 in R</em></p>

<p>There is nothing strange in <em>Code Snippet 3</em>, we see how we do the <code>SELECT</code> in <code>@input_data_1</code>, and how we in the script:</p>

<ul>
<li>Assign the <code>InputDataSet</code> to a variable: <code>df</code>.</li>
<li>Use the R function <code>nrow</code> to get the number of rows in the data frame (<code>df</code>).</li>
<li>Print it out to the console.</li>
</ul>

<p>When we execute the code in <em>Code Snippet 3</em>, the result is like so:</p>

<p><img src="/images/posts/sql_ml_multidata_input1.png" alt="" /></p>

<p><strong>Figure 1:</strong> <em>Input Data 1 Result</em></p>

<p>From <em>Figure 1</em> we see that the dataset contains 1070 rows.</p>

<p>If we want to do this in Python the code looks like this:</p>

<pre><code class="language-sql">EXEC sp_execute_external_script
@language = N'Python'
, @script = N'
df = InputDataSet
nmbrRows = len(df.index)
print(&quot;Number rows @input_data_1: &quot;, nmbrRows)'
, @input_data_1 = N'SELECT * FROM sys.columns' 
</code></pre>

<p><strong>Code Snippet 4:</strong> <em>Pushing Data via @input_data_1 in Python</em></p>

<p>Nothing strange in <em>Code Snippet 4</em> either. The one noteworthy thing is the use of <code>len(df.index)</code>, instead of <code>count()</code> or <code>shape</code>. I use <code>len(df.index)</code> as &ldquo;people in the know&rdquo; says it performs better. When we execute the code in <em>Code Snippet 4</em>, we get the same result as we see in <em>Figure 1</em>.</p>

<p>Ok, so the code in the two code snippets above, (3 and 4), is the base code for what we want to do. Now we need to figure out how to push two more datasets into the scripts, and there are two ways to do that:</p>

<ul>
<li>JSON.</li>
<li>Binary serialization.</li>
</ul>

<p>Before we look at those two ways, let us discuss briefly a requirement for us to be able to do what we want, and that is the use of the <code>@params</code> parameter in <code>sp_execute_external_script</code>.</p>

<h4 id="params">@params</h4>

<p>The <code>@params</code> parameter is an optional parameter, and when defined it contains a comma separated list of the definitions of all parameters embedded in the values for the <code>@input_data_1</code> and the <code>@script</code> parameters. The string must be either a Unicode constant or a Unicode variable. Each parameter definition consists of a parameter name and a data type. The parameters defined in the <code>@params</code> list need to be added as named parameters to the stored procedure, and in the case of parameters for the external script; the script references the parameters by name but without the <code>@</code> sign.</p>

<p>So, when we push data into the script, either by using JSON or binary serialization we define a parameter for the data which we then reference in the script.</p>

<blockquote>
<p><strong>NOTE:</strong> If you want to get the inner workings of the <code>@params</code> parameter, have a look at my blog post: <a href="/2018/03/11/microsoft-sql-server-r-services---sp_execute_external_script---ii/">Microsoft SQL Server R Services - sp_execute_external_script - II</a>.</p>
</blockquote>

<p>Enough of this preamble, let us get going.</p>

<h4 id="json">JSON</h4>

<p>With the release of SQL Server 2016, Microsoft added support for JSON text processing. Microsoft added JSON functions to SQL Server, which enable you to analyze and query JSON data, transform JSON to relational format, and export SQL query results as JSON text. A typical query producing JSON text can look like this:</p>

<pre><code class="language-sql">SELECT name, object_id, schema_id 
FROM sys.tables
FOR JSON AUTO; 
</code></pre>

<p><strong>Code Snippet 5:</strong> <em>Retrieve JSON Data</em></p>

<p>We see how I use the <code>FOR JSON AUTO</code> syntax in <em>Code Snippet 5</em> to indicate to SQL Server I want JSON formatted data as the resultset. You do not necessarily need to use <code>AUTO</code>, as there are other options. To see more of this look here: <a href="https://docs.microsoft.com/en-us/sql/relational-databases/json/format-query-results-as-json-with-for-json-sql-server?view=sql-server-2016">Format Query Results as JSON with FOR JSON (SQL Server)</a>.</p>

<p>I limit the columns I select to get a more readable output. When I execute and click on the result I see:</p>

<p><img src="/images/posts/sql_ml_multidata_simple_json.png" alt="" /></p>

<p><strong>Figure 2:</strong> <em>JSON Result</em></p>

<p>So in <em>Figure 2</em> we see how my <code>SELECT</code> query results in JSON data.</p>

<p>To solve our problem how to push in multiple datasets, we can now use the JSON formatted data together with the <code>@params</code> parameter to define two parameters containing JSON. For example, <code>@sysTables</code> and <code>@sysDatabases</code>:</p>

<pre><code class="language-sql">DECLARE @sysTabs nvarchar(max) = (SELECT * FROM sys.tables FOR JSON AUTO);
DECLARE @sysDbs nvarchar(max) = (SELECT * FROM sys.databases FOR JSON AUTO);

EXEC sp_execute_external_script
@language = N'Python'
, @script = N'
df = InputDataSet
nmbrRows = len(df.index)
print(&quot;Number rows @input_data_1: &quot;, nmbrRows)'
, @input_data_1 = N'SELECT * FROM sys.columns'
, @params = N'@sysTables nvarchar(max), @sysDatabases nvarchar(max)'
, @sysTables = @sysTabs
, @sysDatabases = @sysDbs;
</code></pre>

<p><strong>Code Snippet 6:</strong> <em>Python Push JSON</em></p>

<p>In <em>Code Snippet 6</em> we see how we:</p>

<ul>
<li>Declare two variables: <code>@sysTabs</code> and <code>@sysDbs</code>, both of type <code>nvarchar(max)</code>, and how we load data into them.</li>
<li>Declare two parameters in the <code>@params</code> parameter list: <code>@sysTables</code> and <code>@sysDatabases</code>.</li>
<li>Define the two parameters and assign <code>@sysTabs</code> and <code>@sysDbs</code> to them.</li>
</ul>

<p>If we were to execute, all would work - but we have not done anything with the parameters in the script. What we need to do is to parse the incoming JSON text into a data frame somehow. To do this in Python, we use the <code>pandas</code> package as it has various functions for parsing JSON.</p>

<blockquote>
<p><strong>NOTE:</strong> The <code>pandas</code> package makes it easy to work with relational data. To find out more about it, go to <a href="https://pandas.pydata.org/pandas-docs/stable/">here</a>.</p>
</blockquote>

<p>Anyway, the function from the <code>pandas</code> package we use is <code>read_json</code>:</p>

<pre><code class="language-sql">DECLARE @sysTabs nvarchar(max) = (SELECT * FROM sys.tables FOR JSON AUTO);
DECLARE @sysDbs nvarchar(max) = (SELECT * FROM sys.databases FOR JSON AUTO);
EXEC sp_execute_external_script
@language = N'Python'
, @script = N'

import pandas as pd

df= InputDataSet
sysTab = pd.read_json(sysTables)
sysDb = pd.read_json(sysDatabases)

print(&quot;Number rows @input_data_1: &quot;, len(df.index))
print(&quot;Number rows @sysTables: &quot;, len(sysTab.index))
print(&quot;Number rows @sysDatabases: &quot;, len(sysDb.index))'
, @input_data_1 = N'SELECT * FROM sys.columns'
, @params = N'@sysTables nvarchar(max), @sysDatabases nvarchar(max)'
, @sysTables = @sysTabs
, @sysDatabases = @sysDbs;
</code></pre>

<p><strong>Code Snippet 7:</strong> <em>Python Parse JSON</em></p>

<p>The code in <em>Code Snippet 7</em> shows how we:</p>

<ul>
<li>Import the <code>pandas</code> package and give it an alias: <code>pd</code>.</li>
<li>Assign the <code>InputDataSet</code> parameter to the <code>df</code> variable as before.</li>
</ul>

<p>We then do the &ldquo;heavy lifting&rdquo; (or rather <code>pandas</code> does), where we transform the JSON text to data frames, by the use of <code>read_json</code>. From the three data frames, we finally print out the number of rows per table. The result when we execute looks like so:</p>

<p><img src="/images/posts/sql_ml_multidata_python_parse_json.png" alt="" /></p>

<p><strong>Figure 3:</strong> <em>Result Python read_json</em></p>

<p>It all works! Oh, it just so happens that I am on an almost new SQL Server instance, and that is why the number of rows in <code>sys.tables</code> and <code>sys.databases</code> is the same.</p>

<p>If R is your &ldquo;poison of choice&rdquo;, then we can, for example, use the <code>jsonlite</code> package. You can read more about it <a href="https://cran.r-project.org/web/packages/jsonlite/jsonlite.pdf">here</a>. What we use from <code>jsonlite</code> is the <code>fromJSON</code> function:</p>

<pre><code class="language-sql">DECLARE @sysTabs nvarchar(max) = (SELECT * FROM sys.tables FOR JSON AUTO);
DECLARE @sysDbs nvarchar(max) = (SELECT * FROM sys.databases FOR JSON AUTO);
EXEC sp_execute_external_script
  @language = N'R'
, @script = N'
    require(jsonlite)
    library(jsonlite)

    df &lt;- InputDataSet
    sysTab &lt;- as.data.frame(fromJSON(sysTables))
    sysDb &lt;- as.data.frame(fromJSON(sysDatabases))

    cat(paste(&quot;Number rows @input_data_1: &quot;, nrow(df)))
    cat(paste(&quot;\nNumber rows @sysTables: &quot;, nrow(sysTab)))
    cat(paste(&quot;\nNumber rows @sysDatabases: &quot;, nrow(sysDb)))'
, @input_data_1 = N'SELECT * FROM sys.columns'
, @params = N'@sysTables nvarchar(max), @sysDatabases nvarchar(max)'
, @sysTables = @sysTabs
, @sysDatabases = @sysDbs;
</code></pre>

<p><strong>Code Snippet 8:</strong> <em>Parse JSON in R</em></p>

<p>The code in <em>Code Snippet 8</em>, looks very similar to what is in <em>Code Snippet 7</em>, and in <em>Code Snippet 8</em> we:</p>

<ul>
<li>Load the <code>jsonlite</code> package.</li>
<li>Assign the <code>InputDataSet</code> parameter to the <code>df</code> variable as before.</li>
<li>Parse the JSON  into data frames using <code>fromJSON</code>.</li>
</ul>

<p>We have now seen how we, both in Python as well as R, can use JSON to push multiple datasets into external scripts, and - as I mentioned above - JSON is one way of doing it. Now onto the next.</p>

<h4 id="binary-serialization">Binary Serialization</h4>

<p>When we use the binary serialization method of pushing multiple datasets, we use R and Python&rsquo;s built-in functionality for serialization and deserialization. In Python, it is with the help of the <code>pickle</code> module, and in R the <code>serialize</code> and <code>unserialize</code> methods.</p>

<p>Initially, binary serialization looks somewhat more complicated than JSON (and it might be), especially since the deserialization happens against a binary parameter serialized with R or Python. In other words, we need to make a roundtrip to R/Python to get the binary representation of the data, so having a helper procedure to do this sounds like a good idea to me:</p>

<pre><code class="language-sql">CREATE PROCEDURE dbo.pr_SerializeHelperR 
                       @query nvarchar(max)
                     , @serializedResult varbinary(max) OUT
AS

EXEC sp_execute_external_script
  @language = N'R'
, @script = N'
  serRes &lt;- serialize(InputDataSet, NULL)'
, @input_data_1 = @query
, @params = N'@serRes varbinary(max) OUT'  
, @serRes = @serializedResult OUT;
</code></pre>

<p><strong>Code Snippet 9:</strong> <em>R Serialization Helper</em></p>

<p>In <em>Code Snippet 9</em> we see an R serialization helper procedure:</p>

<ul>
<li>It takes a query as an input parameter (<code>query</code>).</li>
<li>It has an output parameter which is the serialized result set.</li>
</ul>

<p>The body of the procedure is a call to <code>sp_execute_external_script</code>, where the <code>@query</code> parameter acts as <code>@input_data_1</code>, and we have a defined output parameter <code>@serRes</code>. In the script, we call the R <code>serialize</code> function on the pushed in dataset, and assigns it to the output parameter. The flow:</p>

<ul>
<li>We pass in a query statement.</li>
<li>During the call to <code>sp_execute_external_script</code> the query is run, and the resulting data set passed into the external script.</li>
<li>The external script serializes the dataset and passes it back out as an output parameter.</li>
</ul>

<p>The equivalent Python serialization helper looks like so:</p>

<pre><code class="language-sql">CREATE PROCEDURE dbo.pr_SerializeHelperPy  
                          @query nvarchar(max)
                        , @serializedResult varbinary(max) OUT
AS

EXEC sp_execute_external_script
  @language = N'Python'
, @script = N'
import pickle as p 
serRes = p.dumps(InputDataSet)'
, @input_data_1 = @query
, @params = N'@serRes varbinary(max) OUT'  
, @serRes = @serializedResult OUT;
</code></pre>

<p><strong>Code Snippet 10:</strong> <em>Python Serialization Helper</em></p>

<p>We see in <em>Code Snippet 10</em> how we bring in the <code>pickle</code> module, and then serialize the dataset with the <code>dumps</code> function.</p>

<p>The equivalent of <em>Code Snippet 7</em> using the Python serialization helper looks like so:</p>

<pre><code class="language-sql">-- declare the variables for queries as well 
-- as serialized binary representation
DECLARE @sysTabs nvarchar(max) = 
            'SELECT name, object_id, schema_id 
             FROM sys.tables';
DECLARE @sysDbs nvarchar(max) = 
            'SELECT name, database_id, source_database_id 
             FROM sys.databases';
DECLARE @sysTabsBin varbinary(max);
DECLARE @sysDbsBin varbinary(max);

-- get the serialized result of @sysTabs
EXEC dbo.pr_SerializeHelperPy   @query = @sysTabs
                              , @serializedResult = @sysTabsBin OUT

-- get the serialized result of @sysDbs
EXEC dbo.pr_SerializeHelperPy   @query = @sysDbs
                              , @serializedResult = @sysDbsBin OUT

-- do the &quot;real&quot; stuff
EXEC sp_execute_external_script
@language = N'Python'
, @script = N'
import pandas as pd
import pickle as p 

df = InputDataSet
# this deserializes the sys.tables result
sysTab = p.loads(sysTables)
# this deserializes the sys.databases result
sysDb = p.loads(sysDatabases)
print(&quot;Number rows @input_data_1: &quot;, len(df.index))
print(&quot;Number rows @sysTables: &quot;, len(sysTab.index))
print(&quot;Number rows @sysDatabases: &quot;, len(sysDb.index))'
, @input_data_1 = N'SELECT * FROM sys.columns'
, @params = N'@sysTables varbinary(max), @sysDatabases varbinary(max)'
, @sysTables = @sysTabsBin
, @sysDatabases = @sysDbsBin;
</code></pre>

<p><strong>Code Snippet 11:</strong> <em>Implementation of Python Serialization</em></p>

<p>In <em>Code Snippet 11</em> we see how we:</p>

<ul>
<li>Declare the variables for the queries as well as the serialized results of the queries.</li>
<li>Execute the helper procedure for the two queries we want the results serialized for.</li>
<li>Have defined two <code>varbinary(max)</code> parameters in the <code>@params</code> parameter of <code>sp_execute_external_script</code>.</li>
<li>Assign the serialized values to those two parameters.</li>
<li>Execute <code>sp_execute_external_script</code> and send in the two serialized results as well as <code>@input_data_1</code>.</li>
<li>In <code>sp_execute_external_script</code> we deserialize the results using <code>pickle.loads</code>, or rather <code>p.loads</code> where <code>p</code> is the alias for <code>pickle</code>.</li>
</ul>

<p>The code for an R implementation looks almost the same except that we call the R <code>unserialize</code> function instead of <code>pickle.loads</code>, as per the code below:</p>

<pre><code class="language-sql">-- declare the variables for the querie as well 
-- as serialized binary representation
DECLARE @sysTabs nvarchar(max) = 'SELECT name, object_id, schema_id FROM sys.tables';
DECLARE @sysTabsBin varbinary(max);

-- get the serialized result of @sysTabs
EXEC dbo.pr_SerializeHelperR   @query = @sysTabs
                              , @serializedResult = @sysTabsBin OUT

-- do the &quot;real&quot; stuff
EXEC sp_execute_external_script
@language = N'R'
, @script = N'

sysTab = unserialize(sysTables)
cat(paste(&quot;Number rows @sysTables: &quot;, nrow(sysTab)))'
, @params = N'@sysTables varbinary(max)'
, @sysTables = @sysTabsBin;
</code></pre>

<p><strong>Code Snippet 12:</strong> <em>Implementation of R Serialization</em></p>

<p>We see in <em>Code Snippet 12</em> how we push in one resultset, and we do not use <code>@input_data_1</code>. Instead, we serialize the resultset from the query with the R helper procedure and then deserialize with the <code>unserialize</code> function.</p>

<h2 id="performance">Performance</h2>

<p>So, we have now seen two ways of pushing in datasets to an external script: JSON and Binary Serialization. Which should you choose - I mean, JSON seems a lot easier? The answer comes down to performance.</p>

<p>To look at performance let us create a database, a table and some data:</p>

<pre><code class="language-sql">DROP DATABASE IF EXISTS MultiDataSetDB;
GO
CREATE DATABASE MultiDataSetDB;
GO

USE MultiDataSetDB
GO 

SET NOCOUNT ON;
GO

DROP TABLE IF EXISTS dbo.tb_Rand1M ;
CREATE TABLE dbo.tb_Rand1M
(
  RowID bigint identity,
  y int NOT NULL, 
  rand1 int NOT NULL, 
  rand2 int NOT NULL, 
  rand3 int NOT NULL, 
  rand4 int NOT NULL, 
  rand5 int NOT NULL,
  CONSTRAINT [pk_Rand1M] PRIMARY KEY (RowID)
)
GO
INSERT INTO dbo.tb_Rand1M(y, rand1, rand2, rand3, rand4, rand5)
SELECT TOP(1000000) CAST(ABS(CHECKSUM(NEWID())) % 14 AS INT) 
  , CAST(ABS(CHECKSUM(NEWID())) % 20 AS INT)
  , CAST(ABS(CHECKSUM(NEWID())) % 25 AS INT)
  , CAST(ABS(CHECKSUM(NEWID())) % 14 AS INT)
  , CAST(ABS(CHECKSUM(NEWID())) % 50 AS INT)
  , CAST(ABS(CHECKSUM(NEWID())) % 100 AS INT)
FROM sys.objects o1
CROSS JOIN sys.objects o2
CROSS JOIN sys.objects o3
CROSS JOIN sys.objects o4;
GO
</code></pre>

<p><strong>Code Snippet 13:</strong> <em>Database with Table and Data</em></p>

<p>We see above, in <em>Code Snippet 13</em>, how we create a database, with a table and we load one million records into the table. The data is entirely random and fairly useless, but it serves its purposes.</p>

<blockquote>
<p><strong>NOTE:</strong> If you code along and use the code above, please also create <code>dbo.pr_SerializeHelperPy</code>, which you see in <em>Code Snippet 10</em>, in the <code>MultiDataSetDB</code> database.</p>
</blockquote>

<p>Having created the database and the objects, let us look at the code we use to compare performance. The code below is for JSON:</p>

<pre><code class="language-sql">--this is for JSON
DECLARE @start datetime2 = SYSUTCDATETIME();
DECLARE @rand1M nvarchar(max) = (SELECT TOP(100) * 
                           FROM dbo.tb_Rand1M FOR JSON AUTO);
EXEC sp_execute_external_script
@language = N'Python'
, @script = N'
import pandas as pd

df = pd.read_json(randTab)
print(&quot;Number rows @randTab: &quot;, len(df.index))'
, @params = N'@randTab nvarchar(max)'
, @randTab = @rand1M;
SELECT DATEDIFF(ms, @start, SYSUTCDATETIME()) AS JSONTime; 
GO
</code></pre>

<p><strong>Code Snippet 14:</strong> <em>JSON Performance Code</em></p>

<p>And here is the binary serialization code:</p>

<pre><code class="language-sql">--this is binary
-- declare the variables for queries as well 
--as serialized binary representation
DECLARE @start datetime2 = SYSUTCDATETIME();
DECLARE @rand1M nvarchar(max) = 'SELECT TOP(100) * 
                                FROM dbo.tb_Rand1M';
DECLARE @rand1MBin varbinary(max);
-- get the serialized result of @sysTabs
EXEC dbo.pr_SerializeHelperPy   @query = @rand1M
                              , @serializedResult = @rand1MBin OUT

-- do the &quot;real&quot; stuff
EXEC sp_execute_external_script
@language = N'Python'
, @script = N'
import pandas as pd
import pickle as p 

sysTab = p.loads(randTab)

print(&quot;Number rows @sysTables: &quot;, len(sysTab.index))'
, @params = N'@randTab varbinary(max)'
, @randTab = @rand1MBin
SELECT DATEDIFF(ms, @start, SYSUTCDATETIME()) AS BinaryTime;
GO
</code></pre>

<p><strong>Code Snippet 15:</strong> <em>Binary Serialization Performance Code</em></p>

<p>The code in snippets 14, and 15 is a variant of what we have seen so far. In these two snippets, we only push in one table, and we look at the time it takes to do it. We see how we <code>SELECT</code> from <code>dbo.tb_Rand1M</code>, and initially, we do a <code>TOP(100)</code>.</p>

<p>When I highlight both code snippets and run them a couple of times to not incur &ldquo;startup&rdquo; costs the results are:</p>

<p><img src="/images/posts/sql_ml_multidata_perf1.png" alt="" /></p>

<p><strong>Figure 4:</strong> <em>Performance 100 Rows</em></p>

<p>That&rsquo;s quite interesting; we see in <em>Figure 4</em> how JSON serialization is around twice as fast as binary serialization. Ok, what if we did it on 1000 rows? With 1000 rows JSON is still about twice as fast. However, when we tun it against the full table (one million rows), the results are different:</p>

<p><img src="/images/posts/sql_ml_multidata_perf2.png" alt="" /></p>

<p><strong>Figure 5:</strong> <em>Performance a Million Rows</em></p>

<p>In <em>Figure 5</em> we see how with a million rows, the binary serialization is about 3.5 times faster than JSON. There are a couple of reasons why binary serialization performs better that JSON with larger datasets:</p>

<ul>
<li>Binary serialization is more compact, less data to transfer.</li>
<li>By using the <code>@input_data_1</code> parameter to push in the data to the serialization we get a better performing transport. Read more about it in my post: <a href="/2017/11/25/microsoft-sql-server-r-services---internals-xiv/">Microsoft SQL Server R Services - Internals XIV</a>.</li>
</ul>

<p>So, for very small datasets, use the JSON method, but for larger datasets, the binary serialization is always preferred. Another thing to keep in mind is if you use both <code>@input_data_1</code> as well as pushing in serialized data (like in all our code snippets where we used three tables), try to use <code>@input_data_1</code> for the biggest dataset. That way you get the better performing transport and also, potentially, parallel execution of the query.</p>

<h2 id="summary">Summary</h2>

<p>We have now seen how we can push in multiple datasets to an external script, without having to connect from the script back to the database. We can use two methods:</p>

<ul>
<li>JSON.</li>
<li>Binary serialization.</li>
</ul>

<p>When we use JSON we utilize SQL Server&rsquo;s JSON capabilities to execute a query and receive the result as JSON formatted text: <code>SELECT ... FROM ... FOR JSON AUTO</code>. In the external script we then deserialize the JSON using:</p>

<ul>
<li>In R the <code>fromJSON</code> function in the <code>jsonlite</code> package.</li>
<li>In Python the <code>read_json</code> function in the <code>pandas</code> package.</li>
</ul>

<p>When we do binary serialization we use R/Python&rsquo;s capabilities to both serialize as well as deserialize data. This means we need to do a roundtrip to R/Python to serialize the data. The tools we use:</p>

<ul>
<li>In R we call <code>serialize</code> and <code>unserialize</code>.</li>
<li>In Python we use functions from the <code>pickle</code> package. To serialize we call <code>dumps</code> and to deserialize we use <code>loads</code>.</li>
</ul>

<p>What method to use (JSON or binary serialization) comes down to, in my mind, performance. For very small datasets JSON is faster, but as soon as the dataset gets bigger binary serialization outperforms JSON by order of magnitude.</p>

<h2 id="finally">~ Finally</h2>

<p>If you have comments, questions etc., please comment on this post or <a href="mailto:niels.it.berglund@gmail.com">ping</a> me.</p>]]></content>
    <author>
      <name>Niels Berglund</name>

    </author>
  </entry>
  
</feed>

