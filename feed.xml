<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.3">Jekyll</generator><link href="http://nielsberglund.com/feed.xml" rel="self" type="application/atom+xml" /><link href="http://nielsberglund.com/" rel="alternate" type="text/html" /><updated>2018-08-12T12:08:10+02:00</updated><id>http://nielsberglund.com/</id><title type="html">Niels Berglund</title><subtitle>Technology musings about coding and data. Some topics: .NET, SQL Server, Data Science, R, Windows Azure and a lot more.</subtitle><entry><title type="html">Interesting Stuff - Week 32</title><link href="http://nielsberglund.com/2018/08/12/interesting-stuff-week-32/" rel="alternate" type="text/html" title="Interesting Stuff - Week 32" /><published>2018-08-12T12:02:02+02:00</published><updated>2018-08-12T12:02:02+02:00</updated><id>http://nielsberglund.com/2018/08/12/interesting-stuff---week-32</id><content type="html" xml:base="http://nielsberglund.com/2018/08/12/interesting-stuff-week-32/">&lt;p&gt;Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data science&lt;/li&gt;
  &lt;li&gt;data in general&lt;/li&gt;
  &lt;li&gt;distributed computing&lt;/li&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;transactions (both db as well as non db)&lt;/li&gt;
  &lt;li&gt;and other “stuff”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;distributed-computing&quot;&gt;Distributed Computing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://muratbuffalo.blogspot.com/2018/08/the-many-faces-of-consistency.html&quot;&gt;The many faces of consistency&lt;/a&gt;. A blog post by &lt;a href=&quot;https://twitter.com/muratdemirbas&quot;&gt;Murat&lt;/a&gt; where he dissects a white paper about consistency. The paper talks about two types of consistency: &lt;em&gt;state&lt;/em&gt; and &lt;em&gt;operation&lt;/em&gt;. Seeing that Murat now does sabbatical work at Microsoft (see below), he compares the two consistency types with what Cosmos DB provides. The post is a must read if you are the least interested in distributed computing and consistency.&lt;/li&gt;
  &lt;li&gt;[][].&lt;/li&gt;
  &lt;li&gt;[][].&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cloud--big-data&quot;&gt;Cloud / Big Data&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/globally-replicated-data-lakes-with-livedata-using-wandisco-on-azure/&quot;&gt;Globally replicated data lakes with LiveData using WANdisco on Azure&lt;/a&gt;. The post discusses how you can achieve globally replicated Azure Data Lakes. The replication can be both hybrid: on-prem to Azure as well as Azure to Azure.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://cloudblogs.microsoft.com/sqlserver/2018/08/09/cloud-data-and-ai-services-training-roundup-august-2018/&quot;&gt;Cloud data and AI services training roundup August 2018&lt;/a&gt;. This post lists some free data and AI training sessions.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://muratbuffalo.blogspot.com/2018/08/azure-cosmos-db.html&quot;&gt;Azure Cosmos DB&lt;/a&gt;. This post by &lt;a href=&quot;https://twitter.com/muratdemirbas&quot;&gt;Murat&lt;/a&gt; is about his first impressions of Azure Cosmos DB. Murat has taken a sabbatical and spends a year at Microsoft in the Cosmos DB team. I look forward to more posts by Murat about Cosmos DB, and other Azure related topics.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;misc&quot;&gt;Misc.&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://charlla.com/howto-docker-on-windows/&quot;&gt;HowTo - Docker on Windows&lt;/a&gt;. My mate and colleague, &lt;a href=&quot;https://twitter.com/charllamprecht&quot;&gt;Charl&lt;/a&gt; continues his blogging journey. This post is how to run Docker on Windows.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;Streaming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.lightbend.com/blog/streaming-data-dominates-over-2000-developers-say-only-batch-is-almost-extinct&quot;&gt;Streaming Data Dominates: Over 2000 Developers Say “Only Batch” Is Almost Extinct&lt;/a&gt;. A survey by &lt;a href=&quot;https://www.lightbend.com/&quot;&gt;Lightbend&lt;/a&gt;, (formerly known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Lightbend&quot;&gt;Typesafe&lt;/a&gt;), makes it clear that developers now moves more and more towards real-time processing as opposed to batch. That, my friends, is music to my ears!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://data-artisans.com/blog/apache-flink-1-6-0-whats-new-in-the-latest-apache-flink-release&quot;&gt;Apache Flink 1.6.0: What’s new in the latest Apache Flink release&lt;/a&gt;. What the title says; this is a post detailing some of the new features in the Flink 1.6.0 release.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/getting-started-apache-kafka-kubernetes/&quot;&gt;Getting Started with Apache Kafka and Kubernetes&lt;/a&gt;. A blog-post about the work done to enable Kafka to run on Kubernetes. The post points to a white paper: &lt;a href=&quot;https://www.confluent.io/resources/recommendations-for-deploying-apache-kafka-on-kubernetes&quot;&gt;Run Confluent Platform on Kubernetes Using Best Practices&lt;/a&gt; which is really good!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/kafka-streams-action&quot;&gt;Kafka Streams in Action&lt;/a&gt;. A post about the upcoming book: &lt;a href=&quot;https://www.manning.com/books/kafka-streams-in-action&quot;&gt;Kafka Streams in Action&lt;/a&gt;. Apart from announcing the book, the post also contains the foreword to the book. This book is a must if you are interested in Kafka Streams!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2018/08/09/building-a-real-time-attribution-pipeline-with-databricks-delta.html&quot;&gt;Building a Real-Time Attribution Pipeline with Databricks Delta&lt;/a&gt;. this blog post looks at how to use the Databricks DataFrame API to build Structured Streaming applications and use Databricks Delta to query the streams in near-real-time.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-science--ai&quot;&gt;Data Science / AI&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://dzone.com/articles/model-serving-stream-processing-vs-rpc-rest-with-j&quot;&gt;Model Serving: Stream Processing vs. RPC/REST With Java, gRPC, Apache Kafka, TensorFlow&lt;/a&gt;. A short and sweet blog-post comparing stream processing applications with a model serving infrastructure, like &lt;strong&gt;TensorFlow Serving&lt;/strong&gt;, for serving machine learning models.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.revolutionanalytics.com/2018/08/ieee-language-rankings-2018.html&quot;&gt;IEEE Language Rankings 2018&lt;/a&gt;. A post by &lt;a href=&quot;https://twitter.com/revodavid&quot;&gt;David&lt;/a&gt; about the latest IEEE Spectrum language rankings.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.datasciencecentral.com/profiles/blogs/scalable-iot-ml-platform-with-apache-kafka-deep-learning-mqtt&quot;&gt;Scalable IoT ML Platform with Apache Kafka + Deep Learning + MQTT&lt;/a&gt;. This post describes a hybrid machine learning infrastructure leveraging Apache Kafka as a scalable central nervous system. Very interesting!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-server-machine-learning-services&quot;&gt;SQL Server Machine Learning Services&lt;/h2&gt;

&lt;p&gt;I have started on the third post in the &lt;a href=&quot;/series/sql_server_ml_services_install_packages&quot;&gt;Install R Packages in SQL Server ML Services&lt;/a&gt; series. I hope to be able to publish it in a week or so.&lt;/p&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;That’s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="data science" /><category term="distributed computing" /><category term="SQL Server" /><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="kafka" /><category term="flink" /><category term="Azure Cosmos DB" /><category term="Databricks" /><summary type="html">Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me: data science data in general distributed computing SQL Server transactions (both db as well as non db) and other “stuff” This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.</summary></entry><entry><title type="html">Interesting Stuff - Week 31</title><link href="http://nielsberglund.com/2018/08/05/interesting-stuff-week-31/" rel="alternate" type="text/html" title="Interesting Stuff - Week 31" /><published>2018-08-05T08:01:44+02:00</published><updated>2018-08-05T08:01:44+02:00</updated><id>http://nielsberglund.com/2018/08/05/interesting-stuff---week-31</id><content type="html" xml:base="http://nielsberglund.com/2018/08/05/interesting-stuff-week-31/">&lt;p&gt;Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data science&lt;/li&gt;
  &lt;li&gt;data in general&lt;/li&gt;
  &lt;li&gt;distributed computing&lt;/li&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;transactions (both db as well as non db)&lt;/li&gt;
  &lt;li&gt;and other “stuff”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;net&quot;&gt;.NET&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/dotnet/2018/08/02/tiered-compilation-preview-in-net-core-2-1/&quot;&gt;Tiered Compilation Preview in .NET Core 2.1&lt;/a&gt;. A blog-post about a new feature in .NET Core 2.1: &lt;strong&gt;Tiered Compilation&lt;/strong&gt;. Tiered Compilation allows .NET to have multiple compilations for the same method that can be hot-swapped at runtime. This should improve compile times drastically!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;Streaming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://charlla.com/whatsthat-kafka/&quot;&gt;Apache Kafka - Whats That&lt;/a&gt;. This post about Kafka is by a colleague and a good friend of mine, &lt;a href=&quot;https://twitter.com/charllamprecht&quot;&gt;Charl Lamprecht&lt;/a&gt;. In the post, he takes us through a very succinct overview of Kafka. Charl is “Mr Kafka” at &lt;a href=&quot;/Derivco&quot;&gt;Derivco&lt;/a&gt;, and he knows his “stuff”. Please be sure to follow his &lt;a href=&quot;https://charlla.com/&quot;&gt;blog&lt;/a&gt; for more about Kafka (Charl, no pressure, hey?!).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/decoupling-systems-with-apache-kafka-schema-registry-and-avro/&quot;&gt;Decoupling Systems with Apache Kafka, Schema Registry and Avro&lt;/a&gt;. An excellent post on how to decouple the systems you integrate via Kafka by using the &lt;a href=&quot;https://www.confluent.io/confluent-schema-registry/&quot;&gt;Confluent Schema Registry&lt;/a&gt;. An added bonus in this post is that the code is .NET code!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://data-artisans.com/blog/a-practical-guide-to-broadcast-state-in-apache-flink&quot;&gt;A Practical Guide to Broadcast State in Apache Flink&lt;/a&gt;. This article discusses &lt;strong&gt;Broadcast State&lt;/strong&gt;, a new feature in Apache Flink 1.5. With Broadcast State you can evaluate dynamic patterns on event streams by combining and jointly process two streams of events in a specific way.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/introducing-confluent-platform-5-0/&quot;&gt;Introducing Confluent Platform 5.0&lt;/a&gt;. As the title says, this post introduces the latest version of Confluent Platform: 5.0. Lots and lots of new interesting features. Go and have a look!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/landing-page/microservices-online-talk-series/&quot;&gt;Apache Kafka for Microservices: A Confluent Online Talk Series&lt;/a&gt;. This post is a link to a three-part online talk series which introduces fundamental concepts, use cases and best practices for getting started with microservices and Kafka.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;big-data--cloud&quot;&gt;Big Data / Cloud&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2018/07/31/processing-petabytes-of-data-in-seconds-with-databricks-delta.html&quot;&gt;Processing Petabytes of Data in Seconds with Databricks Delta&lt;/a&gt;. In my roundups lately, I have covered Databricks Delta quite a bit and discussed how efficient it is processing lots and lots of data. This blog post takes a look under the hood and examines what makes Databricks Delta capable of sifting through petabytes of data within seconds. If you, like me, are interested in knowing how “stuff” works under the covers, then this post is a must-read!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://eng.uber.com/databook/&quot;&gt;Databook: Turning Big Data into Knowledge with Metadata at Uber&lt;/a&gt;. This post is about &lt;strong&gt;Databook&lt;/strong&gt;, Uber’s in-house platform that surfaces and manages metadata about the internal locations and owners of specific datasets, and allows Uber to turn data into knowledge.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-science--ai&quot;&gt;Data Science / AI&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.revolutionanalytics.com/2018/08/r-python-in-sql-server.html&quot;&gt;Video: How to run R and Python in SQL Server from a Jupyter notebook&lt;/a&gt;. A short post by &lt;a href=&quot;https://twitter.com/revodavid&quot;&gt;David&lt;/a&gt; linking to a video showing how to run Python and R from inside SQL Server.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/minibooks/emag-real-world-machine-learning&quot;&gt;The InfoQ eMag: Real-World Machine Learning: Case Studies, Techniques and Risks&lt;/a&gt;. An &lt;a href=&quot;https://www.infoq.com/&quot;&gt;InfoQ&lt;/a&gt; link to an eMag focusing on the current landscape of machine-learning technologies and real-world case studies of applied machine learning.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.technet.microsoft.com/machinelearning/2018/07/31/3-steps-to-build-your-first-intelligent-app-conference-buddy/&quot;&gt;3 Steps to Build Your First Intelligent App – Conference Buddy&lt;/a&gt;. A blog-post which takes us through how to build an application utilising AI.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-server-machine-learning-services&quot;&gt;SQL Server Machine Learning Services&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/08/04/sp-execute-external-script-and-sql-compute-context-iii/&quot;&gt;sp_execute_external_script and SQL Compute Context - III&lt;/a&gt;. I finally managed to finish and publish the third post in the &lt;a href=&quot;/series/spees_and_sql_compute_context&quot;&gt;sp_execute_external_script and SQL Server Compute Context&lt;/a&gt; series. In this post we use WinDbg, Process Monitor and WireShark to look in detail what happens in SQL Server when we use RxSqlServerData to pull data.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;That’s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="data science" /><category term="distributed computing" /><category term="SQL Server" /><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="kafka" /><category term="Databricks" /><category term="Databricks Delta" /><category term="AI" /><category term="flink" /><summary type="html">Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me: data science data in general distributed computing SQL Server transactions (both db as well as non db) and other “stuff” This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.</summary></entry><entry><title type="html">sp_execute_external_script and SQL Compute Context - III</title><link href="http://nielsberglund.com/2018/08/04/sp-execute-external-script-and-sql-compute-context-iii/" rel="alternate" type="text/html" title="sp_execute_external_script and SQL Compute Context - III" /><published>2018-08-04T16:05:46+02:00</published><updated>2018-08-04T16:05:46+02:00</updated><id>http://nielsberglund.com/2018/08/04/sp-execute-external-script-and-sql-compute-context---iii</id><content type="html" xml:base="http://nielsberglund.com/2018/08/04/sp-execute-external-script-and-sql-compute-context-iii/">&lt;p&gt;In the &lt;a href=&quot;/2018/03/21/microsoft-sql-server-r-services-sp-execute-external-script-iii/&quot;&gt;Microsoft SQL Server R Services - sp_execute_external_script - III&lt;/a&gt; post I wrote about &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_execute_external_script&lt;/code&gt; (SPEES) and the &lt;strong&gt;SQL Server Compute Context&lt;/strong&gt; (SQLCC). Afterwards I realised I had some things wrong, so I wrote a followup post: &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;sp_execute_external_script and SQL Compute Context - I&lt;/a&gt; where I tried to correct my mistakes from the &lt;a href=&quot;/2018/03/21/microsoft-sql-server-r-services-sp-execute-external-script-iii/&quot;&gt;initial post&lt;/a&gt;. That post led to &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;sp_execute_external_script and SQL Compute Context - II&lt;/a&gt; and now we have a mini-series.&lt;/p&gt;

&lt;p&gt;To see other posts (including this) in the series, go to &lt;a href=&quot;/series/spees_and_sql_compute_context&quot;&gt;&lt;strong&gt;sp_execute_external_script and SQL Server Compute Context&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the previous post in this series, we looked at how data is sent to the SqlSatellite from SQL Server when we are in the SQLCC. This post was meant to look at what goes on inside SQL Server when we execute in SQLCC, but I realised that it would make more sense if, before we look at the internal working when in SQLCC, I covered what happens when pulling data in the local context. So that is what this post is all about.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Before we dive into todays topic let us recap.&lt;/p&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt; we discussed what the SQLCC is and we said that as part of RevoScaleR, you can define where a workload executes. By default, it executes on your local machine, but you can also set it to execute in the context of somewhere else: Hadoop, Spark and also SQL Server. So, in essence, you can run some code on your development machine and have it execute in the environments mentioned above. To use the SQLCC in SQL Server we use &lt;code class=&quot;highlighter-rouge&quot;&gt;RxInSqlServer&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;rxSetComputeContext&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# set up the connection string&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlServerConnString&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Driver=SQL Server;
                        server=.; # localhost
                        database=testParallel;
                        uid=some_uid;pwd=some_pwd&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# set up the context&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlCtx&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RxInSqlServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connectionString&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlServerConnString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# set the compute context to be the sql context&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rxSetComputeContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 1:&lt;/strong&gt; &lt;em&gt;Set up SQL Server Compute Context&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The connection string we see in &lt;em&gt;Code Snippet 1&lt;/em&gt; indicates the where we execute, not necessarily where the data we work with lives. The &lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks&lt;/code&gt; argument defines the maximum number of tasks SQL Server can use. Something interesting when setting &lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks&lt;/code&gt; to be greater than 1 is that when we run the code, we run it hosted in a &lt;code class=&quot;highlighter-rouge&quot;&gt;mpiexec.exe&lt;/code&gt; process. If we run in SQLCC under &lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks = 1&lt;/code&gt; we do not see &lt;code class=&quot;highlighter-rouge&quot;&gt;mpiexec.exe&lt;/code&gt;, but we see another &lt;code class=&quot;highlighter-rouge&quot;&gt;bxlserver.exe&lt;/code&gt; process. We also said that when we run in SQLCC. &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_execute_external_script&lt;/code&gt; executes multiple times.&lt;/p&gt;

&lt;p&gt;The most interesting thing that came out of &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt; was the performance benefit of using SQLCC when loading large datasets. So in &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;sp_execute_external_script and SQL Compute Context - II&lt;/a&gt;, we tried to see where that performance benefit came from.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;Context - II&lt;/a&gt; we said we had three ways of getting data into an R script:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Push using &lt;code class=&quot;highlighter-rouge&quot;&gt;@input_data_1&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Pull using &lt;code class=&quot;highlighter-rouge&quot;&gt;RxSqlServerData&lt;/code&gt; in the local context.&lt;/li&gt;
  &lt;li&gt;Pull using &lt;code class=&quot;highlighter-rouge&quot;&gt;RxSqlServerData&lt;/code&gt; and the SQLCC.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We saw that to use SQLCC we need to pull the data; we could not push it. We also saw that for large datasets there was a significant performance difference between pulling in the local context and pulling using SQLCC. The interesting point was that pushing data and pulling using SQLCC had the same performance characteristics.&lt;/p&gt;

&lt;p&gt;When pulling the data (&lt;code class=&quot;highlighter-rouge&quot;&gt;RxSqlServerData&lt;/code&gt;), we use ODBC, and the protocol is TDS. However, when we use the SQLCC, the BXL protocol is also used and that gives us very efficient processing of data which is the reason we see good performance.&lt;/p&gt;

&lt;h2 id=&quot;housekeeping&quot;&gt;Housekeeping&lt;/h2&gt;

&lt;p&gt;Before we go any further let us look at the code and the tools we use today. This section is here for those who want to follow along in what we are doing in the post.&lt;/p&gt;

&lt;h4 id=&quot;helper-tools&quot;&gt;Helper Tools&lt;/h4&gt;

&lt;p&gt;To help us figure out the things we want, we use:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Process Monitor&lt;/em&gt; - to filter out TCP traffic.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;WinDbg&lt;/em&gt; - to see what happens inside SQL Server. If you need help with setting it up, we covered that in &lt;a href=&quot;/2017/03/18/microsoft-sql-server-r-services-internals-i/&quot;&gt;Microsoft SQL Server R Services - Internals I&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;WireShark&lt;/em&gt; - to “sniff” network packets. We covered setting up &lt;em&gt;WireShark&lt;/em&gt; in &lt;a href=&quot;/2017/08/29/microsoft-sql-server-r-services-internals-x/&quot;&gt;Internals - X&lt;/a&gt;. Please remember that if you run SSMS and SQL Server on the same machine, then you need the &lt;a href=&quot;https://nmap.org/npcap/&quot;&gt;&lt;strong&gt;Npcap&lt;/strong&gt;&lt;/a&gt; packet sniffer library instead of the default &lt;strong&gt;WinPcap&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;code&quot;&gt;Code&lt;/h4&gt;

&lt;p&gt;This is the database objects we use in this post:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;USE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NOCOUNT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TestParallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TestParallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;USE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TestParallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_Rand_50M&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_Rand_50M&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;RowID&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bigint&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;identity&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;rand2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;rand4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand5&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_Rand_50M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TOP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 2:&lt;/strong&gt; &lt;em&gt;Setup of Database, Table and Data&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We use more or less the same database and database object as in the &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;Context - II&lt;/a&gt; post:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A database: &lt;code class=&quot;highlighter-rouge&quot;&gt;TestParallel&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A table: &lt;code class=&quot;highlighter-rouge&quot;&gt;dbo.tb_Rand_50M&lt;/code&gt;. This table contains the data we want to analyse.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to creating the database and the table &lt;em&gt;Code Snippet 2&lt;/em&gt; also loads 50 million records into the &lt;code class=&quot;highlighter-rouge&quot;&gt;dbo.tb_Rand_50M&lt;/code&gt;. Be aware that when you run the code in &lt;em&gt;Code Snippet 2&lt;/em&gt; it may take some time to finish due to the loading of the data. Yes, I know - the data is entirely useless, but it is a lot of it, and it helps to illustrate what we want to do.&lt;/p&gt;

&lt;p&gt;Not only is the database and database objects similar to what we used in &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;Context - II&lt;/a&gt;, the code we use is also almost the same:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isCtx&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXEC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp_execute_external_script&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;language&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'R'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'
      # set up the connection string
      sqlServerConnString &amp;lt;- &quot;Driver=SQL Server;server=.;
                              database=testParallel;
                              uid=&amp;lt;username&amp;gt;;pwd=&amp;lt;userpwd&amp;gt;&quot;
      
      if(useContext == 1) {
        sqlCtx &amp;lt;- RxInSqlServer(connectionString = sqlServerConnString, 
                                numTasks = tasks)
        # set the compute context to be the sql context
        rxSetComputeContext(sqlCtx)
      }

      mydata &amp;lt;- RxSqlServerData(sqlQuery = &quot;SELECT y, rand1, rand2, 
                                            rand3, rand4, rand5 
                                            FROM dbo.tb_Rand_50M&quot;,
                                connectionString = sqlServerConnString);
                        
      myModel &amp;lt;- rxLinMod(y ~ rand1 + rand2 + rand3 + rand4 + rand5, 
                      data=mydata)'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'@tasks int, @useContext bit'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;useContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isCtx&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 3:&lt;/strong&gt; &lt;em&gt;Test Code&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As we see in &lt;em&gt;Code Snippet 3&lt;/em&gt; we parameterise the &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_execute_external_script&lt;/code&gt; call, and we have parameters for whether to use the SQLCC and also how many tasks to run when executing in the context. The default is to execute in the local context, and when we execute in SQLCC the default for the number of tasks is 1 (&lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks = 1&lt;/code&gt;).&lt;/p&gt;

&lt;h2 id=&quot;local-context-pull-vs-push&quot;&gt;Local Context Pull vs Push&lt;/h2&gt;

&lt;p&gt;Let us try and see what happens in SQL Server when we execute in the local context, and we pull data (&lt;code class=&quot;highlighter-rouge&quot;&gt;RxSqlServerData&lt;/code&gt;) compared to when we push data (&lt;code class=&quot;highlighter-rouge&quot;&gt;@input_data_1&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;First, let us try and understand when and how the &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement in &lt;code class=&quot;highlighter-rouge&quot;&gt;Code Snippet 3&lt;/code&gt; executes. To check this we use the same technique as we did in &lt;a href=&quot;/2017/11/11/microsoft-sql-server-r-services-internals-xiii/&quot;&gt;Microsoft SQL Server R Services - Internals XIII&lt;/a&gt;, we execute a &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement which causes a division by zero exception. We capture that exception in &lt;em&gt;WinDbg&lt;/em&gt; and we check the call stack.&lt;/p&gt;

&lt;p&gt;So, run &lt;em&gt;WinDbg&lt;/em&gt; as admin and enable an event-filter, so the debugger breaks at a &lt;code class=&quot;highlighter-rouge&quot;&gt;C++ EH&lt;/code&gt; exception. In the &lt;em&gt;Event Filters&lt;/em&gt; dialog you can set how that particular exception should be handled. We want it to be enabled, but not handled:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_r_services_windbg_eventfilters_enable.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; &lt;em&gt;Enable C++ EH Exception&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When the &lt;em&gt;Event Filter&lt;/em&gt; is enabled as in &lt;em&gt;Figure 1&lt;/em&gt; we:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Attach &lt;em&gt;WinDbg&lt;/em&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;sqlservr.exe&lt;/code&gt; process (please do not do this on a production machine - &lt;em&gt;#justsaying&lt;/em&gt;).&lt;/li&gt;
  &lt;li&gt;Set a breakpoint at &lt;code class=&quot;highlighter-rouge&quot;&gt;bp sqllang!SpExecuteExternalScript&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Change the &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement in &lt;em&gt;Code Snippet 3&lt;/em&gt; slightly, so it generates the division by zero exception mentioned above: &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT TOP(1) (1 / y - y), y, rand1, ...&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After changing the &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT&lt;/code&gt; statement, we execute the code. Continue through the breakpoint at &lt;code class=&quot;highlighter-rouge&quot;&gt;SpExecuteExternalScript&lt;/code&gt;, and when the execution breaks at the exception we check the call stack: &lt;code class=&quot;highlighter-rouge&quot;&gt;k&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;KERNELBASE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RaiseException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x68&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ErsqExecuteQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x5a2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtSelect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XretExecute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2f2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CMsqlExecContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExecuteStmts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x4c5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CMsqlExecContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FExecute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xaae&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSQLSource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xa2c&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xe52&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_commands_internal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x289&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_messages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x213&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqldk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SOS_Task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Param&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x231&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ntdll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RtlUserThreadStart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x21&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 4:&lt;/strong&gt; &lt;em&gt;Call Stack Local Context Pull&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The call stack we see in &lt;em&gt;Code Snippet 4&lt;/em&gt; is somewhat edited in that it shows only the important parts. Let us compare it with the call-stack we see when we push the data, (&lt;code class=&quot;highlighter-rouge&quot;&gt;@input_data_1&lt;/code&gt;), and receive a division by zero exception as we did in &lt;a href=&quot;/2017/11/11/microsoft-sql-server-r-services-internals-xiii/&quot;&gt;Microsoft SQL Server R Services - Internals XIII&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;KERNELBASE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RaiseException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x68&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ErsqExecuteQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x49f&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtSelect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XretExecute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2f2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CMsqlExecContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExecuteStmts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x4c5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CMsqlExecContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FExecute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xaae&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSQLSource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xa2c&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SpExecuteExternalScript&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x154b&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSpecProc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExecuteSpecial&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x31e&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXProc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x139&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSQLSource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xb5b&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CStmtExecProc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XretLocalExec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x2d3&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CStmtExecProc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XretExecExecute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x4a1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtExecProc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;XretExecute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x38&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CMsqlExecContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ExecuteStmts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x4c5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CMsqlExecContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FExecute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xaae&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSQLSource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xa2c&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0xe52&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_commands_internal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x289&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process_messages&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x213&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqldk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SOS_Task&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Param&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Execute&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x231&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ntdll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RtlUserThreadStart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mh&quot;&gt;0x21&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 5:&lt;/strong&gt; &lt;em&gt;Call Stack Local Context Push&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The call-stack in &lt;em&gt;Code Snippet 5&lt;/em&gt; is also edited and when we compare the two call-stacks, they look somewhat similar.  We see &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CXStmtQuery::ErsqExecuteQuery&lt;/code&gt; in both code snippets, and we know from &lt;a href=&quot;/2017/11/11/microsoft-sql-server-r-services-internals-xiii/&quot;&gt;Internals - XIII&lt;/a&gt; that &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt; handles execution of SQL statements and also sending data to the SQL Satellite. So that makes sense that we see it in &lt;em&gt;Code Snippet 4&lt;/em&gt;. However, what does not make sense is that we do not see &lt;code class=&quot;highlighter-rouge&quot;&gt;SpExecuteExternalScript&lt;/code&gt; in the &lt;em&gt;Code Snippet 4&lt;/em&gt; call stack (and no, I did not edit it out). What goes on here?&lt;/p&gt;

&lt;p&gt;Ok, let us refer back to what we saw in &lt;a href=&quot;/2017/10/31/microsoft-sql-server-r-services-internals-xii/&quot;&gt;Internals - XII&lt;/a&gt; and  &lt;a href=&quot;/2017/11/11/microsoft-sql-server-r-services-internals-xiii/&quot;&gt;Internals - XIII&lt;/a&gt;, how SQL Server sends various data packages to the SqlSatellite and then finally calls &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CSatelliteCargoContext::SendChunkEndMessage&lt;/code&gt;. So, add a breakpoint, in addition to the &lt;code class=&quot;highlighter-rouge&quot;&gt;SpExecuteExternalScript&lt;/code&gt; breakpoint, at &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CSatelliteCargoContext::SendChunkEndMessage&lt;/code&gt; and execute the code again. Oh, we see how we hit the &lt;code class=&quot;highlighter-rouge&quot;&gt;SpExecuteExternalScript&lt;/code&gt; breakpoint first, followed by &lt;code class=&quot;highlighter-rouge&quot;&gt;SendChunkEndMessage&lt;/code&gt;, and finally, we break at the division by zero exception. That is interesting, SQL Server sends the chunk end message and only after that, the query executes.&lt;/p&gt;

&lt;p&gt;So what with &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt;, what does that do? Let us see if we can find out:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Change the code not to cause a divide by zero exception: &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT TOP(1) y, rand1, ...&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Set a breakpoint at &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you execute the code you see something like so:&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;099&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SpExecuteExternalScript&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;091&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ErsqExecuteQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;091&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CSatelliteCargoContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SendChunkEndMessage&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;091&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Breakpoint&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ErsqExecuteQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mo&quot;&gt;07&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 6:&lt;/strong&gt; &lt;em&gt;Breakpoints Hit&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Code Snippet 6&lt;/em&gt; we see how we first hit the &lt;code class=&quot;highlighter-rouge&quot;&gt;SpExecuteExternalScript&lt;/code&gt; breakpoint, followed by &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt;, (which is expected), then we hit the &lt;code class=&quot;highlighter-rouge&quot;&gt;SendChunkEndMessage&lt;/code&gt; followed by a second &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt;. That is interesting; two &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt;, and we know from above that the query executes after the second &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt;. So the question is now how the data flows from SQL Server to the SqlSatellite. We know from [Internals - XIII&lt;a href=&quot;/2017/11/11/microsoft-sql-server-r-services-internals-xiii/&quot;&gt;si13&lt;/a&gt;, as we mentioned above, that when we push data, SQL Server makes these calls (among many others):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sqlmin!CQScanUdx::PushNextChildRow&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CUDXR_ExternalScript::PushRow&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CSatelliteCargoContext::SendPackets&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let us set a breakpoint at &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CSatelliteCargoContext::SendPackets&lt;/code&gt; and see what happens when we execute.&lt;/p&gt;

&lt;p&gt;THAT was interesting! We never hit &lt;code class=&quot;highlighter-rouge&quot;&gt;SendPackets&lt;/code&gt;. In the recap above we said that when we pull the data we use ODBC and the TDS protocol, and what we see here further ensures that is the case. So what does SQL Server call when it uses TDS to send data? To find out:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Disable the breakpoints at &lt;code class=&quot;highlighter-rouge&quot;&gt;SendChunkEndMessage&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;SendPackets&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Execute the query.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;When you reach &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt; the second time, do a &lt;code class=&quot;highlighter-rouge&quot;&gt;wt  -l4&lt;/code&gt; (watch and trace 4 levels deep) and continue. Look at the output from the &lt;code class=&quot;highlighter-rouge&quot;&gt;wt&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ErsqExecuteQuery&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;   
    &lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SetupQueryScanAndExpression&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CreateExecPlan&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sqldk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CMemProc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CpagesInUse&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQueryScan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StartupQuery&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;      
  &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQueryScan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRow&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQScanTopNew&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRow&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQScanTableScanNew&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRow&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQScanRowsetNew&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRowWithPrefetch&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQScanTableScanNew&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRow&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CValOdsRow&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SetDataX&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CShilohTds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SendRowImpl&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQScanTableScanNew&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRow&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQScanTopNew&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRow&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;sqlmin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CQueryScan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRow&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sqllang&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CXStmtQuery&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ErsqExecuteQuery&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 7:&lt;/strong&gt; &lt;em&gt;Output from wt&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The output shows a lot of data, so in &lt;em&gt;Code Snippet 7&lt;/em&gt; I have edited out all but the interesting parts. We see some routines that have to do with setting up and starting the query and retrieving result data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CXStmtQuery::SetupQueryScanAndExpression&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sqlmin!CQueryScan::StartupQuery&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;sqlmin!CQueryScan::GetRow&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That is interesting but what is more interesting is what we see after the &lt;code class=&quot;highlighter-rouge&quot;&gt;GetRow&lt;/code&gt; calls: &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CShilohTds::SendRowImpl&lt;/code&gt;. SQL Server calls &lt;code class=&quot;highlighter-rouge&quot;&gt;SendRowImpl&lt;/code&gt; when it pushes data to the network packet which it then sends to the caller. We can confirm this is the case by using &lt;em&gt;WinDbg&lt;/em&gt; and &lt;em&gt;Process Monitor&lt;/em&gt;. So, run &lt;em&gt;Process Monitor&lt;/em&gt; as admin and set an event filter which captures TCP Receive events for the &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; process.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; If you are not sure how to set an event filter in &lt;em&gt;Process Monitor&lt;/em&gt;, you can read about it in the &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;sp_execute_external_script and SQL Compute Context - II&lt;/a&gt; post.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now, disable all breakpoints in &lt;em&gt;WinDbg&lt;/em&gt; and execute the code in &lt;em&gt;Code Snippet 3&lt;/em&gt;, (with &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT TOP(1) ...&lt;/code&gt;) and watch the output from &lt;em&gt;Process Monitor&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_procmon_pull_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; &lt;em&gt;Process Monitor Output&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;What we see in &lt;em&gt;Figure 2&lt;/em&gt; is similar to what we saw in &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;Context - II&lt;/a&gt;, when we looked at the TCP packets SQL Server sends to the &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; process. The outlined row in &lt;em&gt;Figure 2&lt;/em&gt; is the packet with the result of the &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT&lt;/code&gt;. I know that because I tried with multiple &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP&lt;/code&gt; values and saw which row changed length between the &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP&lt;/code&gt; values. In &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;Context - II&lt;/a&gt; the corresponding row had a length of 1358 as we did a &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP(50)&lt;/code&gt;. You may wonder what the three highlighted parts if the figure is and we come back to that in a little bit.&lt;/p&gt;

&lt;p&gt;Now let us confirm that the outlined row is the row with the data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Re-enable (set) the breakpoint at &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!SpExecuteExternalScript&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Set a breakpoint at &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CShilohTds::SendRowImpl&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Execute the code and continue through until you break at &lt;code class=&quot;highlighter-rouge&quot;&gt;SendRowImpl&lt;/code&gt;. If you look at the &lt;em&gt;Process Monitor&lt;/em&gt; output, the last row you see is a row with a length of 405. That is the fourth row from the end as we see in &lt;em&gt;Figure 2&lt;/em&gt;. Now continue the execution, and you see how &lt;em&gt;Process Monitor&lt;/em&gt; outputs the three last rows, with a row with a length of 133 as the first one. We have “thus” proven that &lt;code class=&quot;highlighter-rouge&quot;&gt;SendRowImpl&lt;/code&gt; sends the data row to the data packet which then SQL Server sends to the caller. Oh, the reason I use &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP(1)&lt;/code&gt; is that there is one call to &lt;code class=&quot;highlighter-rouge&quot;&gt;SendRowImpl&lt;/code&gt; for each row, and I do not want to have to press F5 millions of times, or even 50 times.&lt;/p&gt;

&lt;h2 id=&quot;packets&quot;&gt;Packets&lt;/h2&gt;

&lt;p&gt;Now, what about the highlighted areas in &lt;em&gt;Figure 2&lt;/em&gt;, what are those? First of all, if you look at the length of the packets it seems like each area have packets of the same length: in the yellow area, we see packets with a length of 37, 1245, 67 and 405, which we also see in the green and blue area. In &lt;em&gt;Figure 2&lt;/em&gt; we also see that the highlighted areas originate from the same &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; process (process id 6572), but different ports: 6799, 6800 and 6801. OK, let us see if we can figure out what this is all about, and to try to get a clearer picture we also want to filter on what &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; sends to SQL Server. To see that, we add two new conditions to the existing &lt;em&gt;Process Monitor&lt;/em&gt; filter:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First condition - &lt;em&gt;Operation&lt;/em&gt; (first drop-down) &lt;em&gt;is&lt;/em&gt; (second dropdown): “TCP Send”.&lt;/li&gt;
  &lt;li&gt;Second condition - &lt;em&gt;Path&lt;/em&gt; &lt;em&gt;contains&lt;/em&gt;: the definition for the SQL Server port (1443). In my examples it is: &lt;code class=&quot;highlighter-rouge&quot;&gt;win10-dev:ms-sql-s&lt;/code&gt;. We set this filter condition, so we only see the ODBC communication.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Disable all breakpoints in &lt;em&gt;WinDbg&lt;/em&gt; and execute the code and watch the &lt;em&gt;Process Monitor&lt;/em&gt; output:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_procmon_pull_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; &lt;em&gt;Process Monitor Output - II&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The output we see in &lt;em&gt;Figure 3&lt;/em&gt; is quite similar to what we see in &lt;em&gt;Figure 2&lt;/em&gt;, apart from that we also see the packets the &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; process sends. We see the same structure of three separate sections of packets, and we have packets of the same length in the three sections. Once again we see the data packet being in the last section, once again with a length of 133 (the outlined row). What are these packets and why do we have three sections? Let us see if we can figure out what the packets do with the help of &lt;em&gt;WireShark&lt;/em&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Start &lt;em&gt;WireShark&lt;/em&gt; as admin.&lt;/li&gt;
  &lt;li&gt;On the opening screen double click the adapter for &lt;em&gt;Npcap&lt;/em&gt; (most likely named “Npcap Loopback Adapter”).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This starts capturing events immediately and to stop the capture you click &lt;strong&gt;Ctrl + E&lt;/strong&gt;. What we want to do now is to create a &lt;em&gt;WireShark&lt;/em&gt; display filter, so we only see network packets we are interested in. What we are interested in are packets for port 1433, and we set the filter in the text box just underneath the toolbox: &lt;code class=&quot;highlighter-rouge&quot;&gt;tcp.port==1433&lt;/code&gt;.  Finally, we click on the right arrow to the right the filter box to apply the filter (outlined in red below):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_filter.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4:&lt;/strong&gt; &lt;em&gt;WireShark Display Filter&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;TThe assumption at this stage is that the &lt;em&gt;WireShark&lt;/em&gt; capture is off. Start the capture (“Ctrl+E”) and then immediately execute the code. We stop the capture as soon as the code has finished executing:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_output_I.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; &lt;em&gt;WireShark Output&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Figure 5&lt;/em&gt; we see part of the output from &lt;em&gt;WireShark&lt;/em&gt;, and we may wonder why we see more packets than when we looked at the output from &lt;em&gt;Process Monitor&lt;/em&gt; and why the packet sixes are not the same. There are a couple of answers to that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Process Monitor&lt;/em&gt; only show packets that has a body (data part), but more messages are going over the wire (&lt;code class=&quot;highlighter-rouge&quot;&gt;ACK&lt;/code&gt; etc.), and &lt;em&gt;WireShark&lt;/em&gt; shows all of them.&lt;/li&gt;
  &lt;li&gt;The packet size question is related to the point above. &lt;em&gt;WireShark&lt;/em&gt; shows the bytes going over the wire and that includes headers and so forth, whereas &lt;em&gt;Process Monitor&lt;/em&gt; only shows the data size.&lt;/li&gt;
  &lt;li&gt;The &lt;em&gt;WireShark&lt;/em&gt; display filter is set on port 1433 (anything going in and out of SQL Server), whereas in &lt;em&gt;Process Monitor&lt;/em&gt; we filtered on traffic to and from the &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; process. The section in &lt;em&gt;Figure 5&lt;/em&gt; highlighted in blue is an example of this; this is the communication between &lt;em&gt;SQL Server Management Studio&lt;/em&gt; and SQL Server.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;yellow-section&quot;&gt;Yellow Section&lt;/h4&gt;

&lt;p&gt;Ok, so what does &lt;em&gt;WireShark&lt;/em&gt; tell us? In &lt;em&gt;Figure 5&lt;/em&gt; I have highlighted in yellow the part that corresponds to the highlighted yellow part in &lt;em&gt;Figure 3&lt;/em&gt;. For this exercise, we can ignore the packets whose &lt;em&gt;Protocol&lt;/em&gt; is TCP and concentrate on the ones which have TDS as a protocol. Just by looking at the info we see that the packets have to do with login and authentication: &lt;code class=&quot;highlighter-rouge&quot;&gt;TDS7 pre-login message&lt;/code&gt; followed by &lt;code class=&quot;highlighter-rouge&quot;&gt;Response&lt;/code&gt; followed by more pre-login messages, followed by &lt;code class=&quot;highlighter-rouge&quot;&gt;TLS Exchange&lt;/code&gt; and a &lt;code class=&quot;highlighter-rouge&quot;&gt;Response&lt;/code&gt;. I am not going into any details about these packets, but if you want all the “gory” details about TDS you find documentation here: &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/dd304523.aspx&quot;&gt;[MS-TDS]: Tabular Data Stream Protocol&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We now realise that the packets in the first section in &lt;em&gt;Figure 3&lt;/em&gt; has to do with authentication. Seeing that we see packets with the same length in the green and blue sections in &lt;em&gt;Figure 3&lt;/em&gt; we can safely assume those packets are also authentication packets, and a quick look at the packets in &lt;em&gt;WireShark&lt;/em&gt; confirms that. What about the packets that are different?&lt;/p&gt;

&lt;h4 id=&quot;green-section&quot;&gt;Green Section&lt;/h4&gt;

&lt;p&gt;In the green section there are packets with lengths of 386, 138, 23 and 22, and in the blue section, we see packet lengths of 330 and 133. Well, we do know what the 133 packet is - that is the packet with the data SQL Server sends to the &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; process. So, let us go back to the &lt;em&gt;WireShark&lt;/em&gt; output and see what we can find out:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_output_II.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 6:&lt;/strong&gt; &lt;em&gt;WireShark Output II&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We see in &lt;em&gt;Figure 6&lt;/em&gt; the last packets of the green section packets in &lt;em&gt;Figure 3&lt;/em&gt;. In &lt;em&gt;Figure 6&lt;/em&gt; the first packet corresponds to the 405 packet in the green section in &lt;em&gt;Figure 3&lt;/em&gt; which we know is a response package. To see what type of response packet it is, we click on the row in the “Packet List” pane in &lt;em&gt;WireShark&lt;/em&gt; and the “Packet Details” pane shows the details about the packet:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_env_change.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 7:&lt;/strong&gt; &lt;em&gt;WireShark Packet Details&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Aha, in &lt;em&gt;Figure 7&lt;/em&gt; we see that this packet is an &lt;code class=&quot;highlighter-rouge&quot;&gt;EnvChange&lt;/code&gt; packet (yellow highlight) which SQL Server use to notify the caller of an environment change (for example, database, language, and so on). In this case, it is a database context change from &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; (grey highlight) to &lt;code class=&quot;highlighter-rouge&quot;&gt;testParallel&lt;/code&gt; (blue highlight). So this packet appears in all three section sin &lt;em&gt;Figure 3&lt;/em&gt;. Now let us look at the 386, 138, 23, and 22 packets, which in &lt;em&gt;WireShark&lt;/em&gt; have lengths of 856, 360, 130 and 128 and are highlighted in &lt;em&gt;Figure 6&lt;/em&gt; with yellow, green, blue and purple respectively.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;WireShark Packet 856&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;When we click on the packet in the “Packet List” pane, the “Packet Details” looks like so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_prepare.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 8:&lt;/strong&gt; &lt;em&gt;WireShark Packet Details II&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The packet details we see in &lt;em&gt;Figure 8&lt;/em&gt; tells us that this is a “Remote Procedure Call” (which we also can see in &lt;em&gt;Figure 6&lt;/em&gt;), and the call is to &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_prepare&lt;/code&gt; (highlighted in blue). The procedure &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_prepare&lt;/code&gt; is generally used for performance reasons and prepares a parameterized Transact-SQL statement and returns a statement handle for execution. The “Packet Bytes” pane shows us a hex dump the statement:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_packet_bytes.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 9:&lt;/strong&gt; &lt;em&gt;WireShark Packet Bytes&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;WireShark Packet 360&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;The 360 packet (green) is a response packet, and when we look at the packet we see:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_col_metadata.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 10:&lt;/strong&gt; &lt;em&gt;WireShark Packet Details and Bytes&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We see in &lt;em&gt;Figure 10&lt;/em&gt; that the response to &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_prepare&lt;/code&gt; is column metadata for the query.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;WireShark Packet 130 and 128&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Finally, the last two packets in the green section is a call to &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_unprepare&lt;/code&gt; (packet 130) and an “End of message” response (packet 128) to that.&lt;/p&gt;

&lt;h4 id=&quot;blue-section&quot;&gt;Blue Section&lt;/h4&gt;

&lt;p&gt;On to the blue section in &lt;em&gt;Figure 3&lt;/em&gt;. We already said that there are only two packets that are different to the ones in the yellow and green sections:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_output_III.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 11:&lt;/strong&gt; &lt;em&gt;WireShark Output III&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The packet highlighted in yellow in &lt;em&gt;Figure 11&lt;/em&gt; is the packet with a length of 330 in &lt;em&gt;Figure 3&lt;/em&gt;, and the 350 packet (highlighted in green) is the &lt;em&gt;Figure 3&lt;/em&gt; 133 packet.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;WireShark Packet 744&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;The 744 packet looks like so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_sql_batch.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 12:&lt;/strong&gt; &lt;em&gt;WireShark Output III&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Figure 12&lt;/em&gt; we see how the packet is a SQL batch (yellow highlight), and it contains the actual query (green and blue highlights). So this is the query that SQL Server executes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;WireShark Packet 350&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;As we have mentioned a few times, the 350 packet contains the result of the query executed from the 744 packet, and the packet details and bytes look like so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_III_wireshark_query_result.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 13:&lt;/strong&gt; &lt;em&gt;WireShark Output Query Result&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;With a cursory glance at &lt;em&gt;Figure 13&lt;/em&gt; we may think there is no difference between what we see in &lt;em&gt;Figure 10&lt;/em&gt; - which shows the response to the &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_prepare&lt;/code&gt; call - and what is in &lt;em&gt;Figure 13&lt;/em&gt;. However, looking a bit closer we see that this packet contains the result of the query where we see highlighted in green and blue the two first column values, 2 and 6 respectively. The column values are not present in &lt;em&gt;Figure 10&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;sections&quot;&gt;Sections&lt;/h2&gt;

&lt;p&gt;By now we sort of understand what goes on when we pull the data in the local context. However, why do we have these different sections, and why do we see multiple authentications? I have no answer why we see multiple authentications; maybe I can get an answer from someone “in the know”. As for the multiple sections; I am not 100% clear about that - but it seems to have something to do with what RevoScaleR function that accesses the data, remember from &lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;Context - II&lt;/a&gt; how loading of the data happens not in the &lt;code class=&quot;highlighter-rouge&quot;&gt;RxSqlServerData&lt;/code&gt; call, but in the call which uses the data. So why I say that the sections are related to this is that if we, instead of doing a &lt;code class=&quot;highlighter-rouge&quot;&gt;rxLinMod&lt;/code&gt; call, did something like &lt;code class=&quot;highlighter-rouge&quot;&gt;ds &amp;lt;- &lt;/code&gt;rxImport(mydata)` then we only see the green and blue sections. Hopefully, I can get some more information about the sections as well which I can update this post with.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;So this post discusses the internal workings in SQL Server when we pull data in the local context. We talked about how SQL Server first sends the script data to the SQL Satellite through the usual &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CXStmtQuery::ErsqExecuteQuery&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;sqllang!CSatelliteCargoContext::SendChunkEndMessage&lt;/code&gt;. After &lt;code class=&quot;highlighter-rouge&quot;&gt;SendChunkEndMessage&lt;/code&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;ErsqExecuteQuery&lt;/code&gt; is called again and at that stage the statement query executes.&lt;/p&gt;

&lt;p&gt;The data transfer between the SqlSatellite (hosted by &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt;) and SQL Server happens through TDS packets, and we saw how authentication packages are sent multiple times, followed by &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_prepare&lt;/code&gt;. Finally, SQL Server executes the query and returns the result to the SqlSatellite.&lt;/p&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;If you have comments, questions etc., please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="R" /><category term="Python" /><category term="Launchpad" /><category term="Process Monitor" /><category term="SqlSatellite" /><category term="Process Monitor" /><category term="parallel" /><category term="SQL Server Compute Context" /><category term="sp_execute_external_script" /><category term="RxSqlServerData" /><category term="WinDbg" /><category term="WireShark" /><summary type="html">In the Microsoft SQL Server R Services - sp_execute_external_script - III post I wrote about sp_execute_external_script (SPEES) and the SQL Server Compute Context (SQLCC). Afterwards I realised I had some things wrong, so I wrote a followup post: sp_execute_external_script and SQL Compute Context - I where I tried to correct my mistakes from the initial post. That post led to sp_execute_external_script and SQL Compute Context - II and now we have a mini-series. To see other posts (including this) in the series, go to sp_execute_external_script and SQL Server Compute Context. In the previous post in this series, we looked at how data is sent to the SqlSatellite from SQL Server when we are in the SQLCC. This post was meant to look at what goes on inside SQL Server when we execute in SQLCC, but I realised that it would make more sense if, before we look at the internal working when in SQLCC, I covered what happens when pulling data in the local context. So that is what this post is all about.</summary></entry><entry><title type="html">Interesting Stuff - Week 30</title><link href="http://nielsberglund.com/2018/07/29/interesting-stuff-week-30/" rel="alternate" type="text/html" title="Interesting Stuff - Week 30" /><published>2018-07-29T19:11:58+02:00</published><updated>2018-07-29T19:11:58+02:00</updated><id>http://nielsberglund.com/2018/07/29/interesting-stuff---week-30</id><content type="html" xml:base="http://nielsberglund.com/2018/07/29/interesting-stuff-week-30/">&lt;p&gt;Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data science&lt;/li&gt;
  &lt;li&gt;data in general&lt;/li&gt;
  &lt;li&gt;distributed computing&lt;/li&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;transactions (both db as well as non db)&lt;/li&gt;
  &lt;li&gt;and other “stuff”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;distributed-computing&quot;&gt;Distributed Computing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/presentations/chaos-engineering-autonous-vehicles&quot;&gt;Properties of Chaos&lt;/a&gt;. An &lt;a href=&quot;https://www.infoq.com/&quot;&gt;InfoQ&lt;/a&gt; presentation about how and why chaos engineering is being applied to autonomous vehicle safety, and how to advance chaos engineering practices to explore beyond basic properties like system availability and extend into verifying system correctness.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cloud&quot;&gt;Cloud&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.pulumi.com/program-the-cloud-with-12-pulumi-pearls&quot;&gt;Program the Cloud with 12 Pulumi Pearls&lt;/a&gt;. In the &lt;a href=&quot;/2018/06/24/interesting-stuff-week-25/&quot;&gt;week 25&lt;/a&gt; roundup I wrote about &lt;a href=&quot;https://twitter.com/funcOfJoe&quot;&gt;Joe Duffy&lt;/a&gt; and his &lt;a href=&quot;http://pulumi.com/&quot;&gt;Pulumi&lt;/a&gt;. This blog post by &lt;a href=&quot;https://twitter.com/funcOfJoe&quot;&gt;Joe&lt;/a&gt; demonstrates some fun ways you can program the cloud using Pulumi. Very interesting!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-server&quot;&gt;SQL Server&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/sqlserverstorageengine/2018/07/23/pearl-abyss-massive-scale-using-azure-sql-database/&quot;&gt;Pearl Abyss: Massive Scale using Azure SQL Database&lt;/a&gt;. A blog post, showing off how you can achieve a massive scale of SQL Server by using Azure SQL Database. 7,500 cores, 46 instances 500,000 queries per second! Can I have two of those, please!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;Streaming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ExEWJVjj-RA&quot;&gt;Demo: Build a Streaming Application with KSQL&lt;/a&gt;. A YouTube video, illustrating how to build a streaming application using KSQL.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/ansible-playbooks-for-confluent-platform/&quot;&gt;Ansible Playbooks for Confluent Platform&lt;/a&gt;. This blog post covers how &lt;a href=&quot;https://www.confluent.io/&quot;&gt;Confluent&lt;/a&gt; wants to make it super easy to set up &lt;a href=&quot;https://www.confluent.io/product/confluent-platform/&quot;&gt;Confluent Platform&lt;/a&gt;. In this post, they introduce their first set of Ansible playbooks. It certainly seems easy!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-science--ai&quot;&gt;Data Science / AI&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.revolutionanalytics.com/2018/07/a-quick-tour-of-ai-services-in-azure.html&quot;&gt;A quick tour of AI services in Azure&lt;/a&gt;. A post by &lt;a href=&quot;https://twitter.com/revodavid&quot;&gt;David&lt;/a&gt; at &lt;a href=&quot;http://blog.revolutionanalytics.com&quot;&gt;Revolution Analytics&lt;/a&gt; talking about a video giving a quick overview of some of the services available in Azure to build AI-enabled applications. Watch the video if you are interested in AI and Azure.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/mlserver/2018/07/26/dockerizing-r-and-python-web-services/&quot;&gt;Dockerizing R and Python Web Services&lt;/a&gt;.  A post looking into how to build a Docker image containing &lt;strong&gt;Machine Learning Server 9.3&lt;/strong&gt;using Dockerfiles and how-to-perform Both R and Python operations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-server-machine-learning-services&quot;&gt;SQL Server Machine Learning Services&lt;/h2&gt;

&lt;p&gt;I am close to finish the third post in the &lt;a href=&quot;/series/spees_and_sql_compute_context&quot;&gt;sp_execute_external_script and SQL Server Compute Context&lt;/a&gt; series. I hope to have it out by the end of this upcoming week.&lt;/p&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;That’s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="data science" /><category term="distributed computing" /><category term="SQL Server" /><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="Azure SQL Database" /><category term="kafka" /><category term="Pulumi" /><category term="R" /><category term="Python" /><summary type="html">Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me: data science data in general distributed computing SQL Server transactions (both db as well as non db) and other “stuff” This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.</summary></entry><entry><title type="html">Interesting Stuff - Week 29</title><link href="http://nielsberglund.com/2018/07/22/interesting-stuff-week-29/" rel="alternate" type="text/html" title="Interesting Stuff - Week 29" /><published>2018-07-22T16:06:58+02:00</published><updated>2018-07-22T16:06:58+02:00</updated><id>http://nielsberglund.com/2018/07/22/interesting-stuff---week-29</id><content type="html" xml:base="http://nielsberglund.com/2018/07/22/interesting-stuff-week-29/">&lt;p&gt;Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data science&lt;/li&gt;
  &lt;li&gt;data in general&lt;/li&gt;
  &lt;li&gt;distributed computing&lt;/li&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;transactions (both db as well as non db)&lt;/li&gt;
  &lt;li&gt;and other “stuff”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending. Unfortunately there was not much that caught my eye this week, so this is a short post.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;distributed-computing&quot;&gt;Distributed Computing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/news/2018/07/zuul-push-messaging&quot;&gt;Scaling Push Messaging for Millions of Devices @Netflix - Susheel Aroskar at QCon NY&lt;/a&gt;. An &lt;a href=&quot;https://www.infoq.com/&quot;&gt;InfoQ&lt;/a&gt; article about Zuul Push, which is a high performance asynchronous service based on Apache Netty, a non-blocking I/O (NIO)-based network application framework. The technology handles more than 5.5 million connected clients at peak.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;Streaming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/apache-kafka-vs-enterprise-service-bus-esb-friends-enemies-or-frenemies/&quot;&gt;Apache Kafka vs. Enterprise Service Bus (ESB)—Friends, Enemies, or Frenemies?&lt;/a&gt;. A blog post showing why so many enterprises leverage the open source ecosystem of Apache Kafka for successful integration of different legacy and modern applications, and how this differs but also complements existing integration solutions like ESB or ETL tools.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2018/07/19/simplify-streaming-stock-data-analysis-using-databricks-delta.html&quot;&gt;Simplify Streaming Stock Data Analysis Using Databricks Delta&lt;/a&gt;. A post about how Databricks Delta helps solving many of the pain points of building a streaming system to analyze stock data in real-time.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-science&quot;&gt;Data Science&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.usejournal.com/python-vs-and-r-for-data-science-833b48ccc91d&quot;&gt;Python vs (and) R for Data Science&lt;/a&gt;. This post acts as a guide for those wishing to choose between Python and R Programming languages for Data Science.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-server-machine-learning-services&quot;&gt;SQL Server Machine Learning Services&lt;/h2&gt;

&lt;p&gt;I am &lt;del&gt;busy&lt;/del&gt; struggling with writing a couple of posts in the &lt;a href=&quot;/series/spees_and_sql_compute_context&quot;&gt;sp_execute_external_script and SQL Server Compute Context&lt;/a&gt; series, as well as the &lt;a href=&quot;/series/sql_server_ml_services_install_packages&quot;&gt;Install R Packages in SQL Server ML Services&lt;/a&gt; series. I do hope to have at least one out in a weeks time (or so).&lt;/p&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;That’s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="data science" /><category term="distributed computing" /><category term="SQL Server" /><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="kafka" /><category term="Databricks" /><category term="R" /><category term="Python" /><summary type="html">Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me: data science data in general distributed computing SQL Server transactions (both db as well as non db) and other “stuff” This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending. Unfortunately there was not much that caught my eye this week, so this is a short post.</summary></entry><entry><title type="html">Interesting Stuff - Week 28</title><link href="http://nielsberglund.com/2018/07/15/interesting-stuff-week-28/" rel="alternate" type="text/html" title="Interesting Stuff - Week 28" /><published>2018-07-15T06:15:28+02:00</published><updated>2018-07-15T06:15:28+02:00</updated><id>http://nielsberglund.com/2018/07/15/interesting-stuff---week-28</id><content type="html" xml:base="http://nielsberglund.com/2018/07/15/interesting-stuff-week-28/">&lt;p&gt;Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data science&lt;/li&gt;
  &lt;li&gt;data in general&lt;/li&gt;
  &lt;li&gt;distributed computing&lt;/li&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;transactions (both db as well as non db)&lt;/li&gt;
  &lt;li&gt;and other “stuff”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;net&quot;&gt;.NET&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/dotnet/2018/07/09/system-io-pipelines-high-performance-io-in-net/&quot;&gt;System.IO.Pipelines: High performance IO in .NET&lt;/a&gt;. A blog post which announces &lt;code class=&quot;highlighter-rouge&quot;&gt;System.IO.Pipelines&lt;/code&gt; which is a new library that is designed to make it easier to do high performance IO in .NET. I wish it had been around when we wrote socket code, way back when.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;distributed-computing&quot;&gt;Distributed Computing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/netflix-techblog/evolution-of-application-data-caching-from-ram-to-ssd-a33d6fa7a690&quot;&gt;Evolution of Application Data Caching : From RAM to SSD&lt;/a&gt;. A blog post about Netflix and how they move from purely RAM based caches to a hybrid between RAM and SSD. Very, very interesting!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/netflix-techblog/auto-scaling-production-services-on-titus-1f3cd49f5cd7&quot;&gt;Auto Scaling Production Services on Titus&lt;/a&gt;. This blog post, also from Netflix, discusses auto-scaling on their container management system &lt;a href=&quot;https://medium.com/netflix-techblog/titus-the-netflix-container-management-platform-is-now-open-source-f868c9fb5436&quot;&gt;Titus&lt;/a&gt;. It is interesting to read how the interaction happens between the AWS Auto Scaling engine and Titus.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;Streaming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/kafka-1-0-on-hdinsight-lights-up-real-time-analytics-scenarios/&quot;&gt;Kafka 1.0 on HDInsight lights up real-time analytics scenarios&lt;/a&gt;. This Microsoft blog post discusses the advantages that Kafka 1.0 on Azure HDInsight provides for data scientists and data analysts.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/07/10/install-confluent-platform-kafka-on-windows/&quot;&gt;Install Confluent Platform (Kafka) on Windows&lt;/a&gt;. This post from yours truly discusses we can install Kafka, in the guise of Confluent Platform, on Windows Subsystem for Linux (WSL). Useful if you, like me, is a Windows dude (or dudette) and you want to run Kafka locally on your development box.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-science&quot;&gt;Data Science&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.revolutionanalytics.com/2018/07/r-351-update-now-available-.html&quot;&gt;R 3.5.1 update now available&lt;/a&gt;. This post by &lt;a href=&quot;https://twitter.com/revodavid&quot;&gt;David&lt;/a&gt; talks about the new version of R: 3.5.1.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/dotnet/2018/07/09/announcing-ml-net-0-3/&quot;&gt;Announcing ML.NET 0.3&lt;/a&gt;. At Build 2018 Microsoft released ML.NET 0.1, a cross-platform, open source machine learning framework for .NET developers, and I posted about it in the &lt;a href=&quot;/2018/05/13/interesting-stuff-week-19/&quot;&gt;week 19 roundup&lt;/a&gt;. A month or two later they released ML.NET 0.2 which I covered in the roundup for &lt;a href=&quot;/2018/06/10/interesting-stuff-week-23/&quot;&gt;week 23&lt;/a&gt;. It is now time for ML.NET 0.3 with quite a few new enhancements. What interests me is to see what “cool” new features application developers dreams up with this.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/presentations/r-framework-ai-apps&quot;&gt;R for AI developers&lt;/a&gt;. So, &lt;a href=&quot;https://twitter.com/revodavid&quot;&gt;David&lt;/a&gt; is at it again. This time he did a presentation at QCon.ai where he makes a case for R as a platform for developing models for intelligent applications. The presentation is a must-see!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;That’s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="data science" /><category term="distributed computing" /><category term="SQL Server" /><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="kafka" /><category term="R" /><category term="ML.NET" /><summary type="html">Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me: data science data in general distributed computing SQL Server transactions (both db as well as non db) and other “stuff” This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.</summary></entry><entry><title type="html">Install Confluent Platform (Kafka) on Windows</title><link href="http://nielsberglund.com/2018/07/10/install-confluent-platform-kafka-on-windows/" rel="alternate" type="text/html" title="Install Confluent Platform (Kafka) on Windows" /><published>2018-07-10T18:43:48+02:00</published><updated>2018-07-10T18:43:48+02:00</updated><id>http://nielsberglund.com/2018/07/10/install-confluent-platform-kafka-on-windows</id><content type="html" xml:base="http://nielsberglund.com/2018/07/10/install-confluent-platform-kafka-on-windows/">&lt;p&gt;You who follows my blog and have read my weekly roundups you know that I am quite (that is an understatement) interested in Apache Kafka and I am curious to find out what “cool” things one can do with it. For that, I want to be able to test “stuff” quickly. When I test and try out new things, I usually do it on my development box which contains everything I need: &lt;strong&gt;SQL Server&lt;/strong&gt;, &lt;strong&gt;RabbitMQ&lt;/strong&gt;, &lt;strong&gt;RStudio&lt;/strong&gt;, &lt;strong&gt;Microsoft Machine Learning Server&lt;/strong&gt;, &lt;strong&gt;Visual Studio&lt;/strong&gt; and the list goes on.&lt;/p&gt;

&lt;p&gt;So seeing that I have most of my “tools of the trade” on my machine I obviously also would like to have Kafka on the box. Herein lies a problem, I am a Windows dude and Kafka, and Windows do not gel. Yes, some people are running Kafka on Windows, but it is a chore. OK, so what to do? Sure, I could potentially run Kafka on a virtual machine, or in a Docker image, but it is not as transparent as I would like it to be (yeah, I am lazy).&lt;/p&gt;

&lt;p&gt;Hmm, Microsoft did introduce the ability to run Linux binary executables (in ELF format) natively on Windows 10 in Windows 10 version 1607. The feature is called &lt;strong&gt;Windows Subsystem for Linux&lt;/strong&gt; (WSL), and since I am now running version 1803, maybe I should try and install Kafka in &lt;em&gt;WSL&lt;/em&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;pre-reqs&quot;&gt;Pre-reqs&lt;/h2&gt;

&lt;p&gt;To install and run the &lt;strong&gt;Confluent Platform&lt;/strong&gt;, (which contains Kafka), on &lt;em&gt;WSL&lt;/em&gt; there are some pre-reqs:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;WSL&lt;/em&gt; installed (fairly obvious).&lt;/li&gt;
  &lt;li&gt;Java 1.7 or later.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;windows-subsystem-for-linux&quot;&gt;Windows Subsystem for Linux&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;WSL&lt;/em&gt; is primarily aimed at developers, and it allows you to run Linux environments directly on Windows in a native format and without the overhead of a virtual machine. Let us retake a look at that statement: &lt;em&gt;run Linux environments directly on Windows in a native format&lt;/em&gt;. Yes native format, &lt;em&gt;WSL&lt;/em&gt; is not a UNIX-like environment like Cygwin, which wraps non-Windows functionality in Win32 system calls but it serves Linux programs as special, isolated minimal processes (&lt;em&gt;pico-processes&lt;/em&gt;) attached to kernel-mode &lt;em&gt;pico-providers&lt;/em&gt;. If you want to read all the “gory” details about &lt;em&gt;WSL&lt;/em&gt;: &lt;a href=&quot;https://blogs.msdn.microsoft.com/wsl/2016/04/22/windows-subsystem-for-linux-overview/&quot;&gt;Windows Subsystem for Linux Overview&lt;/a&gt; gives you an excellent introduction.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Installing &lt;em&gt;WSL&lt;/em&gt; is very easy; you first enable &lt;em&gt;WSL&lt;/em&gt; either via a Powershell command: &lt;code class=&quot;highlighter-rouge&quot;&gt;Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux&lt;/code&gt; or by switching it on from “Turn Windows features on or off” via “Control Panel&lt;/td&gt;
      &lt;td&gt;Programs and Features”:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_enable_wsl.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; &lt;em&gt;Enable WSL&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;You should restart the machine after enabling &lt;em&gt;WSL&lt;/em&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; So I have enabled &lt;em&gt;WSL&lt;/em&gt; a few times now, and some of the times I have not had to restart.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When &lt;em&gt;WSL&lt;/em&gt; is enabled you need to download and install a distro from the Windows Store. When &lt;em&gt;WSL&lt;/em&gt; first was introduced the only distro available was Ubuntu, since then quite a few have been added, and now the distro list looks like so:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ubuntu&lt;/li&gt;
  &lt;li&gt;OpenSUSE&lt;/li&gt;
  &lt;li&gt;SLES&lt;/li&gt;
  &lt;li&gt;Kali Linux&lt;/li&gt;
  &lt;li&gt;Debian GNU/Linux&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I started with &lt;em&gt;WSL&lt;/em&gt; when Ubuntu was the only distro available, so I have “stuck” with it, but I do not think the distros are that different. To continue, you choose a distro and let it install. Finally, you start the command shell for the distro from the Windows “Start” menu:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_start_distro.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; &lt;em&gt;Start the Distro&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When you start up the distro for the first time the setup finishes, and you are prompted to enter a root password. Now is probably a good time to run &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get update -y &amp;amp;&amp;amp; sudo apt-get upgrade -y&lt;/code&gt; where &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get update -y&lt;/code&gt; updates the list of all current program packages in the repositories to determine which packages are candidates for upgrading. The command &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo apt-get upgrade -y&lt;/code&gt; upgrades all current program packages in the operating system.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The above commands are for Ubuntu, so if you have another distro installed check the commands for that particular distro.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;java&quot;&gt;Java&lt;/h4&gt;

&lt;p&gt;When your distro is up and running, you can now install Java. When reading the documentation about &lt;a href=&quot;https://docs.confluent.io/current/installation/versions-interoperability.html#java&quot;&gt;supported Java versions&lt;/a&gt;, you see that &lt;strong&gt;Confluent Platform&lt;/strong&gt; 4.1 is the last version with support for Java 1.7. The &lt;strong&gt;Confluent Platform&lt;/strong&gt; version I use is the latest preview (version 5.x), so I install 1.8. Oh, and do not try with 1.9 -  it does not work.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://docs.confluent.io/current/installation/versions-interoperability.html#java&quot;&gt;docs&lt;/a&gt; mention the JDK, but I have found that the JRE works as well (since I am not writing any Java code) and I use the open source version of Java - OpenJDK. So to install you run the following from the bash shell:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;apt &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;openjdk-8-jre-headless 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 1:&lt;/strong&gt; &lt;em&gt;Install JRE&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As &lt;em&gt;WSL&lt;/em&gt; has no GUI, I choose to install the headless version of the JRE as we see in &lt;em&gt;Code Snippet 1&lt;/em&gt;. Finally, to check that it installed correctly I do &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt; java -version&lt;/code&gt; and the result is like so:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;openjdk version &lt;span class=&quot;s2&quot;&gt;&quot;1.8.0_171&quot;&lt;/span&gt;
OpenJDK Runtime Environment &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;build 1.8.0_171-8u171-b11-0ubuntu0.18.04.1-b11&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
OpenJDK 64-Bit Server VM &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;build 25.171-b11, mixed mode&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 2:&lt;/strong&gt; Java Version Output*.&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Code Snippet 2&lt;/em&gt; everything looks OK, so we can now go ahead with the main attraction.&lt;/p&gt;

&lt;h2 id=&quot;confluent-platform&quot;&gt;Confluent Platform&lt;/h2&gt;

&lt;p&gt;By now you may ask yourself what is this thing &lt;strong&gt;Confluent Platform&lt;/strong&gt;? Well, &lt;a href=&quot;https://confluent.io&quot;&gt;Confluent&lt;/a&gt; is a company founded by the guys (and girls) that originally built Kafka back at LinkedIn. The company is now focusing on building a streaming platform to help other companies get easy access to enterprise data as real-time streams.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Confluent Platform&lt;/strong&gt; improves Apache Kafka by expanding its integration capabilities, adding tools to optimise and manage Kafka clusters, and methods to ensure the streams are secure. &lt;strong&gt;Confluent Platform&lt;/strong&gt; makes Kafka easier to build and easier to operate. The &lt;strong&gt;Confluent Platform&lt;/strong&gt; comes in two flavours:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/product/confluent-open-source/&quot;&gt;Confluent Open Source&lt;/a&gt; is freely downloadable.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/product/confluent-enterprise/&quot;&gt;Confluent Enterprise&lt;/a&gt; is available on a subscription basis.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Back in April Confluent started releasing preview versions of the &lt;strong&gt;Confluent Platform&lt;/strong&gt; with the latest and the greatest and that is what I am using. At the time I write this the June preview has just been released, and that is what I am installing here.&lt;/p&gt;

&lt;h4 id=&quot;installation&quot;&gt;Installation&lt;/h4&gt;

&lt;p&gt;Before we can install, we need to download the install media which you do from &lt;a href=&quot;https://www.confluent.io/preview-release&quot;&gt;here&lt;/a&gt;. When clicking the “Download …” button, a form “pops up” where you choose your download format and enter your details. I usually choose &lt;code class=&quot;highlighter-rouge&quot;&gt;tar.gz&lt;/code&gt;, and that is what I base the following instructions on. Download the file to your PC and then in the bash shell:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Create a directory where to extract the files to.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cd&lt;/code&gt; to the download directory:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_mkdir.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; &lt;em&gt;Make Kafka Directory&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Figure 3&lt;/em&gt; we see how I create the &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/kafka&lt;/code&gt; directory, and how I &lt;code class=&quot;highlighter-rouge&quot;&gt;cd&lt;/code&gt; to the Windows directory where my downloaded files are. One of the cool things with &lt;em&gt;WSL&lt;/em&gt; is that the local Windows drives gets automatically mounted under the &lt;code class=&quot;highlighter-rouge&quot;&gt;/mnt&lt;/code&gt; folder. I can now extract the files:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The only reason I chose to create the &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka&lt;/code&gt; directory under &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt&lt;/code&gt; is that traditionally &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt&lt;/code&gt; is for third-party applications.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_untar.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4:&lt;/strong&gt; &lt;em&gt;Extract Files&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So I &lt;code class=&quot;highlighter-rouge&quot;&gt;tar&lt;/code&gt; the files, and we see in &lt;em&gt;Figure 4&lt;/em&gt; how the files are extracted. To extract the files takes a couple of minutes and when done we can drill down into the extracted directories and files:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_kafka_dirs_files.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; &lt;em&gt;Directory and File Structure&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Figure 5&lt;/em&gt; we see how directories and files ended up under a &lt;code class=&quot;highlighter-rouge&quot;&gt;confluent-version...&lt;/code&gt; directory (outlined in white) and when we &lt;code class=&quot;highlighter-rouge&quot;&gt;ls&lt;/code&gt; into that directory we see sub-directories (also outlined in white), and amongst them a &lt;code class=&quot;highlighter-rouge&quot;&gt;bin&lt;/code&gt; directory.&lt;/p&gt;

&lt;p&gt;When we drill down into the &lt;code class=&quot;highlighter-rouge&quot;&gt;bin&lt;/code&gt; directory and list the content we see a file named &lt;code class=&quot;highlighter-rouge&quot;&gt;confluent&lt;/code&gt;. This is an executable file, and we use this file to start and stop all the Confluent components. The &lt;code class=&quot;highlighter-rouge&quot;&gt;bin&lt;/code&gt; directory also contains executable files to start and stop individual components, such as &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka-server-start&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka-server-stop&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;zookeeper-server-start&lt;/code&gt;, and so forth.&lt;/p&gt;

&lt;p&gt;Right, enough of this - let us see if we can get the show on the road and spin up all components:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_start_kafka.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 6:&lt;/strong&gt; &lt;em&gt;Start Confluent&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To start all the Confluent components, we use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo ./confluent start (from the &lt;/code&gt;bin` directory) and in &lt;em&gt;Figure 6&lt;/em&gt; we see how the various components startup, awesome!&lt;/p&gt;

&lt;h4 id=&quot;control-center&quot;&gt;Control Center&lt;/h4&gt;

&lt;p&gt;Part of the &lt;strong&gt;Confluent Platform&lt;/strong&gt; installation (Enterprise version) is the &lt;em&gt;Control Center&lt;/em&gt;. The &lt;em&gt;Control Center&lt;/em&gt; (I copied the text from the &lt;a href=&quot;https://www.confluent.io/confluent-control-center/&quot;&gt;Control Center&lt;/a&gt; site) “gives the administrator monitoring and management capabilities, delivering automated, curated dashboards so that Kafka experts can easily understand what is happening without tweaking dashboards”. So let us see if we can connect with the &lt;em&gt;Control Center&lt;/em&gt;. If we connect from the same machine as we installed &lt;strong&gt;Confluent Platform&lt;/strong&gt; on, the address is &lt;code class=&quot;highlighter-rouge&quot;&gt;http://localhost:9021&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_control_center.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 7:&lt;/strong&gt; &lt;em&gt;Confluent Control Center&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Cool, &lt;em&gt;Control Center&lt;/em&gt; seems to be up and running, let us now use it to create a &lt;em&gt;Topic&lt;/em&gt; so we can do a final test.&lt;/p&gt;

&lt;h4 id=&quot;topics&quot;&gt;Topics&lt;/h4&gt;

&lt;p&gt;When you send messages to a Kafka broker, you typically send it to a “Topic”, which is like a collection point in the broker for “like-minded” messages. If you are a database dude like me, you can see it as a table in a database where you keep records of the same type.&lt;/p&gt;

&lt;p&gt;Typically you create multiple topics in you Kafka cluster to cater for multiple message types, and &lt;em&gt;Control Center&lt;/em&gt; can help you with that. In &lt;em&gt;Figure 7&lt;/em&gt; we see at the bottom left corner, outlined in red, “Topics”. Click on that, and you see existing default topics. Click on, in the far right corner, the “Create topic” button and you see something like so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_create_topic.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 8:&lt;/strong&gt; &lt;em&gt;Topics&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In the topic name box enter “testing” and then click “Create with defaults” and we are back seeing the existing topics as well as the newly created “testing” topic:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_topic_created.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 9:&lt;/strong&gt; &lt;em&gt;New Topic&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When we have a topic, we can now see whether we can publish and consume messages.&lt;/p&gt;

&lt;h2 id=&quot;test-send--receive&quot;&gt;Test Send &amp;amp; Receive&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Confluent Platform&lt;/strong&gt; is now up and running, and you can now start doing “cool” stuff. However, to make sure everything works let us use the built-in command line clients to send and receive some test messages.&lt;/p&gt;

&lt;p&gt;What we do is that in the open bash shell we &lt;code class=&quot;highlighter-rouge&quot;&gt;cd&lt;/code&gt; to the &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/kafka/confluent-xxx/bin/&lt;/code&gt; directory. We use the command line producer &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka-console-producer&lt;/code&gt; to send messages:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; ./kafka-console-producer &lt;span class=&quot;nt&quot;&gt;--broker-list&lt;/span&gt; localhost:9092 &lt;span class=&quot;nt&quot;&gt;--topic&lt;/span&gt; testing
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;Hello World!
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;Life Is Awesome!
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;We Have Installed Kafka on Windows!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 3:&lt;/strong&gt; &lt;em&gt;Publishing Messages&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We see in &lt;em&gt;Code Snippet 3&lt;/em&gt; how we target the local broker on port 9092, and the topic we send to is the “testing” topic we created above. After hitting enter, we create one message after each other (hit enter in between).&lt;/p&gt;

&lt;p&gt;To consume messages we open a second bash shell and &lt;code class=&quot;highlighter-rouge&quot;&gt;cd&lt;/code&gt; into the &lt;code class=&quot;highlighter-rouge&quot;&gt;/bin&lt;/code&gt; directory as before, and to receive messages we use the &lt;code class=&quot;highlighter-rouge&quot;&gt;kafka-console-consumer&lt;/code&gt; command line client:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo&lt;/span&gt; ./kafka-console-consumer &lt;span class=&quot;nt&quot;&gt;--bootstrap-server&lt;/span&gt; localhost:9092 &lt;span class=&quot;nt&quot;&gt;--topic&lt;/span&gt; testing &lt;span class=&quot;nt&quot;&gt;--from-beginning&lt;/span&gt;
Hello World!
Life Is Awesome!
We Have Installed Kafka on Windows!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 4:&lt;/strong&gt; &lt;em&gt;Consume Messages&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When running the consumer we see in &lt;em&gt;Code Snippet 4&lt;/em&gt; how we receive the messages we just sent. If we were to go back to the publisher and create some more messages we immediately see them in the consumer bash shell. It works! So now we can start creating streaming applications using proper &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Clients&quot;&gt;clients&lt;/a&gt;. If you write .NET applications, I suggest you look at the &lt;a href=&quot;https://github.com/confluentinc/confluent-kafka-dotnet&quot;&gt;Confluent client&lt;/a&gt; which is very feature rich.&lt;/p&gt;

&lt;p&gt;When we are done with the &lt;strong&gt;Confluent Platform&lt;/strong&gt;, we stop it from the &lt;code class=&quot;highlighter-rouge&quot;&gt;/bin&lt;/code&gt; directory:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_stop_kafka.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 10:&lt;/strong&gt; &lt;em&gt;Stopping Kafka&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We stop Kafka by calling &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo ./confluent stop&lt;/code&gt; and then as &lt;em&gt;Figure 10&lt;/em&gt; shows, all components shut down in an orderly fashion.&lt;/p&gt;

&lt;p&gt;We have installed &lt;strong&gt;Confluent Platform&lt;/strong&gt; on &lt;em&gt;WSL&lt;/em&gt;, started it, published and consumed some messages and stopped it. All is good! Or is it?&lt;/p&gt;

&lt;h2 id=&quot;issue&quot;&gt;ISSUE&lt;/h2&gt;

&lt;p&gt;So what happens when you try to start the platform again:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/inst_kafka_wsl_start_error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 11:&lt;/strong&gt; &lt;em&gt;Error at Start Up&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;That is not good! We get an error when we try to start the platform after a shutdown. What we see here is a “half” known issue which is most prevalent on Windows machines, and it has to do with Kafka trying to clean up old log files. If you drill down in the Kafka log files you see an error looking something like this: &lt;code class=&quot;highlighter-rouge&quot;&gt;FATAL Shutdown broker because all log dirs in &amp;lt;path_to_logs&amp;gt; have failed (kafka.log.LogManager)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;At the moment I do not have a solution for it other than that before each startup run something like so: &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo rm -fr /tmp/confl*&lt;/code&gt; which removes all Kafka related log directories. This is obviously not a solution in a production environment or a “proper” test/dev environment but for us just wanting to do some “quick and dirty” testing on &lt;em&gt;WSL&lt;/em&gt; it is sufficient.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;In this post, we discussed a little bit what &lt;em&gt;WSL&lt;/em&gt; is and how we can install &lt;strong&gt;Confluent Platform&lt;/strong&gt; on &lt;em&gt;WSL&lt;/em&gt;. We looked at we can test the installation by creating a topic and then publish and consume messages using the command line publish and consume clients.&lt;/p&gt;

&lt;p&gt;Having &lt;strong&gt;Confluent Platform&lt;/strong&gt; installed we can now use a &lt;a href=&quot;https://cwiki.apache.org/confluence/display/KAFKA/Clients&quot;&gt;client of choice&lt;/a&gt; to start doing “cool” stuff. Keep an eye on my blog for future &lt;strong&gt;Confluent Platform&lt;/strong&gt; and Kafka posts!&lt;/p&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;If you have comments, questions etc., please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="streaming" /><category term="kafka" /><category term="Control Center" /><category term="WSL" /><summary type="html">You who follows my blog and have read my weekly roundups you know that I am quite (that is an understatement) interested in Apache Kafka and I am curious to find out what “cool” things one can do with it. For that, I want to be able to test “stuff” quickly. When I test and try out new things, I usually do it on my development box which contains everything I need: SQL Server, RabbitMQ, RStudio, Microsoft Machine Learning Server, Visual Studio and the list goes on. So seeing that I have most of my “tools of the trade” on my machine I obviously also would like to have Kafka on the box. Herein lies a problem, I am a Windows dude and Kafka, and Windows do not gel. Yes, some people are running Kafka on Windows, but it is a chore. OK, so what to do? Sure, I could potentially run Kafka on a virtual machine, or in a Docker image, but it is not as transparent as I would like it to be (yeah, I am lazy). Hmm, Microsoft did introduce the ability to run Linux binary executables (in ELF format) natively on Windows 10 in Windows 10 version 1607. The feature is called Windows Subsystem for Linux (WSL), and since I am now running version 1803, maybe I should try and install Kafka in WSL.</summary></entry><entry><title type="html">Interesting Stuff - Week 27</title><link href="http://nielsberglund.com/2018/07/08/interesting-stuff-week-27/" rel="alternate" type="text/html" title="Interesting Stuff - Week 27" /><published>2018-07-08T12:11:28+02:00</published><updated>2018-07-08T12:11:28+02:00</updated><id>http://nielsberglund.com/2018/07/08/interesting-stuff---week-27</id><content type="html" xml:base="http://nielsberglund.com/2018/07/08/interesting-stuff-week-27/">&lt;p&gt;Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data science&lt;/li&gt;
  &lt;li&gt;data in general&lt;/li&gt;
  &lt;li&gt;distributed computing&lt;/li&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;transactions (both db as well as non db)&lt;/li&gt;
  &lt;li&gt;and other “stuff”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;cloud&quot;&gt;Cloud&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/ip-filtering-for-event-hubs-and-service-bus/&quot;&gt;IP filtering for Event Hubs and Service Bus&lt;/a&gt;. A frequently asked for feature in Azure Event Hubs is the ability to restrict access to the Event Hubs to certain well-known sites, alternatively rejecting traffic from specific IP addresses. The Azure team has now announced a public preview of IP filtering.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2018/07/02/build-a-mobile-gaming-events-data-pipeline-with-databricks-delta.html&quot;&gt;Build a Mobile Gaming Events Data Pipeline with Databricks Delta&lt;/a&gt;. This blog post shows how to build a data pipeline in AWS using the &lt;a href=&quot;https://databricks.com/product/unified-analytics-platform&quot;&gt;Databricks Unified Analytics Platform&lt;/a&gt;. Even though they in the blog post use AWS it should be possible to do the same on Azure since Databricks is now available there as well.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;net&quot;&gt;.NET&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://mattwarren.org/2018/07/05/.NET-JIT-and-CLR-Joined-at-the-Hip/&quot;&gt;.NET JIT and CLR - Joined at the Hip&lt;/a&gt;. This is another excellent blog post by &lt;a href=&quot;https://twitter.com/matthewwarren&quot;&gt;Matthew&lt;/a&gt;, looking at how the .NET JIT compiler works together with CLR.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;distributed-computing&quot;&gt;Distributed Computing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/news/2018/07/boner-events-first-microservices&quot;&gt;QCon NY: Jonas Bonér on Designing Events-First Microservices&lt;/a&gt;. An &lt;a href=&quot;https://www.infoq.com/&quot;&gt;InfoQ&lt;/a&gt; article summarising a QCon talk by &lt;a href=&quot;http://jonasboner.com/&quot;&gt;Jonas Bonér&lt;/a&gt; of &lt;a href=&quot;https://akka.io/&quot;&gt;Akka&lt;/a&gt; fame. The main point Jonas makes is that events-first domain-driven design (DDD) and event streaming are critical in a microservices based architecture. Oh and by th way, if you are interested in event-driven systems and microservices go and download Jonas mini-book &lt;a href=&quot;https://www.lightbend.com/blog/reactive-microsystems-the-evolution-of-microservices-at-scale-free-oreilly-report-by-jonas-boner&quot;&gt;Reactive Microsystems - The Evolution Of Microservices At Scale&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;Streaming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/june-preview-release-confluent-plaform/&quot;&gt;June Preview Release: Packing Confluent Platform with the Features You Requested!&lt;/a&gt;. A blog post by the Confluent team announcing the latest preview release of Confluent Platform. This release packs quite a few new features, and I am especially interested in the KSQL support for nested data as well as the ability to join two streams together.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.infoq.com/news/2018/07/event-sourcing-kafka-streams&quot;&gt;Experiences from Building an Event-Sourced System with Kafka Streams&lt;/a&gt;. An article from &lt;a href=&quot;https://www.infoq.com/&quot;&gt;InfoQ&lt;/a&gt; about how engineers at &lt;a href=&quot;https://www.wix.com/&quot;&gt;Wix&lt;/a&gt; built an event sourced system using &lt;a href=&quot;https://kafka.apache.org/documentation/streams/&quot;&gt;Kafka Streams&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-science&quot;&gt;Data Science&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/a-feature-selection-tool-for-machine-learning-in-python-b64dd23710f0&quot;&gt;A Feature Selection Tool for Machine Learning in Python&lt;/a&gt;. This blog post is about a Python tool that helps with feature selection in a dataset.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420&quot;&gt;A Complete Machine Learning Project Walk-Through in Python: Part One&lt;/a&gt;. First post in a series walking through a complete Python machine learning solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-server-machine-learning-services&quot;&gt;SQL Server Machine Learning Services&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/&quot;&gt;sp_execute_external_script and SQL Compute Context - II&lt;/a&gt;. I finally published part 2 of the &lt;a href=&quot;/series/spees_and_sql_compute_context&quot;&gt;sp_execute_external_script and SQL Server Compute Context&lt;/a&gt; series. In the post, I tried to figure out why the performance is so much better when executing in a &lt;strong&gt;SQL Server Compute Context&lt;/strong&gt; in &lt;strong&gt;SQL Server ML Services&lt;/strong&gt; compared to executing in the local context (it is SQL Server after all). Even though I “sort of” figured it out, a few questions arose and hopefully I can answer those questions in a future post.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;That’s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="data science" /><category term="distributed computing" /><category term="SQL Server" /><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="kafka" /><category term="Databricks" /><category term="Confluent Platform" /><category term="Azure Event Hubs" /><category term="Python" /><summary type="html">Throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me: data science data in general distributed computing SQL Server transactions (both db as well as non db) and other “stuff” This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.</summary></entry><entry><title type="html">sp_execute_external_script and SQL Compute Context - II</title><link href="http://nielsberglund.com/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/" rel="alternate" type="text/html" title="sp_execute_external_script and SQL Compute Context - II" /><published>2018-07-07T10:54:21+02:00</published><updated>2018-07-07T10:54:21+02:00</updated><id>http://nielsberglund.com/2018/07/07/sp-execute-external-script-and-sql-compute-context-II</id><content type="html" xml:base="http://nielsberglund.com/2018/07/07/sp-execute-external-script-and-sql-compute-context-II/">&lt;p&gt;I wrote the post &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;sp_execute_external_script and SQL Compute Context - I&lt;/a&gt; about how the &lt;strong&gt;SQL Server Compute Context&lt;/strong&gt; (SQLCC) works with &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_execute_external_script&lt;/code&gt; (SPEES), as I wanted to correct some mistakes I did in the &lt;a href=&quot;/2018/03/21/microsoft-sql-server-r-services-sp-execute-external-script-iii/&quot;&gt;Microsoft SQL Server R Services - sp_execute_external_script - III&lt;/a&gt; post. I initially thought one post would be enough, but quite soon I realised I was too optimistic, and at least one more post would be needed, if not more. So this is the first followup post about SPEES and SQLCC.&lt;/p&gt;

&lt;p&gt;To see other posts (including this) in the series, go to &lt;a href=&quot;/series/spees_and_sql_compute_context&quot;&gt;&lt;strong&gt;sp_execute_external_script and SQL Server Compute Context&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One of the reasons for me realising that one post is not enough is that while I wrote and executed code for the first &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;post&lt;/a&gt;, I noticed some fairly significant performance differences using SQLCC compared to not using SQLCC (SQLCC performed better :)). So that is part of what we look at in this post.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;recap&quot;&gt;Recap&lt;/h2&gt;

&lt;p&gt;In quite a few posts about &lt;strong&gt;SQL Server Machine Learning Services&lt;/strong&gt; we have discussed how, as part of the functionality in RevoScaleR, you can define where a workload executes. By default, it executes on your local machine, but you can also set it to execute in the context of somewhere else: Hadoop, Spark and also SQL Server. So, in essence, you can run some code on your development machine and have it execute in the environments mentioned above.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt; post we saw that even when we executed from inside SQL Server, the compute context was the local context: &lt;code class=&quot;highlighter-rouge&quot;&gt;RxLocalSeq&lt;/code&gt;. If we want to use the SQLCC we used &lt;code class=&quot;highlighter-rouge&quot;&gt;RxInSqlServer&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;rxSetComputeContext&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-r highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# set up the connection string&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlServerConnString&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Driver=SQL Server;
                        server=.; # localhost
                        database=testParallel;
                        uid=some_uid;pwd=some_pwd&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# set up the context&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlCtx&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RxInSqlServer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connectionString&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlServerConnString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; 
                        &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;# set the compute context to be the sql context&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rxSetComputeContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlCtx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;    
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 1:&lt;/strong&gt; &lt;em&gt;Set up SQL Server Compute Context&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;To setup the context we see in &lt;em&gt;Code Snippet 1&lt;/em&gt; how we use a connection string pointing to the SQL Server where we want to execute the code. In this case, it is the instance we are on.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The connection string is for where we want to execute, not necessarily where the data we use resides.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We also see in &lt;em&gt;Figure 1&lt;/em&gt; how &lt;code class=&quot;highlighter-rouge&quot;&gt;RxInSqlServer&lt;/code&gt; has the &lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks&lt;/code&gt; parameter for you to set the number of tasks (processes) to run for each computation. The parameter defines the maximum number of tasks SQL Server can use. SQL Server can, however, decide to start fewer processes. Finally in &lt;em&gt;Figure 1&lt;/em&gt; we call &lt;code class=&quot;highlighter-rouge&quot;&gt;rxSetComputeContext&lt;/code&gt; which ensures that any code with functions that support SQLCC, executes under the compute context.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt; post, we saw how when we execute inside of SQL Server via SPEES we by default run in the local context and only by setting the context as in &lt;em&gt;Code Snippet 1&lt;/em&gt; we can execute in SQLCC.&lt;/p&gt;

&lt;p&gt;An interesting observation when we set the &lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks&lt;/code&gt; parameter to a value greater than 1 is that when we run the code, we run it hosted in an &lt;code class=&quot;highlighter-rouge&quot;&gt;mpiexec.exe&lt;/code&gt; process:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_comp_mpi.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1:&lt;/strong&gt; &lt;em&gt;Parallel Execution in Compute Context&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Figure 1&lt;/em&gt; we now see not only the “usual” RTerm and &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; processes but also a new hosting process, outlined in red, &lt;code class=&quot;highlighter-rouge&quot;&gt;mpiexec.exe&lt;/code&gt;. Underneath the &lt;code class=&quot;highlighter-rouge&quot;&gt;mpiexec.exe&lt;/code&gt; process we see the &lt;code class=&quot;highlighter-rouge&quot;&gt;smpd.exe&lt;/code&gt; process (outlined in green) and then four RTerm processes with &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; processes which handle the workload. So, &lt;code class=&quot;highlighter-rouge&quot;&gt;mpiexec.exe&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;smpd.exe&lt;/code&gt; are parts of &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/bb524831%28v=vs.85%29.aspx?f=255&amp;amp;MSPPError=-2147217396&quot;&gt;&lt;strong&gt;Microsoft MPI&lt;/strong&gt;&lt;/a&gt; which is an implementation of MPI which is a communication protocol for programming parallel computers.&lt;/p&gt;

&lt;p&gt;All this is somewhat interesting, but the most interesting thing (at least for me) is the performance difference we saw when executing the same code in the local context compared to the SQLCC. When executing with &lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks&lt;/code&gt; set to 1 (as it would be under the local context) code that ran in ~40 seconds in the local context took ~30 seconds to run in SQLCC! Once again, we did not run it with multiple tasks in SQLCC, so just be running in SQLCC we received a performance gain of about 30%!&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; The performance gain is of course not always 30%, it depends on data volumes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So, as I said at the beginning of this post - let us try and figure out why the performance is better using SQLCC.&lt;/p&gt;

&lt;h2 id=&quot;housekeeping&quot;&gt;Housekeeping&lt;/h2&gt;

&lt;p&gt;Before we “dive” into today’s topics let us look at the code and the tools we use today. This section is here for those who want to follow along in what we are doing in the post.&lt;/p&gt;

&lt;h4 id=&quot;helper-tools&quot;&gt;Helper Tools&lt;/h4&gt;

&lt;p&gt;To help us figure out the things we want, we use &lt;em&gt;Process Monitor&lt;/em&gt; to filter TCP traffic.&lt;/p&gt;

&lt;h4 id=&quot;code&quot;&gt;Code&lt;/h4&gt;

&lt;p&gt;This is the database objects we use in this post:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;USE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;SET&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;NOCOUNT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TestParallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DATABASE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TestParallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;USE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TestParallel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;DROP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;EXISTS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_Rand_50M&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TABLE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_Rand_50M&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;RowID&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bigint&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;identity&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIMARY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;KEY&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;rand2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;rand4&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand5&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tb_Rand_50M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rand5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TOP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50000000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;CAST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ABS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CHECKSUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NEWID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;INT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o2&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o3&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;CROSS&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 2:&lt;/strong&gt; &lt;em&gt;Setup of Database, Table and Data&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We use more or less the same database and database object as in the &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt; post:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A database: &lt;code class=&quot;highlighter-rouge&quot;&gt;TestParallel&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A table: &lt;code class=&quot;highlighter-rouge&quot;&gt;dbo.tb_Rand_50M&lt;/code&gt;. This table contains the data we want to analyse.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In addition to creating the database and the table &lt;em&gt;Code Snippet 2&lt;/em&gt; also loads 50 million records into the &lt;code class=&quot;highlighter-rouge&quot;&gt;dbo.tb_Rand_50M&lt;/code&gt;. Be aware that when you run the code in &lt;em&gt;Code Snippet 2&lt;/em&gt; it may take some time to finish due to the loading of the data. Yes, I know - the data is entirely useless, but it is a lot of it, and it helps to illustrate what we want to do.&lt;/p&gt;

&lt;p&gt;The code we use is almost like what we used in &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isCtx&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SYSUTCDATETIME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXEC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp_execute_external_script&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;language&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'R'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'
      # set up the connection string
      sqlServerConnString &amp;lt;- &quot;Driver=SQL Server;server=.;
                              database=testParallel;
                              uid=&amp;lt;username&amp;gt;;pwd=&amp;lt;userpwd&amp;gt;&quot;
      
      if(useContext == 1) {
        sqlCtx &amp;lt;- RxInSqlServer(connectionString = sqlServerConnString, 
                                numTasks = tasks)
        # set the compute context to be the sql context
        rxSetComputeContext(sqlCtx)
      }

      mydata &amp;lt;- RxSqlServerData(sqlQuery = &quot;SELECT y, rand1, rand2, 
                                            rand3, rand4, rand5 
                                            FROM dbo.tb_Rand_50M&quot;,
                                connectionString = sqlServerConnString);
                        
      myModel &amp;lt;- rxLinMod(y ~ rand1 + rand2 + rand3 + rand4 + rand5, 
                      data=mydata)

      OutputDataSet &amp;lt;- data.frame(nRows=myModel$nValidObs);'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'@tasks int, @useContext bit'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;useContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isCtx&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RESULT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SETS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NumberRows&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SYSUTCDATETIME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 3:&lt;/strong&gt; &lt;em&gt;Test Code&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As we see in &lt;em&gt;Code Snippet 3&lt;/em&gt; we parameterize the &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_execute_external_script&lt;/code&gt; call, and we have parameters for whether to use the SQLCC and also how many tasks to run when executing in the context. The default is to execute in the local context, and when executing in SQLCC &lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks&lt;/code&gt; is 1.&lt;/p&gt;

&lt;h2 id=&quot;performance-differences&quot;&gt;Performance Differences&lt;/h2&gt;

&lt;p&gt;To start with, let us repeat - more or less - what we did in &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt; and compare execution times when running in the local context (&lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 0&lt;/code&gt;) and when in SQLCC  (&lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 1&lt;/code&gt;). In both cases, we execute with the default number of tasks (&lt;code class=&quot;highlighter-rouge&quot;&gt;numTasks = 1&lt;/code&gt;).&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; Do a couple of executions in the local context as well as in the SQLCC to ensure you get representative numbers for both.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;When I run the code on my SQL Server instance I get the following results:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Local context: ~40 seconds&lt;/li&gt;
  &lt;li&gt;SQLCC: ~24 seconds&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, the same workload shows an approximately 40% performance improvement when running in the SQLCC compared to the local context and this is in line with what we saw in &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt;. Why is this, we do the same things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We load data&lt;/li&gt;
  &lt;li&gt;We apply the &lt;code class=&quot;highlighter-rouge&quot;&gt;rxLinMod&lt;/code&gt; function.&lt;/li&gt;
  &lt;li&gt;We run with the same number of tasks (single threaded).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A question I have now is at what stage in the script, the script receives the 50 million rows? Comment out in the code, (&lt;em&gt;Code Snippet 3&lt;/em&gt;), the &lt;code class=&quot;highlighter-rouge&quot;&gt;myModel&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;OutputDataSet&lt;/code&gt; lines of code. When you now execute in the local context, you see the execution time is ~ 1 second. When you do the same in the SQLCC the time is about the same. It seems like the actual loading of the data happens not in the &lt;code class=&quot;highlighter-rouge&quot;&gt;RxSqlServerData&lt;/code&gt; call, but in the call - in this case - to &lt;code class=&quot;highlighter-rouge&quot;&gt;rxLinMod&lt;/code&gt;. Hmm, I wonder what happens if we instead of pulling the data, pushed the data to the &lt;code class=&quot;highlighter-rouge&quot;&gt;rxLinMod&lt;/code&gt; call by using &lt;code class=&quot;highlighter-rouge&quot;&gt;@input_data_1&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isCtx&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;DECLARE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SYSUTCDATETIME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;EXEC&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sp_execute_external_script&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;language&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'R'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'
      # set up the connection string
      sqlServerConnString &amp;lt;- &quot;Driver=SQL Server;server=.;
                              database=testParallel;
                              uid=&amp;lt;username&amp;gt;;pwd=&amp;lt;userpwd&amp;gt;&quot;
      
      if(useContext == 1) {
        sqlCtx &amp;lt;- RxInSqlServer(connectionString = sqlServerConnString, 
                                numTasks = tasks)
        # set the compute context to be the sql context
        rxSetComputeContext(sqlCtx)
      }
                      
      myModel &amp;lt;- rxLinMod(y ~ rand1 + rand2 + rand3 + rand4 + rand5, 
                         data=InputDataSet)

      OutputDataSet &amp;lt;- data.frame(nRows=myModel$nValidObs);'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_data_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'SELECT y, rand1, rand2, rand3, rand4, rand5 
                        FROM dbo.tb_Rand_50M'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'@tasks int, @useContext bit'&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tasks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numTasks&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;useContext&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isCtx&lt;/span&gt;    
&lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;RESULT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SETS&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NumberRows&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;NULL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DATEDIFF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SYSUTCDATETIME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;GO&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Code Snippet 4:&lt;/strong&gt; &lt;em&gt;Pushing the Data&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Code Snippet 4&lt;/em&gt; we see how we push the data through the &lt;code class=&quot;highlighter-rouge&quot;&gt;@input_data_1&lt;/code&gt; straight to the &lt;code class=&quot;highlighter-rouge&quot;&gt;rxLinMod&lt;/code&gt; call via &lt;code class=&quot;highlighter-rouge&quot;&gt;InputDataSet&lt;/code&gt;. The code here does not look any different than from most of the other code used in many of my blog posts. When I execute it in the local context (&lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx bit = 0)&lt;/code&gt; however:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_II_push_error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2:&lt;/strong&gt; &lt;em&gt;Error Pushing Data&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Oh, it looks like we try to push too much data as we see, highlighted in &lt;em&gt;Figure 2&lt;/em&gt;, a memory issue. Ok, but this is what the SQLCC is all about - efficiently handling large volumes of data, so let us execute the same code but in the SQLCC (&lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx bit = 1&lt;/code&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compII_input_data_ctx_error.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3:&lt;/strong&gt; &lt;em&gt;Push and SQLCC Error&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Ouch, it seems that to use SQLCC we need to pull data through &lt;code class=&quot;highlighter-rouge&quot;&gt;RxSqlServerData&lt;/code&gt;. Never mind, I still want to push large volumes of data, so I change &lt;code class=&quot;highlighter-rouge&quot;&gt;@input_data_1&lt;/code&gt; to do a &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT TOP(30000000) ...&lt;/code&gt; (30 million) from the table instead. When I push my 30 million rows in the local context the execution time is around  17 seconds. What are the timings if we execute the code in &lt;em&gt;Code Snippet 3&lt;/em&gt; with a &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP (30000000)&lt;/code&gt; both in the local context as well as SQLCC and compare execution times:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Local context push (&lt;em&gt;Code Snippet 4&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 0&lt;/code&gt;): ~ 17 seconds.&lt;/li&gt;
  &lt;li&gt;Local context pull (&lt;em&gt;Code Snippet 3&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 0&lt;/code&gt;): ~ 23 seconds.&lt;/li&gt;
  &lt;li&gt;SQLCC pull (&lt;em&gt;Code Snippet 3&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 1&lt;/code&gt;): ~ 15 seconds.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That was interesting, the timings between pushing the data in the local context are almost the same as pulling the data in SQLCC, and the push in the local context is much faster than the pull in the same context. What gives?&lt;/p&gt;

&lt;p&gt;All we have done so far points to that the difference in performance comes from loading the data, so the question is what the difference is when loading it from the local context compared to the SQLCC, and is SQLCC always faster. Let us start with the last question first; is SQLCC always faster?&lt;/p&gt;

&lt;p&gt;To test this change the &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP&lt;/code&gt; clause to &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP(50)&lt;/code&gt; and execute &lt;em&gt;Code Snippet 4&lt;/em&gt; (pushing the data) and &lt;em&gt;Code Snippet 3&lt;/em&gt; pulling the data both in the local context as well as SQLCC and take note of the timings:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Local context push (&lt;em&gt;Code Snippet 4&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 0&lt;/code&gt;): ~ 200 ms.&lt;/li&gt;
  &lt;li&gt;Local context pull (&lt;em&gt;Code Snippet 3&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 0&lt;/code&gt;): ~ 260 ms.&lt;/li&gt;
  &lt;li&gt;SQLCC pull (&lt;em&gt;Code Snippet 3&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 1&lt;/code&gt;): ~ 1.6 seconds.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That was quite a difference and now, all of a sudden, SQLCC is slowest! Why is that? Let us use &lt;em&gt;Process Monitor&lt;/em&gt; to try to figure out why this is the case. However, before we do that let us recap a little bit about the internal workings when we execute &lt;em&gt;SPEES&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&quot;internals&quot;&gt;Internals&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The host for an external engine is &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;When we execute &lt;em&gt;SPEES&lt;/em&gt; the SqlSatellite (loaded by the BxlServer) connects to SQL Server over a TCP connection.&lt;/li&gt;
  &lt;li&gt;Data is sent over the TCP connection from and to SQL Server.&lt;/li&gt;
  &lt;li&gt;The data sent among other things authentication data, script data (the actual external script) as well as the dataset.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The figure below illustrates connections and so forth in a “simple” case where we push data to the SqlSatellite in the local context:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_r_services_ext_scriptIII_single_process.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4:&lt;/strong&gt; &lt;em&gt;Process Flow&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In &lt;em&gt;Figure 4&lt;/em&gt; we see what happens when we execute &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_execute_external_script&lt;/code&gt; and the numbers in the figure stands for:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We call &lt;code class=&quot;highlighter-rouge&quot;&gt;sp_execute_external_script&lt;/code&gt; and SQL Server calls into the launchpad service.&lt;/li&gt;
  &lt;li&gt;The launchpad service creates RTerm processes which in turn creates BxlServer processes. One process becomes the executing process.&lt;/li&gt;
  &lt;li&gt;A TCP connection from the SqlSatellite in the executing process gets established.&lt;/li&gt;
  &lt;li&gt;SQL server sends input data to the SqlSatellite.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; does the processing.&lt;/li&gt;
  &lt;li&gt;SQL Server receives data back from the SqlSatellite.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The &lt;a href=&quot;/series/sql_server_2k16_r_services&quot;&gt;SQL Server R Services&lt;/a&gt; series covered in “excruciating” details what data SQL Server sends to the BxlServer. If you want to read up on it I suggest &lt;strong&gt;Internals&lt;/strong&gt; &lt;a href=&quot;/2017/08/29/microsoft-sql-server-r-services-internals-x/&quot;&gt;X&lt;/a&gt;, &lt;a href=&quot;/2017/10/20/microsoft-sql-server-r-services-internals-xi/&quot;&gt;XI&lt;/a&gt;, &lt;a href=&quot;/2017/10/31/microsoft-sql-server-r-services-internals-xii/&quot;&gt;XII&lt;/a&gt;, &lt;a href=&quot;/2017/11/25/microsoft-sql-server-r-services-internals-xiv/&quot;&gt;XIV&lt;/a&gt; and &lt;a href=&quot;/2017/12/02/microsoft-sql-server-r-services-internals-xv/&quot;&gt;XV&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;investigation-using-performance-monitor&quot;&gt;Investigation using Performance Monitor&lt;/h4&gt;

&lt;p&gt;To see what happens when we execute our three scenarios (local push, local pull, SQLCC pull) we set up some &lt;em&gt;Process Monitor&lt;/em&gt; event filters to capture TCP traffic from SQL Server to the SqlSatellite, where &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; is “hosting” the SqlSatellite. The filters we set up are for “Process Name” and “Operation”. We want the process to be &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; and the operation “TCP Receive”.&lt;/p&gt;

&lt;p&gt;So, run &lt;em&gt;Process Monitor&lt;/em&gt; as admin. To set the filter; under the &lt;em&gt;Filter&lt;/em&gt; menu click the Filter menu item, and you see the “Process Monitor Filter” dialog. To create the filter we enter the conditions we want to match:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;em&gt;Process Name&lt;/em&gt; (from the first drop down) should be  &lt;em&gt;is&lt;/em&gt; (from the second drop-down): &lt;code class=&quot;highlighter-rouge&quot;&gt;bxlserver.exe&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Operation&lt;/em&gt; (first drop-down) &lt;em&gt;is&lt;/em&gt; (second dropdown): “TCP Receive”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You add and include the conditions included and added, and at this stage, the filter dialog looks something like so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_II_procmon_filter.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 5:&lt;/strong&gt; &lt;em&gt;Filters BxlServer&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;What the filter says is that any “TCP Receive” events for &lt;code class=&quot;highlighter-rouge&quot;&gt;bxlserver.exe&lt;/code&gt; should be monitored and displayed. When you have clicked “OK” out of the dialog box, we are ready to test this by executing the code for local context push (&lt;em&gt;Code Snippet 4&lt;/em&gt;), local context pull (&lt;em&gt;Code Snippet 3&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 0&lt;/code&gt;) and SQLCC pull (&lt;em&gt;Code Snippet 3&lt;/em&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;@isCtx = 1&lt;/code&gt;). When executing we look at the &lt;em&gt;Process Monitor&lt;/em&gt; output, and the output for the local push is like so:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_II_procmon_push2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 6:&lt;/strong&gt; &lt;em&gt;TCP Receive Local Context Push&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We see in &lt;em&gt;Figure 6&lt;/em&gt; that the output looks quite “tidy” and by looking at the &lt;code class=&quot;highlighter-rouge&quot;&gt;Path&lt;/code&gt; column see a connection between SQL Server and the SqlSatellite on port 13273 (&lt;code class=&quot;highlighter-rouge&quot;&gt;win10-dev:13273&lt;/code&gt;). Furthermore, we see:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There is one &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; process with a process id of 17260.&lt;/li&gt;
  &lt;li&gt;The data the BxlServer receives are what we covered in the &lt;a href=&quot;/series/sql_server_2k16_r_services&quot;&gt;SQL Server R Services&lt;/a&gt; series.&lt;/li&gt;
  &lt;li&gt;The 50 rows we pushed to the BxlServer is the outlined (in blue) row with a length of 1392.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ok, so onto the local context pull:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_II_procmon_pull_loc_ctx2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 7:&lt;/strong&gt; &lt;em&gt;TCP Receive Local Context Pull&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Looking at &lt;em&gt;Figure 7&lt;/em&gt; we see that there is quite a difference between when we push the data to the SqlSatellite. First, we see (highlighted in red) the usual connection between SQL Server and the SqlSatellite and how SQL Server sends data (authentication and script) to the SqlSatellite. Then, however, we see data going from SQL Server from a “strange” port: &lt;code class=&quot;highlighter-rouge&quot;&gt;ms-sql-s&lt;/code&gt;. That “name” is &lt;a href=&quot;http://www.t1shopper.com/tools/port-number/1433/&quot;&gt;&lt;em&gt;IANA&lt;/em&gt;’s&lt;/a&gt; (Internet Assigned Numbers Authority) definition for SQL Server’s port 1433. As we know, port 1433 is the default port SQL uses for connections and retrieval of data. So it looks like that when we use pull, we connect to SQL Server over the default port and retrieves the data that way. Thinking about it, it makes sense as the connection is an ODBC connection. All the packets received by the SqlSatellite are the regular ODBC data packets. The actual 50 rows of data are in the packet outlined in blue with a length of 1358. As we use ODBC the protocol used to send the data is TDS.&lt;/p&gt;

&lt;p&gt;Oh, TDS - that is probably a reason why the local pull is slower than local push, as the local push uses the &lt;a href=&quot;/2017/11/25/microsoft-sql-server-r-services-internals-xiv/&quot;&gt;&lt;strong&gt;Binary eXchange Language&lt;/strong&gt;&lt;/a&gt; protocol (BXL) which is very efficient for transferring data. Another reason why the local pull is slower than the local push, even with small datasets, is that for local pull there is much more happening, as we see in &lt;em&gt;Figure 7&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Right, then what about SQLCC pull:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/posts/sql_ml_services_compctx_II_procmon_pull_sqlcc2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 8:&lt;/strong&gt; &lt;em&gt;TCP Receive SQLCC Pull&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Oh my, that is a lot! As in &lt;em&gt;Figure 7&lt;/em&gt; the sections outlined in red is the connection between SQL Server and the SqlSatellite, and in blue it is the “ODBC” connection. What is noticeable is that there are multiple sections interleaved, as well that there are multiple &lt;code class=&quot;highlighter-rouge&quot;&gt;BxlServer.exe&lt;/code&gt; processes involved (process id’s 2108, 13360 and 15340). Well, maybe that is not such a surprise as we spoke about it in &lt;a href=&quot;/2018/05/20/sp-execute-external-script-and-sql-compute-context/&quot;&gt;Context - I&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;What is more interesting though is that we receive the dataset both via the ODBC connection outlined in blue (length 1358), as well as the way we do it in the local push context, outlined in purple (length 1392)! That means that SQL sends data using both the TDS protocol as well as the BXL protocol.&lt;/p&gt;

&lt;p&gt;By seeing the amount of “stuff” happening in &lt;em&gt;Figure 8&lt;/em&gt; we do realise why the SQLCC pull is not as efficient as local push and local pull (1.6 s vs ~200 ms). Having seen all this, we probably ask ourselves why the SQLCC pull was a lot faster (~15 s) than local pull (~23 s) for a big dataset and somewhat faster than the local push (~17 s)?&lt;/p&gt;

&lt;p&gt;Let us execute the code in &lt;em&gt;Code Snippet 3&lt;/em&gt; and &lt;em&gt;Code Snippet 4&lt;/em&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;TOP (30000000)&lt;/code&gt; (30 million) and see what &lt;em&gt;Process Monitor&lt;/em&gt; tells us. For local push, we see many packets with a size of 65495 which is the maximum size for BXL data package. When we execute the local pull, we see many TDS packets with a size of 4096 followed by many packages with sizes ranging from ~70,000 up to 2.5 Mb. For me, it looks like the local pull is nowhere as efficient as the local push. Finally, the SQLCC pull shows the same behaviour as local pull with many TDS 4096 packages. However, after the TDS packages follows BXL packages where most have the maximum size of 65495.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt; I do not know why, in the case of SQLCC, data is first loaded via TDS and then BXL. I also do not know why in the case of local pull we see multiple 4096 packages followed by packages with an arbitrary big size. I see if I can find answers to this, in which case update this post (or write a new).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This post set out to try to find out why SQLCC performs better than local context. I believe we found why this is the reason but not necessarily how it works.&lt;/p&gt;

&lt;p&gt;What did we see:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Local push performs really, really well up until it does not :). It performs well up until you hit memory restrictions.&lt;/li&gt;
  &lt;li&gt;Some of the memory issues can be alleviated by using the &lt;code class=&quot;highlighter-rouge&quot;&gt;@r_rowsPerRead&lt;/code&gt; parameter (not shown in this post).&lt;/li&gt;
  &lt;li&gt;When pushing the data (&lt;code class=&quot;highlighter-rouge&quot;&gt;@input_data_1&lt;/code&gt;) we cannot use SQLCC.&lt;/li&gt;
  &lt;li&gt;Both local pull as well as SQLCC uses ODBC connections, and the data transfer protocol is TDS.&lt;/li&gt;
  &lt;li&gt;When using SQLCC the BXL protocol is also used.&lt;/li&gt;
  &lt;li&gt;By the use of BXL we get very efficient processing of data, and that is the reasons we see good performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After writing this post, I have quite a few questions which I will try to answer in a future post.&lt;/p&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;If you have comments, questions etc., please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="R" /><category term="Python" /><category term="Launchpad" /><category term="Process Monitor" /><category term="SqlSatellite" /><category term="Process Monitor" /><category term="parallel" /><category term="SQL Server Compute Context" /><category term="sp_execute_external_script" /><summary type="html">I wrote the post sp_execute_external_script and SQL Compute Context - I about how the SQL Server Compute Context (SQLCC) works with sp_execute_external_script (SPEES), as I wanted to correct some mistakes I did in the Microsoft SQL Server R Services - sp_execute_external_script - III post. I initially thought one post would be enough, but quite soon I realised I was too optimistic, and at least one more post would be needed, if not more. So this is the first followup post about SPEES and SQLCC. To see other posts (including this) in the series, go to sp_execute_external_script and SQL Server Compute Context. One of the reasons for me realising that one post is not enough is that while I wrote and executed code for the first post, I noticed some fairly significant performance differences using SQLCC compared to not using SQLCC (SQLCC performed better :)). So that is part of what we look at in this post.</summary></entry><entry><title type="html">Interesting Stuff - Week 26</title><link href="http://nielsberglund.com/2018/07/01/interesting-stuff-week-26/" rel="alternate" type="text/html" title="Interesting Stuff - Week 26" /><published>2018-07-01T05:51:55+02:00</published><updated>2018-07-01T05:51:55+02:00</updated><id>http://nielsberglund.com/2018/07/01/interesting-stuff---week-26</id><content type="html" xml:base="http://nielsberglund.com/2018/07/01/interesting-stuff-week-26/">&lt;p&gt;Geez, does time fly or what? We are already past the halfway mark of the year! Anyway, throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data science&lt;/li&gt;
  &lt;li&gt;data in general&lt;/li&gt;
  &lt;li&gt;distributed computing&lt;/li&gt;
  &lt;li&gt;SQL Server&lt;/li&gt;
  &lt;li&gt;transactions (both db as well as non db)&lt;/li&gt;
  &lt;li&gt;and other “stuff”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;databases&quot;&gt;Databases&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.allthingsdistributed.com/2018/06/purpose-built-databases-in-aws.html&quot;&gt;A one size fits all database doesn’t fit anyone&lt;/a&gt;. A very interesting post by &lt;a href=&quot;https://en.wikipedia.org/wiki/Werner_Vogels&quot;&gt;Werner Vogels&lt;/a&gt;, CTO at Amazon, where he argues that (from the article): &lt;em&gt;The days of the one-size-fits-all monolithic database are behind us, and developers are now building highly distributed applications using a multitude of purpose-built databases.&lt;/em&gt;. As I said, a very interesting read!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;streaming&quot;&gt;Streaming&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.confluent.io/blog/real-time-syslog-processing-apache-kafka-ksql-enriching-events-with-external-data/&quot;&gt;We ❤ syslogs: Real-time syslog processing with Apache Kafka and KSQL—Part 3: Enriching events with external data&lt;/a&gt;. This article is the third in the series about syslog processing and Apache Kafka. In this episode &lt;a href=&quot;https://twitter.com/rmoff&quot;&gt;Robin Moffat&lt;/a&gt; discusses how the inbound streams of syslog data can be enriched. Awesome article!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;big-data--cloud&quot;&gt;Big Data / Cloud&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/structured-streaming-with-databricks-into-power-bi-cosmos-db/&quot;&gt;Structured streaming with Azure Databricks into Power BI &amp;amp; Cosmos DB&lt;/a&gt;. A post, discussing the concept of Structured Streaming and how a data ingestion path can be built using &lt;a href=&quot;https://docs.microsoft.com/en-gb/azure/azure-databricks/what-is-azure-databricks&quot;&gt;Azure Databricks&lt;/a&gt; to enable the streaming of data in near-real-time. The post also talks about how Databricks can be connected directly into Power BI for reporting etc., and to Cosmos DB for persistence.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/the-emerging-big-data-architectural-pattern/&quot;&gt;The emerging big data architectural pattern&lt;/a&gt;. A very interesting blog post, discussing the popularity and success of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Lambda_architecture&quot;&gt;Lambda&lt;/a&gt; architecture as well as some of the shortcomings. The post then goes on to talk about how some of the shortcomings of Lambda can be solved by the use of Azure and &lt;a href=&quot;https://azure.microsoft.com/en-gb/services/cosmos-db/&quot;&gt;Azure Cosmos DB&lt;/a&gt;. In essence, the post discusses how we can implement the &lt;a href=&quot;http://dataottam.com/2016/06/02/understand-kappa-architecture-in-2-minutes/&quot;&gt;Kappa&lt;/a&gt; architecture in Azure.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://azure.microsoft.com/en-us/blog/a-closer-look-at-azure-data-lake-storage-gen2/&quot;&gt;A closer look at Azure Data Lake Storage Gen2&lt;/a&gt;. Microsoft recently announced &lt;a href=&quot;https://azure.microsoft.com/en-us/services/storage/data-lake-storage/&quot;&gt;Azure Data Lake Storage Gen2&lt;/a&gt; and this post discusses some of the new features and capabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;data-science&quot;&gt;Data Science&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://databricks.com/blog/2018/06/27/rstudio-integration.html&quot;&gt;Announcing RStudio and Databricks Integration&lt;/a&gt;. This post announces the integration of RStudio with the &lt;a href=&quot;https://databricks.com/glossary/what-is-unified-analytics&quot;&gt;Databricks Unified Analytics Platform&lt;/a&gt;. Databricks “pops up” all over the place lately. I really need to look into it!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.msdn.microsoft.com/buckwoody/2018/06/28/the-data-analysis-maturity-model-level-three-distributed-consistent-reporting-systems/&quot;&gt;The Data Analysis Maturity Model – Level Three: Distributed, consistent reporting systems&lt;/a&gt;. The third “episode” in &lt;a href=&quot;https://twitter.com/BuckWoodyMSFT&quot;&gt;Buck Woody’s&lt;/a&gt; series about data analysis maturity levels. In this post, Buck talks about distributed and consistent reporting systems.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;sql-server-machine-learning-services&quot;&gt;SQL Server Machine Learning Services&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/06/30/installing-r-packages-in-sql-server-machine-learning-services-ii/&quot;&gt;Installing R Packages in SQL Server Machine Learning Services - II&lt;/a&gt;. I published part 2 of the &lt;a href=&quot;/series/sql_server_ml_services_install_packages&quot;&gt;Install R Packages in SQL Server ML Services Series&lt;/a&gt;. In this post, we discussed how to use functionality in RevoScaleR to install packages on a remote &lt;strong&gt;SQL Server ML Services&lt;/strong&gt; instance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;-finally&quot;&gt;~ Finally&lt;/h2&gt;

&lt;p&gt;That’s all for this week. I hope you enjoy what I did put together. If you have ideas for what to cover, please comment on this post or &lt;a href=&quot;mailto:niels.it.berglund@gmail.com&quot;&gt;ping&lt;/a&gt; me.&lt;/p&gt;</content><author><name>nielsb</name></author><category term="data science" /><category term="distributed computing" /><category term="SQL Server" /><category term="SQL Server R Services" /><category term="SQL Server Machine Learning Services" /><category term="kafka" /><category term="Databricks" /><category term="Azure Data Lake Store" /><summary type="html">Geez, does time fly or what? We are already past the halfway mark of the year! Anyway, throughout the week, I read a lot of blog-posts, articles, and so forth, that has to do with things that interest me: data science data in general distributed computing SQL Server transactions (both db as well as non db) and other “stuff” This blog-post is the “roundup” of the things that have been most interesting to me, for the week just ending.</summary></entry></feed>